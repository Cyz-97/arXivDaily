{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load ../zotero.py\n",
    "\n",
    "import os\n",
    "from pyzotero import zotero\n",
    "\n",
    "\n",
    "def get_zotero_corpus(id:str,key:str) -> list[dict]:\n",
    "    \"\"\"\n",
    "    定义一个函数，用于从 Zotero 获取文献语料库\n",
    "    参数:\n",
    "    id (str): Zotero 用户的 ID\n",
    "    key (str): Zotero 用户的 API 密钥\n",
    "    返回:\n",
    "    list[dict]: 包含文献信息的字典列表\n",
    "    \"\"\"\n",
    "    # 创建一个 Zotero 实例，用于与 Zotero API 进行交互\n",
    "    zot = zotero.Zotero(id, 'user', key)\n",
    "    # 获取用户的所有集合，并遍历所有分页以获取完整结果\n",
    "    collections = zot.everything(zot.collections())\n",
    "    # 将集合列表转换为字典，键为集合的 key，值为集合对象\n",
    "    collections = {c['key']:c for c in collections}\n",
    "    # 获取所有会议论文、期刊文章和预印本类型的文献，并遍历所有分页以获取完整结果\n",
    "    corpus = zot.everything(zot.items(itemType='conferencePaper || journalArticle || preprint'))\n",
    "    # 过滤掉没有摘要的文献\n",
    "    corpus = [c for c in corpus if c['data']['abstractNote'] != '']\n",
    "\n",
    "    # 定义一个内部递归函数，用于获取集合的完整路径\n",
    "    # 参数:\n",
    "    #   col_key (str): 集合的 key\n",
    "    # 返回:\n",
    "    #   str: 集合的完整路径\n",
    "    def get_collection_path(col_key:str) -> str:\n",
    "        # 检查集合是否有父集合\n",
    "        if p := collections[col_key]['data']['parentCollection']:\n",
    "            # 若有父集合，则递归调用函数获取父集合路径，并拼接当前集合名称\n",
    "            return get_collection_path(p) + '/' + collections[col_key]['data']['name']\n",
    "        else:\n",
    "            # 若没有父集合，则返回当前集合名称\n",
    "            return collections[col_key]['data']['name']\n",
    "\n",
    "    # 遍历语料库中的每篇文献\n",
    "    for c in corpus:\n",
    "        # 为每篇文献获取其所在集合的完整路径列表\n",
    "        paths = [get_collection_path(col) for col in c['data']['collections']]\n",
    "        # 将集合路径列表添加到文献信息字典中\n",
    "        c['paths'] = paths\n",
    "\n",
    "    return corpus\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28mid\u001b[39m = \u001b[33m'\u001b[39m\u001b[33m5688686\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m      2\u001b[39m key = \u001b[33m'\u001b[39m\u001b[33mw8JvDkba8m7yfljAd51u5VRb\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m corpus = \u001b[43mget_zotero_corpus\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mid\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 23\u001b[39m, in \u001b[36mget_zotero_corpus\u001b[39m\u001b[34m(id, key)\u001b[39m\n\u001b[32m     21\u001b[39m collections = {c[\u001b[33m'\u001b[39m\u001b[33mkey\u001b[39m\u001b[33m'\u001b[39m]:c \u001b[38;5;28;01mfor\u001b[39;00m c \u001b[38;5;129;01min\u001b[39;00m collections}\n\u001b[32m     22\u001b[39m \u001b[38;5;66;03m# 获取所有会议论文、期刊文章和预印本类型的文献，并遍历所有分页以获取完整结果\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m23\u001b[39m corpus = \u001b[43mzot\u001b[49m\u001b[43m.\u001b[49m\u001b[43meverything\u001b[49m\u001b[43m(\u001b[49m\u001b[43mzot\u001b[49m\u001b[43m.\u001b[49m\u001b[43mitems\u001b[49m\u001b[43m(\u001b[49m\u001b[43mitemType\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mconferencePaper || journalArticle || preprint\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     24\u001b[39m \u001b[38;5;66;03m# 过滤掉没有摘要的文献\u001b[39;00m\n\u001b[32m     25\u001b[39m corpus = [c \u001b[38;5;28;01mfor\u001b[39;00m c \u001b[38;5;129;01min\u001b[39;00m corpus \u001b[38;5;28;01mif\u001b[39;00m c[\u001b[33m'\u001b[39m\u001b[33mdata\u001b[39m\u001b[33m'\u001b[39m][\u001b[33m'\u001b[39m\u001b[33mabstractNote\u001b[39m\u001b[33m'\u001b[39m] != \u001b[33m'\u001b[39m\u001b[33m'\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/opt/anaconda3/envs/arXivDaily/lib/python3.11/site-packages/pyzotero/zotero.py:940\u001b[39m, in \u001b[36mZotero.everything\u001b[39m\u001b[34m(self, query)\u001b[39m\n\u001b[32m    938\u001b[39m     items.extend(query)\n\u001b[32m    939\u001b[39m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mself\u001b[39m.links.get(\u001b[33m\"\u001b[39m\u001b[33mnext\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m--> \u001b[39m\u001b[32m940\u001b[39m         items.extend(\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfollow\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[32m    941\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[32m    942\u001b[39m     \u001b[38;5;66;03m# we have a bibliography object ughh\u001b[39;00m\n\u001b[32m    943\u001b[39m     items = copy.deepcopy(query)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/opt/anaconda3/envs/arXivDaily/lib/python3.11/site-packages/pyzotero/zotero.py:185\u001b[39m, in \u001b[36mretrieve.<locals>.wrapped_f\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    183\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m kwargs:\n\u001b[32m    184\u001b[39m     \u001b[38;5;28mself\u001b[39m.add_parameters(**kwargs)\n\u001b[32m--> \u001b[39m\u001b[32m185\u001b[39m retrieved = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_retrieve_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    186\u001b[39m \u001b[38;5;66;03m# we now always have links in the header response\u001b[39;00m\n\u001b[32m    187\u001b[39m \u001b[38;5;28mself\u001b[39m.links = \u001b[38;5;28mself\u001b[39m._extract_links()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/opt/anaconda3/envs/arXivDaily/lib/python3.11/site-packages/pyzotero/zotero.py:480\u001b[39m, in \u001b[36mZotero._retrieve_data\u001b[39m\u001b[34m(self, request, params)\u001b[39m\n\u001b[32m    478\u001b[39m \u001b[38;5;66;03m# file URI errors are raised immediately so we have to try here\u001b[39;00m\n\u001b[32m    479\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m480\u001b[39m     \u001b[38;5;28mself\u001b[39m.request = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mclient\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    481\u001b[39m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfinal_url\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    482\u001b[39m \u001b[43m        \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfinal_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    483\u001b[39m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdefault_headers\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    484\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    485\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    486\u001b[39m     \u001b[38;5;28mself\u001b[39m.request.encoding = \u001b[33m\"\u001b[39m\u001b[33mutf-8\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    487\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m httpx.UnsupportedProtocol:\n\u001b[32m    488\u001b[39m     \u001b[38;5;66;03m# File URI handler logic\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/opt/anaconda3/envs/arXivDaily/lib/python3.11/site-packages/httpx/_client.py:1053\u001b[39m, in \u001b[36mClient.get\u001b[39m\u001b[34m(self, url, params, headers, cookies, auth, follow_redirects, timeout, extensions)\u001b[39m\n\u001b[32m   1036\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mget\u001b[39m(\n\u001b[32m   1037\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   1038\u001b[39m     url: URL | \u001b[38;5;28mstr\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1046\u001b[39m     extensions: RequestExtensions | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   1047\u001b[39m ) -> Response:\n\u001b[32m   1048\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   1049\u001b[39m \u001b[33;03m    Send a `GET` request.\u001b[39;00m\n\u001b[32m   1050\u001b[39m \n\u001b[32m   1051\u001b[39m \u001b[33;03m    **Parameters**: See `httpx.request`.\u001b[39;00m\n\u001b[32m   1052\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1053\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1054\u001b[39m \u001b[43m        \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mGET\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   1055\u001b[39m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1056\u001b[39m \u001b[43m        \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m=\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1057\u001b[39m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1058\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcookies\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcookies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1059\u001b[39m \u001b[43m        \u001b[49m\u001b[43mauth\u001b[49m\u001b[43m=\u001b[49m\u001b[43mauth\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1060\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfollow_redirects\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfollow_redirects\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1061\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1062\u001b[39m \u001b[43m        \u001b[49m\u001b[43mextensions\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextensions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1063\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/opt/anaconda3/envs/arXivDaily/lib/python3.11/site-packages/httpx/_client.py:825\u001b[39m, in \u001b[36mClient.request\u001b[39m\u001b[34m(self, method, url, content, data, files, json, params, headers, cookies, auth, follow_redirects, timeout, extensions)\u001b[39m\n\u001b[32m    810\u001b[39m     warnings.warn(message, \u001b[38;5;167;01mDeprecationWarning\u001b[39;00m, stacklevel=\u001b[32m2\u001b[39m)\n\u001b[32m    812\u001b[39m request = \u001b[38;5;28mself\u001b[39m.build_request(\n\u001b[32m    813\u001b[39m     method=method,\n\u001b[32m    814\u001b[39m     url=url,\n\u001b[32m   (...)\u001b[39m\u001b[32m    823\u001b[39m     extensions=extensions,\n\u001b[32m    824\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m825\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mauth\u001b[49m\u001b[43m=\u001b[49m\u001b[43mauth\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfollow_redirects\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfollow_redirects\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/opt/anaconda3/envs/arXivDaily/lib/python3.11/site-packages/httpx/_client.py:914\u001b[39m, in \u001b[36mClient.send\u001b[39m\u001b[34m(self, request, stream, auth, follow_redirects)\u001b[39m\n\u001b[32m    910\u001b[39m \u001b[38;5;28mself\u001b[39m._set_timeout(request)\n\u001b[32m    912\u001b[39m auth = \u001b[38;5;28mself\u001b[39m._build_request_auth(request, auth)\n\u001b[32m--> \u001b[39m\u001b[32m914\u001b[39m response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_send_handling_auth\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    915\u001b[39m \u001b[43m    \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    916\u001b[39m \u001b[43m    \u001b[49m\u001b[43mauth\u001b[49m\u001b[43m=\u001b[49m\u001b[43mauth\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    917\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfollow_redirects\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfollow_redirects\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    918\u001b[39m \u001b[43m    \u001b[49m\u001b[43mhistory\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    919\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    920\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    921\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m stream:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/opt/anaconda3/envs/arXivDaily/lib/python3.11/site-packages/httpx/_client.py:942\u001b[39m, in \u001b[36mClient._send_handling_auth\u001b[39m\u001b[34m(self, request, auth, follow_redirects, history)\u001b[39m\n\u001b[32m    939\u001b[39m request = \u001b[38;5;28mnext\u001b[39m(auth_flow)\n\u001b[32m    941\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m942\u001b[39m     response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_send_handling_redirects\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    943\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    944\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfollow_redirects\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfollow_redirects\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    945\u001b[39m \u001b[43m        \u001b[49m\u001b[43mhistory\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhistory\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    946\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    947\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    948\u001b[39m         \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/opt/anaconda3/envs/arXivDaily/lib/python3.11/site-packages/httpx/_client.py:979\u001b[39m, in \u001b[36mClient._send_handling_redirects\u001b[39m\u001b[34m(self, request, follow_redirects, history)\u001b[39m\n\u001b[32m    976\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m hook \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m._event_hooks[\u001b[33m\"\u001b[39m\u001b[33mrequest\u001b[39m\u001b[33m\"\u001b[39m]:\n\u001b[32m    977\u001b[39m     hook(request)\n\u001b[32m--> \u001b[39m\u001b[32m979\u001b[39m response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_send_single_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    980\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    981\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m hook \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m._event_hooks[\u001b[33m\"\u001b[39m\u001b[33mresponse\u001b[39m\u001b[33m\"\u001b[39m]:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/opt/anaconda3/envs/arXivDaily/lib/python3.11/site-packages/httpx/_client.py:1014\u001b[39m, in \u001b[36mClient._send_single_request\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m   1009\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[32m   1010\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mAttempted to send an async request with a sync Client instance.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1011\u001b[39m     )\n\u001b[32m   1013\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m request_context(request=request):\n\u001b[32m-> \u001b[39m\u001b[32m1014\u001b[39m     response = \u001b[43mtransport\u001b[49m\u001b[43m.\u001b[49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1016\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(response.stream, SyncByteStream)\n\u001b[32m   1018\u001b[39m response.request = request\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/opt/anaconda3/envs/arXivDaily/lib/python3.11/site-packages/httpx/_transports/default.py:250\u001b[39m, in \u001b[36mHTTPTransport.handle_request\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m    237\u001b[39m req = httpcore.Request(\n\u001b[32m    238\u001b[39m     method=request.method,\n\u001b[32m    239\u001b[39m     url=httpcore.URL(\n\u001b[32m   (...)\u001b[39m\u001b[32m    247\u001b[39m     extensions=request.extensions,\n\u001b[32m    248\u001b[39m )\n\u001b[32m    249\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m map_httpcore_exceptions():\n\u001b[32m--> \u001b[39m\u001b[32m250\u001b[39m     resp = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_pool\u001b[49m\u001b[43m.\u001b[49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreq\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    252\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(resp.stream, typing.Iterable)\n\u001b[32m    254\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m Response(\n\u001b[32m    255\u001b[39m     status_code=resp.status,\n\u001b[32m    256\u001b[39m     headers=resp.headers,\n\u001b[32m    257\u001b[39m     stream=ResponseStream(resp.stream),\n\u001b[32m    258\u001b[39m     extensions=resp.extensions,\n\u001b[32m    259\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/opt/anaconda3/envs/arXivDaily/lib/python3.11/site-packages/httpcore/_sync/connection_pool.py:256\u001b[39m, in \u001b[36mConnectionPool.handle_request\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m    253\u001b[39m         closing = \u001b[38;5;28mself\u001b[39m._assign_requests_to_connections()\n\u001b[32m    255\u001b[39m     \u001b[38;5;28mself\u001b[39m._close_connections(closing)\n\u001b[32m--> \u001b[39m\u001b[32m256\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m exc \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    258\u001b[39m \u001b[38;5;66;03m# Return the response. Note that in this case we still have to manage\u001b[39;00m\n\u001b[32m    259\u001b[39m \u001b[38;5;66;03m# the point at which the response is closed.\u001b[39;00m\n\u001b[32m    260\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(response.stream, typing.Iterable)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/opt/anaconda3/envs/arXivDaily/lib/python3.11/site-packages/httpcore/_sync/connection_pool.py:236\u001b[39m, in \u001b[36mConnectionPool.handle_request\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m    232\u001b[39m connection = pool_request.wait_for_connection(timeout=timeout)\n\u001b[32m    234\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    235\u001b[39m     \u001b[38;5;66;03m# Send the request on the assigned connection.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m236\u001b[39m     response = \u001b[43mconnection\u001b[49m\u001b[43m.\u001b[49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    237\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpool_request\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrequest\u001b[49m\n\u001b[32m    238\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    239\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m ConnectionNotAvailable:\n\u001b[32m    240\u001b[39m     \u001b[38;5;66;03m# In some cases a connection may initially be available to\u001b[39;00m\n\u001b[32m    241\u001b[39m     \u001b[38;5;66;03m# handle a request, but then become unavailable.\u001b[39;00m\n\u001b[32m    242\u001b[39m     \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[32m    243\u001b[39m     \u001b[38;5;66;03m# In this case we clear the connection and try again.\u001b[39;00m\n\u001b[32m    244\u001b[39m     pool_request.clear_connection()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/opt/anaconda3/envs/arXivDaily/lib/python3.11/site-packages/httpcore/_sync/http_proxy.py:343\u001b[39m, in \u001b[36mTunnelHTTPConnection.handle_request\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m    336\u001b[39m             \u001b[38;5;28mself\u001b[39m._connection = HTTP11Connection(\n\u001b[32m    337\u001b[39m                 origin=\u001b[38;5;28mself\u001b[39m._remote_origin,\n\u001b[32m    338\u001b[39m                 stream=stream,\n\u001b[32m    339\u001b[39m                 keepalive_expiry=\u001b[38;5;28mself\u001b[39m._keepalive_expiry,\n\u001b[32m    340\u001b[39m             )\n\u001b[32m    342\u001b[39m         \u001b[38;5;28mself\u001b[39m._connected = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m343\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_connection\u001b[49m\u001b[43m.\u001b[49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/opt/anaconda3/envs/arXivDaily/lib/python3.11/site-packages/httpcore/_sync/http11.py:136\u001b[39m, in \u001b[36mHTTP11Connection.handle_request\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m    134\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m Trace(\u001b[33m\"\u001b[39m\u001b[33mresponse_closed\u001b[39m\u001b[33m\"\u001b[39m, logger, request) \u001b[38;5;28;01mas\u001b[39;00m trace:\n\u001b[32m    135\u001b[39m         \u001b[38;5;28mself\u001b[39m._response_closed()\n\u001b[32m--> \u001b[39m\u001b[32m136\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m exc\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/opt/anaconda3/envs/arXivDaily/lib/python3.11/site-packages/httpcore/_sync/http11.py:106\u001b[39m, in \u001b[36mHTTP11Connection.handle_request\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m     95\u001b[39m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[32m     97\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m Trace(\n\u001b[32m     98\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mreceive_response_headers\u001b[39m\u001b[33m\"\u001b[39m, logger, request, kwargs\n\u001b[32m     99\u001b[39m ) \u001b[38;5;28;01mas\u001b[39;00m trace:\n\u001b[32m    100\u001b[39m     (\n\u001b[32m    101\u001b[39m         http_version,\n\u001b[32m    102\u001b[39m         status,\n\u001b[32m    103\u001b[39m         reason_phrase,\n\u001b[32m    104\u001b[39m         headers,\n\u001b[32m    105\u001b[39m         trailing_data,\n\u001b[32m--> \u001b[39m\u001b[32m106\u001b[39m     ) = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_receive_response_headers\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    107\u001b[39m     trace.return_value = (\n\u001b[32m    108\u001b[39m         http_version,\n\u001b[32m    109\u001b[39m         status,\n\u001b[32m    110\u001b[39m         reason_phrase,\n\u001b[32m    111\u001b[39m         headers,\n\u001b[32m    112\u001b[39m     )\n\u001b[32m    114\u001b[39m network_stream = \u001b[38;5;28mself\u001b[39m._network_stream\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/opt/anaconda3/envs/arXivDaily/lib/python3.11/site-packages/httpcore/_sync/http11.py:177\u001b[39m, in \u001b[36mHTTP11Connection._receive_response_headers\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m    174\u001b[39m timeout = timeouts.get(\u001b[33m\"\u001b[39m\u001b[33mread\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m    176\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m177\u001b[39m     event = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_receive_event\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    178\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(event, h11.Response):\n\u001b[32m    179\u001b[39m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/opt/anaconda3/envs/arXivDaily/lib/python3.11/site-packages/httpcore/_sync/http11.py:217\u001b[39m, in \u001b[36mHTTP11Connection._receive_event\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m    214\u001b[39m     event = \u001b[38;5;28mself\u001b[39m._h11_state.next_event()\n\u001b[32m    216\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m event \u001b[38;5;129;01mis\u001b[39;00m h11.NEED_DATA:\n\u001b[32m--> \u001b[39m\u001b[32m217\u001b[39m     data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_network_stream\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    218\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mREAD_NUM_BYTES\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\n\u001b[32m    219\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    221\u001b[39m     \u001b[38;5;66;03m# If we feed this case through h11 we'll raise an exception like:\u001b[39;00m\n\u001b[32m    222\u001b[39m     \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[32m    223\u001b[39m     \u001b[38;5;66;03m#     httpcore.RemoteProtocolError: can't handle event type\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    227\u001b[39m     \u001b[38;5;66;03m# perspective. Instead we handle this case distinctly and treat\u001b[39;00m\n\u001b[32m    228\u001b[39m     \u001b[38;5;66;03m# it as a ConnectError.\u001b[39;00m\n\u001b[32m    229\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m data == \u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._h11_state.their_state == h11.SEND_RESPONSE:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/opt/anaconda3/envs/arXivDaily/lib/python3.11/site-packages/httpcore/_backends/sync.py:128\u001b[39m, in \u001b[36mSyncStream.read\u001b[39m\u001b[34m(self, max_bytes, timeout)\u001b[39m\n\u001b[32m    126\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m map_exceptions(exc_map):\n\u001b[32m    127\u001b[39m     \u001b[38;5;28mself\u001b[39m._sock.settimeout(timeout)\n\u001b[32m--> \u001b[39m\u001b[32m128\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_sock\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrecv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmax_bytes\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/opt/anaconda3/envs/arXivDaily/lib/python3.11/ssl.py:1295\u001b[39m, in \u001b[36mSSLSocket.recv\u001b[39m\u001b[34m(self, buflen, flags)\u001b[39m\n\u001b[32m   1291\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m flags != \u001b[32m0\u001b[39m:\n\u001b[32m   1292\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m   1293\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mnon-zero flags not allowed in calls to recv() on \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m\"\u001b[39m %\n\u001b[32m   1294\u001b[39m             \u001b[38;5;28mself\u001b[39m.\u001b[34m__class__\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m1295\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbuflen\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1296\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1297\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m().recv(buflen, flags)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/opt/anaconda3/envs/arXivDaily/lib/python3.11/ssl.py:1168\u001b[39m, in \u001b[36mSSLSocket.read\u001b[39m\u001b[34m(self, len, buffer)\u001b[39m\n\u001b[32m   1166\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._sslobj.read(\u001b[38;5;28mlen\u001b[39m, buffer)\n\u001b[32m   1167\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1168\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_sslobj\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m   1169\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m SSLError \u001b[38;5;28;01mas\u001b[39;00m x:\n\u001b[32m   1170\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m x.args[\u001b[32m0\u001b[39m] == SSL_ERROR_EOF \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m.suppress_ragged_eofs:\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "id = '5688686'\n",
    "key = 'w8JvDkba8m7yfljAd51u5VRb'\n",
    "corpus = get_zotero_corpus(id,key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Search for the dark photon in <span class=\"nocase\">π⁰</span> decays\n",
      "\n",
      "A sample of $1.69\\times 10^7$ fully reconstructed $\\pi^0\\to\\gamma e^+e^-$ decay candidates collected by the NA48/2 experiment at CERN in 2003--2004 is analysed to search for the dark photon ($A'$) production in the $\\pi^0\\to\\gamma A'$ decay followed by the prompt $A'\\to e^+e^-$ decay. No signal is observed, and an exclusion region in the plane of the dark photon mass $m_{A'}$ and mixing parameter $\\varepsilon^2$ is established. The obtained upper limits on $\\varepsilon^2$ are more stringent than the previous limits in the mass range $9~{\\rm MeV}/c^2<m_{A'}<70~{\\rm MeV}/c^2$. The NA48/2 sensitivity to the dark photon production in the $K^\\pm\\to\\pi^\\pm A'$ decay is also evaluated.\n",
      "\n",
      "---\n",
      "\n",
      "# Search for new light vector boson using J/Ψ at BESIII and Belle II\n",
      "\n",
      "We investigate various search strategies for light vector boson $X$ in $\\mathcal{O}(10)~{\\rm MeV}$ mass range using $J/\\Psi$ associated channels at BESIII and Belle II: (i) $J/\\Psi \\to \\eta_c X$ with $10^{10} J/\\Psi$s at BESIII, (ii) $J/\\Psi (\\eta_c +X) +\\ell \\bar{\\ell}$ production at Belle~II, and (iii) $J/\\Psi +X$ with the displaced vertex in $X\\to e^+e^-$ decay are analyzed and the future sensitivities at Belle II with 50 ${\\rm ab}^{-1}$ luminosity are comprehensively studied. By requiring the displaced vertex to be within the beam pipe, the third method results in nearly background-free analysis, and the vector boson-electron coupling and the vector boson mass can be probed in the unprecedented range, $10^{-4}\\leq |\\varepsilon_e| \\leq 10^{-3}$ and $9~{\\rm MeV}\\leq m_X\\leq 100 {\\rm MeV}$ with 50 ${\\rm ab}^{-1}$ at Belle II. This covers the favored signal region of $^8{\\rm Be}^*$ anomaly recently reported by Atomki experiment with $m_X \\simeq 17~{\\rm MeV}$.\n",
      "\n",
      "---\n",
      "\n",
      "# Measurement of the time-like pion transition form factor at BESIII\n",
      "\n",
      "The pion transition form factor is an important input to the dispersive approaches of the Standard Model calculations for the anomalous magnetic moment of the muon. We report the prospects of a first measurement at high momentum transfer in the time-like region performed at BESIII. The aim is to improve the uncertainty of the hadronic light-by-light calculations and to shed light on the BaBar-Belle puzzle in the space-like region.\n",
      "\n",
      "---\n",
      "\n",
      "# Holographic analysis of the pion\n",
      "\n",
      "Inspired by light-front holography, we compute the pion mass, charge radius, decay constant, electromagnetic form factor and electromagnetic transition form factor. To do so, we model the longitudinal quark dynamics using potentials due to 't Hooft and to Li & Vary. We find a longitudinal wavefunction that is rather more peaked about $x \\sim 1/2$ than in previous studies. We also explore the strong degeneracy between these two potentials and conclude by noting that one scenario that accords well with the data also maps onto an equation previously noted by Vegh that describes the dynamics of a four-segmented string in $\\mathrm{AdS}_3$.\n",
      "\n",
      "---\n",
      "\n",
      "# Measurement of the <span class=\"nocase\">π⁰</span> electromagnetic transition form factor slope\n",
      "\n",
      "The NA62 experiment collected a large sample of charged kaon decays in 2007 with a highly efficient trigger for decays into electrons. A measurement of the $\\pi^0$ electromagnetic transition form factor slope parameter from $1.11\\times10^{6}$ fully reconstructed $K^\\pm \\to \\pi^\\pm \\pi^0_D, \\pi^0_D \\to e^+ e^-\\gamma$ events is reported. The measured value $a = (3.68 \\pm 0.57)\\times10^{-2}$ is in good agreement with theoretical expectations and previous measurements, and represents the most precise experimental determination of the slope in the time-like momentum transfer region.\n",
      "\n",
      "---\n",
      "\n",
      "# Design and construction of the BESIII detector\n",
      "\n",
      "This paper will discuss the design and construction of BESIII, which is designed to study physics in the t-charm energy region utilizing the new high luminosity BEPCII double ring e+eÀ collider. The expected performance will be given based on Monte Carlo simulations and results of cosmic ray and beam tests. In BESIII, tracking and momentum measurements for charged particles are made by a cylindrical multilayer drift chamber in a 1 T superconducting solenoid. Charged particles are identiﬁed with a time-of-ﬂight system based on plastic scintillators in conjunction with dE/dx (energy loss per unit pathlength) measurements in the drift chamber. Energies of electromagnetic showers are measured by a CsI(Tl) crystal calorimeter located inside the solenoid magnet. Muons are identiﬁed by arrays of resistive plate chambers in a steel magnetic yoke for the ﬂux return. The level 1 trigger system, data acquisition system and the detector control system based on networked computers will also be described.\n",
      "\n",
      "---\n",
      "\n",
      "# Measurement of the spectral function for the <span class=\"nocase\">τ⁻→K⁻K<sub>S</sub>ν<sub>τ</sub></span> decay\n",
      "\n",
      "The decay $\\tau^{-}\\to K^{-}K_S\\nu_{\\tau}$ has been studied using $430\\times10^6$ $e^+e^-\\to \\tau^+\\tau^-$ events produced at a center-of-mass energy around 10.6 GeV at the PEP-II collider and studied with the BABAR detector. The mass spectrum of the $K^{-}K_S$ system has been measured and the spectral function has been obtained. The measured branching fraction ${\\cal B}(\\tau^{-}\\to K^{-}K_S\\nu_{\\tau}) = (0.739\\pm 0.011(\\rm stat.)\\pm 0.020(\\rm syst.))\\times 10^{-3}$ is found to be in agreement with earlier measurements.\n",
      "\n",
      "---\n",
      "\n",
      "# High-Statistics Study of the tau- —> pi- pi0 nu(tau) Decay\n",
      "\n",
      "We report a high-statistics measurement of the branching fraction for tau^- -> pi^- pi^0 nu_tau and the invariant mass spectrum of the produced pi^- pi^0 system using 72.2 fb^-1 of data recorded with the Belle detector at the KEKB asymmetric-energy e^+ e^- collider. The branching fraction obtained is (25.12 +/- 0.01 +/- 0.38)%, where the first error is statistical and the second is systematic. The unfolded pi^- pi^0 mass spectrum is used to determine resonance parameters for the rho(770), rho'(1450), and rho''(1700) mesons. We also use this spectrum to estimate the hadronic (2pi) contribution to the anomalous magnetic moment of the muon (a_{mu}^{pipi}). Our result for a_{mu}^{pipi} integrated over the mass range sqrt{s} = 2m_{pi} - 1.8 GeV/c^2 is a_{mu}^{pipi} = (519.1 +/- 1.5 (exp) +/- 2.6 (Br) +/- 2.5 (isospin)) x 10^{-10}, where the first error is due to the experimental uncertainties, the second is due to the uncertainties in the branching fractions and the third is due to the uncertainties in the isospin-violating corrections.\n",
      "\n",
      "---\n",
      "\n",
      "# The strong coupling from hadronic <span class=\"nocase\">τ</span>-decay data including <span class=\"nocase\">τ→π⁻π⁰ν<sub>τ</sub></span> from Belle\n",
      "\n",
      "In previous work we have combined the $\\pi^-\\pi^0$, $2\\pi^-\\pi^+\\pi^0$ and $\\pi^-3\\pi^0$ spectral data obtained from hadronic $\\tau$ decays measured by the ALEPH and OPAL experiments, together with electroproduction data for several of the subleading hadronic modes and BaBar data for the $K\\bar{K}$ mode to construct an inclusive non-strange vector spectral function entirely based on experimental data, with no Monte-Carlo generated input. In this paper, we include, for the first time, the Belle $\\tau\\to\\pi^-\\pi^0\\nu_\\tau$ high-statistics decay data to construct a new inclusive non-strange vector spectral function that combines more of the world's available data. As no Belle data are at present available for the two $4\\pi$ modes, this requires a revised data analysis in comparison with our previous work. From the resulting new spectral function, we obtain a new determination of the strong coupling, $\\alpha_s$, using our previously developed strategy based on finite-energy sum rules. We find, at the $Z$ mass scale, $\\alpha_s(m_Z^2)=0.1159(14)$. We discuss the smaller central value and larger error of our new result compared to our previous result, showing the shifts to be due mainly to significant changes in updated HFLAV results for the $\\pi^-3\\pi^0$ decay mode.\n",
      "\n",
      "---\n",
      "\n",
      "# Probing entanglement and testing Bell inequality violation with e+e-→τ+τ- at Belle II\n",
      "\n",
      "We present a feasibility study to probe quantum entanglement and Belle inequality violation in the process $\\textrm{e}^{+}\\textrm{e}^{-} \\rightarrow \\tau^{+}\\tau^{-}$ at a center-of-mass energy of $\\sqrt{s} = 10.579$ GeV. The sensitivity of the analysis is enhanced by applying a selection on the scattering angle $\\vartheta$ in the $\\tau^{+}\\tau^{-}$ center-of-mass frame. We analyze events in which both $\\tau$ leptons decay to hadrons, using a combination of decay channels $\\tau^{-} \\rightarrow \\pi^{-}\\nu_{\\tau}$, $\\tau^{-} \\rightarrow \\pi^{-}\\pi^{0}\\nu_{\\tau}$, and $\\tau^{-} \\rightarrow \\pi^{-}\\pi^{+}\\pi^{-}\\nu_{\\tau}$. The spin orientation of the $\\tau$ leptons in these decays is reconstructed using the polarimeter-vector method. Assuming a dataset of $200$ million $\\tau^{+}\\tau^{-}$ events and accounting for experimental resolutions, we expect the observation of quantum entanglement and Bell inequality violation by the Belle-II experiment will be possible with a significance well in excess of five standard deviations.\n",
      "\n",
      "---\n",
      "\n",
      "# Quantum information and CP measurement in H→τ+τ- at future lepton colliders\n",
      "\n",
      "We introduce a methodology and investigate the feasibility of measuring quantum properties of tau lepton pairs in the $H \\to \\tau^+ \\tau^-$ decay at future lepton colliders. In particular, observation of entanglement, steerability and violation of Bell inequalities are examined for the ILC and FCC-ee. We find that detecting quantum correlation crucially relies on precise reconstruction of the tau lepton rest frame and a simple kinematics reconstruction does not suffice due to the finite energy resolution of the colliding beams and detectors. To correct for energy mismeasurements, a log-likelihood method is developed that incorporates the information of impact parameters of tau lepton decays. We demonstrate that an accurate measurement of quantum properties is possible with this method. As a by-product, we show that a novel model-independent test of CP violation can be performed and the CP-phase of $H \\tau \\tau$ interaction can be constrained with an accuracy comparable to dedicated analyses, i.e., up to $7.9^{\\circ}$ and $5.4^{\\circ}$ at ILC and FCC-ee, respectively.\n",
      "\n",
      "---\n",
      "\n",
      "# Tau kinematics from impact parameters\n",
      "\n",
      "The momenta of $\\tau$ decay products in the reaction $e~+e~-\\to\\tau~+\\tau~-$ do not constrain the $\\tau$ direction unambiguously. It is shown how the measurement of tracks of hadrons from semileptonic $\\tau$ decays, in particular their relative impact parameters, allows to resolve this ambiguity.\n",
      "\n",
      "---\n",
      "\n",
      "# Probing entanglement and testing Bell inequality violation with ${e}^{+}{e}^{\\ensuremath{-}}\\ensuremath{\\rightarrow}{\\ensuremath{\\tau}}^{+}{\\ensuremath{\\tau}}^{\\ensuremath{-}}$ at Belle II\n",
      "\n",
      "We present a feasibility study to probe quantum entanglement and Bell inequality violation in the process e+⁢e− →𝜏+⁢𝜏− at a center-of-mass energy of √𝑠=10.579 GeV. The sensitivity of the analysis is enhanced by applying a selection on the scattering angle 𝜗 in the 𝜏+⁢𝜏− center-of-mass frame. We analyze events in which both 𝜏 leptons decay to hadrons, using a combination of decay channels 𝜏− →𝜋−⁢𝜈𝜏, 𝜏−→𝜋−⁢𝜋0⁢𝜈𝜏, and 𝜏− →𝜋−⁢𝜋+⁢𝜋−⁢𝜈𝜏. The spin orientation of the 𝜏 leptons in these decays is reconstructed using the polarimeter-vector method. Assuming a dataset of 200 million 𝜏+⁢𝜏− events and accounting for experimental resolutions, we expect the observation of quantum entanglement and Bell inequality violation by the Belle-II experiment will be possible with a significance well in excess of five standard deviations.\n",
      "\n",
      "---\n",
      "\n",
      "# QCD predictions for the decay of the \\ensuremath{\\tau} lepton\n",
      "\n",
      "The semileptonic decay rate of a heavy lepton is shown to be rigorously calculable by use of perturbative QCD. Even the τ lepton is heavy enough for the perturbative approximation to be accurate. The prediction for the ratio R=Γ(τ→𝑣τ+hadrons)/Γ(τ→𝑣τ+𝑒−+v¯𝑒) is 3.29, with an uncertainty of about 1% due to the uncertainty in the Λ parameter of QCD. Nonperturbative corrections to this prediction are estimated to be on the order of 1%. More importantly, these corrections are shown to be negative because of a fortuitous cancellation of the leading contribution from the gluon condensate. The resulting prediction is significantly smaller than the present experimental result R=3.65±0.13.\n",
      "\n",
      "---\n",
      "\n",
      "# QCD and resonance physics. applications\n",
      "\n",
      "Resonance properties are investigated within the QCD-based approach to resonance physics developed earlier. We extend first the dispersion charmonium theory to include power terms due to the non-perturbative effects of QCD. As a byproduct, an estimate for the gluonic vacuum expectation value, 〈0|GμνaGμνa|0〉, emerges. The main emphasis is made on the analysis of the ϱ, ω, ϕ, K∗ mesons. Predictions are formulated for integrals of the type ∫ Im Π e−s/M2 ds where Im Π is aan appropriate spectral density. It is shown that there exist such M2 that the integrals are dominated by a single resonance, on one hand, and are calculable in a reliable way, on the other. As a result we are able to calculate the resonance coupling constants and masses. The typical accuracy achieved is about 10%. The power terms considered explain both the π-ϱ-A1 mass splittings and the observed pattern of the SU(3) symmetry breaking in the vector nonet. We discuss, also, the relation between our approach and more traditional ones. A few original remarks concerning the MIT bag model, instanton calculus, etc. are included.\n",
      "\n",
      "---\n",
      "\n",
      "# Perturbative QCD corrections to the ratio R for \\ensuremath{\\tau} decay\n",
      "\n",
      "The perturbative QCD correction to the semihadronic decay rate of a heavy lepton is expressed as an expansion in 𝛼𝑠. In the case of the τ lepton, the ratio of the semihadronic and electronic decay rates is R=3[1+𝛼𝑠/π+5.20(𝛼𝑠/π)2 +104.0(𝛼𝑠/π)3]. The use of R to give a precise determination of 𝛼𝑠 is advocated.\n",
      "\n",
      "---\n",
      "\n",
      "# Nonperturbative effects in $\\ensuremath{\\tau}$ decay\n",
      "\n",
      "It has been suggested that the lifetime of the 𝜏 lepton can be calculated using perturbative QCD, with sufficient accuracy that comparison with the measured lifetime can be used to determine the QCD scale parameter 𝛬. Contrary to this suggestion, nonperturbative effects are shown here to introduce uncertainties in the calculated lifetime which are so large as to make the determination of 𝛬 unreliable. These nonperturbative effects are associated with hadronic thresholds and resonances, and are much larger than previous estimates based on QCD sum rules. Independent experimental tests, which make use of the hadronic mass spectrum in 𝜏 decay, are proposed.\n",
      "\n",
      "---\n",
      "\n",
      "# On the perturbative QCD calculation of the <i>R</i> ratio for <i>τ</i> decay\n",
      "\n",
      "We show that perturbative QCD calculation of the R ratio for τ decay cannot be trusted because of the small value of the scheme invariant quantity, ρ0, for this process. The predictions are strongly dependent on renormalization scheme choice for values of ΛMS favoured by e+e− annihilation data. This is true to O(αs2) and O(αs3), and has nothing to do with the large O(αs3) perturbative coefficient.\n",
      "\n",
      "---\n",
      "\n",
      "# Renormalization group analysis of the τ-lepton decay within QCD\n",
      "\n",
      "A technique to sum up the regular corrections appearing under the analytical continuation from the space like momentum region to the time like one is proposed. A perturbative part of the inclusive semileptonic decay width of the τ-lepton in analyzed in detail.\n",
      "\n",
      "---\n",
      "\n",
      "# The perturbative QCD prediction to Rτ revisited\n",
      "\n",
      "The perturbative QCD prediction to the total hadronic width of the tau lepton is re-examined. A more convergent perturbative expansion is proposed, which is associated with a smaller renormalization-scheme dependence and better-defined higher-order uncertainties.\n",
      "\n",
      "---\n",
      "\n",
      "# Testing QCD with τ decays\n",
      "\n",
      "The invariant-mass distribution of the hadronic state in τ decay can be used for testing fundamental aspects of the strong interactions. Using standard QCD techniques, it is possible to compute certain weighted integrals of the hadronic spectrum. We work out some QCD predictions which will be useful for analysing the data. They provide a direct way to simultaneously measure αs(mτ2) and the parameters characterizing the non-perturbative dynamics, allowing for a better control of the theoretical errors in the determination of αs(mτ2).\n",
      "\n",
      "---\n",
      "\n",
      "# The optimal method for the measurement of tau polarization\n",
      "\n",
      "A variable is constructed for each τ decay channel which carries all the available information on the τ spin state. Its use allows a simple determination of the polarization with the maximal sensitivity for all final states. Further applications to the τ→a1ν channel are discussed and it is shown that a sizeable improvement of the measurement can be achieved.\n",
      "\n",
      "---\n",
      "\n",
      "# Measurement of the branching fraction scrB(${\\mathrm{\\ensuremath{\\tau}}}^{\\mathrm{\\ensuremath{-}}}$\\ensuremath{\\rightarrow}${\\mathit{h}}^{\\mathrm{\\ensuremath{-}}}$\\ensuremath{\\rightarrow}${\\mathrm{\\ensuremath{\\pi}}}^{0}$${\\ensuremath{\\nu}}_{\\mathrm{\\ensuremath{\\tau}}}$)\n",
      "\n",
      "Using data from the CLEO II detector at the Cornell Electron Storage Ring, we measure scrB(τ−→h−π0ντ) where h− refers to either π− or K−. We use three different methods to measure this branching fraction. The combined result is scrB(τ−→h−π0ντ)=0.2587±0.0012±0.0042, in good agreement with standard model predictions.\n",
      "\n",
      "---\n",
      "\n",
      "# Measurement of the spectral functions of vector current hadronic tau decays\n",
      "\n",
      "A measurement of the spectral functions of non-strange τ vector current final states is presented, using 124 358 τ pairs recorded by the ALEPH detector at LEP during the years 1991 to 1994. The spectral functions of the dominant two- and four-pion τ decay channels are compared to published results of e+e- annihilation experiments via isospin rotation. A combined fit of the pion form factor from τ decays and e+e- data is performed using different parametrizations. The mass and the width of the ρ±(770) and the ρ0(770) are separately determined in order to extract possible isospin violating effects. The mass and width differences are measured to be Mρ±(770) - Mρ0(770) = (0.0 ± 1.0) MeV/c2 and Γρ±(770) - Γρ0(770) = (0.1 ± 1.9) MeV/c2.\n",
      "\n",
      "---\n",
      "\n",
      "# Measurement of αS from τ decays\n",
      "\n",
      "We present measurements of spectral moments extracted from the invariant mass distributions of the final states of hadronic τ decay products recorded in the CLEO detector. From a fit of theoretical predictions to the measurements of spectral moments and the total hadronic decay width of the τ, we determine the strong coupling constant and a set of non-perturbative QCD parameters. The strong coupling constant is measured to be αs(mτ) = 0.306 ± 0.024, which when extrapolated to the Z mass, yields αs(Mz) = 0.114 ± 0.003.\n",
      "\n",
      "---\n",
      "\n",
      "# Renormalization scheme dependence and the problem of the determination of ${\\ensuremath{\\alpha}}_{s}$ and the condensates from semileptonic $\\ensuremath{\\tau}$ decays\n",
      "\n",
      "The QCD corrections to the moments of the invariant mass distribution in the semileptonic 𝜏 decays are considered. The effect of the renormalization scheme dependence on the fitted values of 𝛼𝑠⁢(𝑚2𝜏) and the condensates is discussed, using a simplified approach where the nonperturbative contributions are approximated by the dimension six condensates. The fits in the vector and axial-vector channels are investigated in the next-to-leading and the next-to-next-to-leading order. The next-to-next-to-leading order results are found to be relatively stable with respect to change of the renormalization scheme. A change from the ¯MS scheme to the minimal sensitivity scheme results in the reduction of the extracted value of 𝛼𝑠⁢(𝑚2𝜏) by 0.01.\n",
      "\n",
      "---\n",
      "\n",
      "# Measurement of the Strong Coupling Constant and the Vector and Axial-Vector Spectral Functions in Hadronic Tau Decays\n",
      "\n",
      "The spectral functions of the vector current and the axial-vector current have been measured in hadronic tau decays using the OPAL detector at LEP. Within the framework of the Operator Product Expansion a simultaneous determination of the strong coupling constant alpha_s, the non-perturbative operators of dimension 6 and 8 and of the gluon condensate has been performed. Different perturbative descriptions have been compared to the data. The Contour Improved Fixed Order Perturbation Theory gives alpha_s(mtau**2) = 0.348 +- 0.009 +- 0.019 at the tau-mass scale and alpha_s(mz**2) = 0.1219 +- 0.0010 +- 0.0017 at the Z-mass scale. The values obtained for alpha_s(mz**2) using Fixed Order Perturbation Theory or Renormalon Chain Resummation are 2.3% and 4.1% smaller, respectively. The running of the strong coupling between s_0 ~1.3 GeV**2 and s_0 = mtau**2 has been tested from direct fits to the integrated differential hadronic decay rate R_tau. A test of the saturation of QCD sum rules at the tau-mass scale has been performed.\n",
      "\n",
      "---\n",
      "\n",
      "# Spectral functions from hadronic τ decays\n",
      "\n",
      "Hadronic decays of the τ lepton provide a clean environment to study hadron dynamics in an energy regime dominated by resonances, with the interesting information captured in the spectral functions. Recent results on exclusive channels are reviewed. Inclusive spectral functions are the basis for QCD analyses, delivering an accurate determination of the strong coupling constant and quantitative information on nonperturbative contributions. The τ vector spectral functions for the 2π and 4π final states are used together with e+e− data in order to compute vacuum polarization integrals occuring in the calculations of the anomalous magnetic moment of the muon and the running of the electromagnetic coupling.\n",
      "\n",
      "---\n",
      "\n",
      "# Electroweak fits at LEP\n",
      "\n",
      "High precision electroweak measurements performed over ten years at LEP and SLC have allowed to constrain the Standard Model of electroweak interactio…\n",
      "\n",
      "---\n",
      "\n",
      "# Precision determination of heavy quark masses and the strong coupling constant\n",
      "\n",
      "We present a new QCD sum rule with high sensitivity to the continuum regions of charm and bottom quark pair production. Combining this sum rule with existing ones yields very stable results for the MS quark masses, mc(mc) and mb(mb). We introduce a phenomenological parametrization of the continuum interpolating smoothly between the pseudoscalar threshold and asymptotic quark regions. Comparison of our approach with recent BES data allows for a robust theoretical error estimate. The parametric uncertainty due to αs is reduced by performing a simultaneous ﬁt to the most precise sum rules and other high precision observables. This includes a new evaluation of the lifetime of the τ lepton, ττ , serving as a strong constraint on αs . Our results are mc(mc) = 1.289+−00..004405 GeV, mb(mb) = 4.207+−00..003301 GeV (with a correlation of 29%), and αs (MZ)[ττ ] = 0.1221+−00..00002263.\n",
      "\n",
      "---\n",
      "\n",
      "# Branching ratios and spectral functions of τ decays: Final ALEPH measurements and physics implications\n",
      "\n",
      "The full LEP-1 data set collected with the ALEPH detector at the Z pole during 1991–1995 is analysed in order to measure the τ decay branching fractions. The analysis follows the global method used in the published study based on 1991–1993 data, but several improvements are introduced, especially concerning the treatment of photons and π0's. Extensive systematic studies are performed, in order to match the large statistics of the data sample corresponding to over 300000 measured and identified τ decays. Branching fractions are obtained for the two leptonic channels and 11 hadronic channels defined by their respective numbers of charged particles and π0's. Using previously published ALEPH results on final states with charged and neutral kaons, corrections are applied to the hadronic channels to derive branching ratios for exclusive final states without kaons. Thus the analyses of the full LEP-1 ALEPH data are combined to yield a complete description of τ decays, encompassing 22 non-strange and 11 strange hadronic modes. Some physics implications of the results are given, in particular related to universality in the leptonic charged weak current, isospin invariance in a1 decays, and the separation of vector and axial-vector components of the total hadronic rate. Finally, spectral functions are determined for the dominant hadronic modes and updates are given for several analyses. These include: tests of isospin invariance between the weak charged and electromagnetic hadronic currents, fits of the ρ resonance lineshape, and a QCD analysis of the non-strange hadronic decays using spectral moments, yielding the value αs(mτ2)=0.340±0.005exp±0.014th. The evolution to the Z mass scale yields αs(MZ2)=0.1209±0.0018. This value agrees well with the direct determination from the Z width and provides the most accurate test to date of asymptotic freedom in the QCD gauge theory.\n",
      "\n",
      "---\n",
      "\n",
      "# The physics of hadronic tau decays\n",
      "\n",
      "Hadronic τ decays provide a clean laboratory for the precise study of quantum chromodynamics (QCD). Observables based on the spectral functions of hadronic τ decays can be related to QCD quark-level calculations to determine fundamental quantities like the strong-coupling constant, parameters of the chiral Lagrangian ∣Vus∣, the mass of the strange quark, and to simultaneously test the concept of quark-hadron duality. Using the best available measurements and a revisited analysis of the theoretical framework, the value αs(m2τ)=0.345±0.004exp±0.009th is obtained. Taken together with the determination of αs(M2Z) from the global electroweak fit, this result leads to the most accurate test of asymptotic freedom: the value of the logarithmic slope of α−1s(s) is found to agree with QCD at a precision of 4%. The τ spectral functions can also be used to determine hadronic quantities that, due to the nonperturbative nature of long-distance QCD, cannot be computed from first principles. An example for this is the contribution from hadronic vacuum polarization to loop-dominated processes like the anomalous magnetic moment of the muon. This article reviews the measurements of nonstrange and strange τ spectral functions and their phenomenological applications.\n",
      "\n",
      "---\n",
      "\n",
      "# Order α s 4 QCD Corrections to Z and τ Decays\n",
      "\n",
      "The exact result for the  4s term in the Adler function allows to extract the strong coupling constant from Z and   decays with high precision. Including the exact  4s leads to small shifts of the central values and to a signiﬁcant reduction of the theory uncertainty. Note that the shifts in  sMZ from Z and   decays are opposite in sign and move the values in the proper direction, decreasing, thus, the current slight mismatch between two independent determinations of  s.\n",
      "\n",
      "---\n",
      "\n",
      "# The determination of α S from τ decays revisited\n",
      "\n",
      "We revisit the determination of αS(m2τ ) using a ﬁt to inclusive τ hadronic spectral moments in light of (1) the recent calculation of the fourth-order perturbative coefﬁcient K4 in the expansion of the Adler function, (2) new precision measurements from BABAR of e+e− annihilation cross sections, which decrease the uncertainty in the separation of vector and axial-vector spectral functions, and (3) improved results from BABAR and Belle on τ branching fractions involving kaons. We estimate that the fourth-order perturbative prediction reduces the theoretical uncertainty, introduced by the truncation of the series, by 20% with respect to earlier determinations. We discuss to some detail the perturbative prediction of two different methods: ﬁxed-order perturbation theory (FOPT) and contour-improved perturbative theory (CIPT). The corresponding theoretical uncertainties are studied at the τ and Z mass scales. The CIPT method is found to be more stable with respect to the missing higher order contributions and to renormalization scale variations. It is also shown that FOPT suffers from convergence problems along the complex integration contour. Nonperturbative contributions extracted from the most inclusive ﬁt are small, in agreement with earlier determinations. Systematic effects from quark-hadron duality violation are estimated with simple models and found to be within the quoted systematic errors. The ﬁt based on CIPT gives αS(m2τ ) = 0.344 ± 0.005 ± 0.007, where the ﬁrst error is experimental and the second theoretical. After evolution to MZ we obtain αS(MZ2 ) = 0.1212 ± 0.0005 ± 0.0008 ± 0.0005, where the errors are respectively experimental, theoretical and due to the evolution. The result is in agreement with the corresponding N3LO value derived from essentially the Z width in the global electroweak ﬁt. The αS(MZ2 ) determination from τ decays is the most precise one to date.\n",
      "\n",
      "---\n",
      "\n",
      "# Tau Decays and αs\n",
      "\n",
      "The evolution of the determination of the strong coupling constant αs from the leptonic branching ratios, the life-time, and the invariant mass distributions of the hadronic final state of the τ lepton over the last two decades is briefly reviewed. The improvements in the latest ALEPH update are described in some detail. Currently this is one of the most precise αs determinations. Together with the other determination at the Z boson mass pole, they constitutes the most accurate test of the asymptotic freedom in QCD.\n",
      "\n",
      "---\n",
      "\n",
      "# The strong coupling from the revised ALEPH data for hadronic $\\tau$ decays\n",
      "\n",
      "We apply an analysis method previously developed for the extraction of the strong coupling from the OPAL data to the recently revised ALEPH data for non-strange hadronic $\\tau$ decays. Our analysis yields the values $\\alpha_s(m_\\tau^2)=0.296\\pm 0.010$ using fixed-order perturbation theory, and $\\alpha_s(m_\\tau^2)=0.310\\pm 0.014$ using contour-improved perturbation theory. Averaging these values with our previously obtained values from the OPAL data, we find $\\alpha_s(m_\\tau^2)=0.303\\pm 0.009$, respectively, $\\alpha_s(m_\\tau^2)=0.319\\pm 0.012$. We present a critique of the analysis method employed previously, for example in analyses by the ALEPH and OPAL collaborations, and compare it with our own approach. Our conclusion is that non-perturbative effects limit the accuracy with which the strong coupling, an inherently perturbative quantity, can be extracted at energies as low as the $\\tau$ mass. Our results further indicate that systematic errors on the determination of the strong coupling from analyses of hadronic $\\tau$-decay data have been underestimated in much of the existing literature.\n",
      "\n",
      "---\n",
      "\n",
      "# αs from the updated ALEPH data for hadronic τ decays\n",
      "\n",
      "We extract the strong coupling αs(mτ2) from the recently updated ALEPH non-strange spectral functions obtained from hadronic τ decays. We apply a self-consistent analysis method, first tested in the analysis of OPAL data, to extract αs(mτ2) and non-perturbative contributions. The analysis yields αsFO(mτ2)=0.296±0.010, using Fixed Order Perturbation Theory (FOPT), and αsCI(mτ2)=0.310±0.014, using Contour Improved Perturbation Theory (CIPT). The weighted average of these results with those previously obtained from OPAL data give αsFO(mτ2)=0.303±0.009 and αsCI(mτ2)=0.319±0.012, which gives, after evolution to the Z boson mass scale, αsFO(mZ2)=0.1165±0.0012 and αsCI(mZ2)=0.1185±0.0015, respectively. We observe that non-perturbative effects limit the accuracy with which αs can be extracted from τ decay data.\n",
      "\n",
      "---\n",
      "\n",
      "# Strong coupling from ${e}^{+}{e}^{\\ensuremath{-}}\\ensuremath{\\rightarrow}\\mathrm{hadrons}$ below charm\n",
      "\n",
      "We use a new compilation of the hadronic R-ratio from available data for the process e+e−→hadrons to determine the strong coupling, αs. We make use of all data for the R-ratio from threshold to a center-of-mass energy of 2 GeV by employing finite-energy sum rules. Data above 2 GeV, for which at present far fewer high-precision experimental data are available, do not provide much additional constraint but are fully consistent with the values for αs we obtain. Quoting our results at the τ mass to facilitate comparison to the results obtained from analogous analyses of hadronic τ-decay data, we find αs(m2τ)=0.298±0.016±0.006 in fixed-order perturbation theory, and αs(m2τ)=0.304±0.018±0.006 in contour-improved perturbation theory, where the first error is statistical, and the second error reflects our estimate of various systematic effects. These values are in good agreement with a recent determination from the OPAL and ALEPH data for hadronic τ decays.\n",
      "\n",
      "---\n",
      "\n",
      "# Version 3 of {\\tt RunDec} and {\\tt CRunDec}\n",
      "\n",
      "We present new versions of the packages {\\tt RunDec} and {\\tt CRunDec} which can be used for the running and decoupling of the strong coupling constant and quark masses. Furthermore several conversion formulae for heavy quark masses are implemented. The new versions include five-loop corrections of the QCD beta function and four-loop decoupling effects. Furthermore, various relations between the heavy quark mass defined in the $\\overline{\\rm MS}$ and other short-distance schemes are implemented to next-to-next-to-next-to-leading order. We discuss in detail the improvements and provide several examples which show how {\\tt RunDec} and {\\tt CRunDec} can be used in frequently occurring situations.\n",
      "\n",
      "---\n",
      "\n",
      "# Higher-order QCD corrections to hadronic τ decays from Padé approximants\n",
      "\n",
      "Perturbative QCD corrections to hadronic τ decays and e+e− annihilation into hadrons below charm are obtained from the Adler function, which at present is known in the chiral limit to ﬁve-loop accuracy. Extractions of the strong coupling, αs, from these processes suﬀer from an ambiguity related to the treatment of unknown higher orders in the perturbative series. In this work, we exploit the method of Pad´e approximants and its convergence theorems to extract information about higher-order corrections to the Adler function in a systematic way. First, the method is tested in the large-β0 limit of QCD, where the perturbative series is known to all orders. We devise strategies to accelerate the convergence of the method employing renormalization scheme variations and the so-called D-log Pad´e approximants. The success of these strategies can be understood in terms of the analytic structure of the series in the Borel plane. We then apply the method to full QCD and obtain reliable model-independent predictions for the higher-order coeﬃcients of the Adler function. For the six-, seven-, and eight-loop coeﬃcients we ﬁnd c5,1 = 277 ± 51, c6,1 = 3460±690, and c7,1 = (2.02±0.72)×104, respectively, with errors to be understood as lower and upper bounds. Our model-independent reconstruction of the perturbative QCD corrections to the τ hadronic width strongly favours the use of ﬁxed-order perturbation theory (FOPT) for the renormalization-scale setting.\n",
      "\n",
      "---\n",
      "\n",
      "# Precise αs determination from charmonium sum rules\n",
      "\n",
      "The strong coupling, αs, governs perturbative Quantum Chromodynamics (QCD) and is one of the free parameters of the Standard Model. We introduce a new method that allows a precise extraction of αs(mZ) from dimensionless ratios of roots of moments of the charm-quark vector correlator. The ratios we use in our analysis have a rather weak logarithmic quark-mass dependence, starting at O(αs2), and can be obtained from experimental data with good precision, since they benefit from positive correlations among the individual experimentally determined moments. We perform a careful and conservative error analysis with special emphasis on uncertainties related to the truncation of perturbation theory, treating the renormalization scales such as to ensure order-by-order convergence. Our final result, with expressions at O(αs3), is αs(mZ)=0.1168±0.0019.\n",
      "\n",
      "---\n",
      "\n",
      "# The strong coupling from an improved $\\tau$ vector isovector spectral function\n",
      "\n",
      "We combine ALEPH and OPAL results for the spectral distributions measured in $\\tau\\to\\pi^-\\pi^0\\nu_\\tau$, $\\tau\\to 2\\pi^-\\pi^+\\pi^0\\nu_\\tau$ and $\\tau\\to\\pi^-3\\pi^0\\nu_\\tau$ decays with (i) recent BaBar results for the analogous $\\tau\\to K^- K^0\\nu_\\tau$ distribution and (ii) estimates of the contributions from other hadronic $\\tau$-decay modes obtained using CVC and electroproduction data, to obtain a new and more precise non-strange, inclusive vector, isovector spectral function. The BaBar $K^- K^0$ and CVC/electroproduction results provide us with alternate, entirely data-based input for the contributions of all exclusive modes for which ALEPH and OPAL employed Monte-Carlo-based estimates. We use the resulting spectral function to determine $\\alpha_s(m_\\tau)$, the strong coupling at the $\\tau$ mass scale, employing finite energy sum rules. Using the fixed-order perturbation theory (FOPT) prescription, we find $\\alpha_s(m_\\tau)=0.3077\\pm 0.0075$, which corresponds to the five-flavor result $\\alpha_s(M_Z)=0.1171\\pm 0.0010$ at the $Z$ mass. While we also provide an estimate using contour-improved perturbation theory (CIPT), we point out that the FOPT prescription is to be preferred for comparison with other $\\alpha_s$ determinations employing the $\\overline{{\\rm MS}}$ scheme, especially given the inconsistency between CIPT and the standard operator product expansion recently pointed out in the literature. Additional experimental input on the dominant $2\\pi$ and $4\\pi$ modes would allow for further improvements to the current analysis.\n",
      "\n",
      "---\n",
      "\n",
      "# TAUOLA update for decay channels with e+e− pairs in the final state\n",
      "\n",
      "With the arrival of high luminosity B-factories like the Belle II experiment, τ decay measurements have become more precise than ever, allowing rarer processes to be explored, and finer details of τ decays to be studied. These are important to understand the spectrum of intermediate particles produced in τ decays. Therefore Monte Carlo generators, like the TAUOLA program, have to facilitate precision analysis as well as confront new models that constantly emerge with the availability of high statistics experimental data. New decay channels and models may lead to large variation of matrix elements size within the available phase space, as in the case when e+e− pairs are present in final state. It requires appropriate presampler of the phase space generator and a proper documentation to help users introduce their own models. While releasing a new update, it is important for the TAUOLA Monte Carlo library to maintain the general structure of the previous versions to preserve backward compatibility. The aim is to minimize changes from the user perspective. This paper presents a demonstration of new models implementation facilitated by the current update.\n",
      "Program summary\n",
      "Program Title: tauola-bbb CPC Library link to program files: https://doi.org/10.17632/3hyw3f7v32.1 Licensing provisions: GPLv2 Programming language: FORTRAN/C++ Journal reference of previous version: Comput. Phys. Comm., 232:220–236, 2018 Does the new version supersede the previous version?: No Reasons for the new version: Meeting the needs of present day experiments. Summary of revisions: Phase space presamplers enriched with the possibility to generate narrow peaks of e+e− pairs, if present in matrix elements of 4- and 5-body decay channels and due to electromagnetic or New Physics interactions. The examples of physical models are implemented for: τ−→π−e−e+ντ, τ−→ν¯μμ−e−e+ντ and τ−→ν¯ee−e−e+ντ channels, which are used for the collected new algorithm validations. Nature of problem: Present day experiments, in particular Belle II, have the capability to measure extremely rare, not yet measured τ decays, as well as precise measurements of known decay channels. They require a Monte Carlo generator capable of generating all desired decays. They also need the possibility to modify and test new models for such decays. At the same time the default initialization of the event generator should contain decent modeling of known τ decays. Solution method: The new version supplements previous publications on TAUOLA. Phase-space presamplers and new decay channels with additional light lepton pairs are introduced. Additional comments including restrictions and unusual features: TAR BALL of the future versions of the program may become available through:http://wasm.web.cern.ch/wasm/Welcome.html; its sub-pages http://tauolapp.web.cern.ch/tauolapp/ or http://wasm.web.cern.ch/wasm/f77.html\n",
      "\n",
      "---\n",
      "\n",
      "# The Euclidean Adler Function and its Interplay with $\\Delta\\alpha^{\\mathrm{had}}_{\\mathrm{QED}}$ and $\\alpha_s$\n",
      "\n",
      "Three diﬀerent approaches to precisely describe the Adler function in the Euclidean regime at around 2 GeVs are available: dispersion relations based on the hadronic production data in e+e− annihilation, lattice simulations and perturbative QCD (pQCD). We make a comprehensive study of the perturbative approach, supplemented with the leading power corrections in the operator product expansion. All known contributions are included, with a careful assessment of uncertainties. The pQCD predictions are compared with the Adler functions extracted from ∆αQhaEdD(Q2), using both the DHMZ compilation of e+e− data and published lattice results. Taking as input the FLAG value of αs, the pQCD Adler function turns out to be in good agreement with the lattice data, while the dispersive results lie systematically below them. Finally, we explore the sensitivity to αs of the direct comparison between the data-driven, lattice and QCD Euclidean Adler functions. The precision with which the renormalisation group equation can be tested is also evaluated.\n",
      "\n",
      "---\n",
      "\n",
      "# Strong coupling from an improved $\\ensuremath{\\tau}$ vector isovector spectral function\n",
      "\n",
      "我们将 ALEPH 和 OPAL 结果结合起来，测量光谱分布τ→π−π0ντ,τ→2π−π+π0ντ和τ→π−3π0ντ衰减与 （i） 最近的 BABAR 结果为类似τ→K−K0ντ分布和（二）其他强子贡献的估计数τ-利用CVC和电产数据得到衰变模式，得到一种新的、更精确的非奇异、包容矢量、等向量谱函数。巴巴尔酒店 K−K0CVC/电生产结果为我们提供了替代的、完全基于数据的输入，用于ALEPH和OPAL采用基于蒙特卡洛的估计的所有排他模式的贡献。我们使用所得光谱函数来确定αs(mτ)，强耦合在τ质量尺度，采用有限能量和规则。使用固定阶扰动理论（FOPT）处方，我们发现αs(mτ)=0.3077±0.0075，对应于五味结果αs(MZ)=0.1171±0.0010在Z质量。虽然我们也使用轮廓改进的扰动理论（CIPT）提供了估计，但我们指出FOPT处方是与其他药物进行比较的首选。αs采用¯¯¯¯¯¯女士方案，特别是考虑到CIPT与标准运营商产品扩展之间的不一致，最近在文献中指出。关于显性2π和4π模式将允许进一步改进当前的分析。\n",
      "\n",
      "---\n",
      "\n",
      "# Perturbative corrections to power suppressed effects in semileptonic B decays\n",
      "\n",
      "We compute the O(αs) corrections to the Wilson coefficient of the chromomagnetic operator in inclusive semileptonic B decays. The results are employed to evaluate the complete $ {{{{\\alpha_s}\\Lambda_{\\mathrm{QCD}}^2}} \\left/ {{m_b^2}} \\right.} $correction to the semileptonic width and to the first moments of the lepton energy distribution.\n",
      "\n",
      "---\n",
      "\n",
      "# The three-loop relation between the MS<math><mtext>MS</mtext></math> and the pole quark masses\n",
      "\n",
      "The analytic relation between the MS and the pole quark masses is computed to O(αs3) in QCD. Using this exact result, the accuracy of the large β0 approximation is critically examined and the implications of the obtained relation for semileptonic B decays are discussed.\n",
      "\n",
      "---\n",
      "\n",
      "# Inclusive Semileptonic $b \\to c \\ell \\bar{\\nu}$ Decays to Order $1/m_b^5$\n",
      "\n",
      "Inclusive semileptonic $B\\to X_c \\ell\\bar{\\nu}$ decays can be described in the Heavy Quark Expansion (HQE) and allow for a precision determination of the CKM element $|V_{cb}|$. We calculate the terms of $1/m_b^5$ and derive a ``trace formula'' which allows for the computation of the decay rate and kinematic moments of the spectrum up to this order in the HQE. We focus specifically on the reparametrization invariant (RPI) dilepton invariant mass $q^2$ moments of the spectrum, which depend on a reduced set of HQE parameters. At this order, ``intrinsic charm'' (IC) contributions proportional to $1/(m_b^3m_c^2)$ enter, which are numerically expected to be sizeable. Using the ``lowest-lying state saturation ansatz'' (LLSA), we estimate the size of these contributions. Within this approximation, we observe a partial cancellation between the IC and the ``genuine'' $1/m_b^5$ contributions, resulting in a small overall contribution.\n",
      "\n",
      "---\n",
      "\n",
      "# NLO QCD Corrections to Inclusive $b \\rightarrow c \\ell \\bar{\\nu}$ Decay Spectra up to $1/m_Q^3$\n",
      "\n",
      "We present analytical results for higher order corrections to the decay spectra of inclusive semileptonic heavy hadron weak decays using the heavy quark expansion (HQE). We compute analytically the spectrum of the leptonic invariant mass for $B \\rightarrow X_c \\ell \\bar{\\nu}$ up to and including terms of order $1/m_Q^3$ within the HQE at next-to-leading order (NLO) in $\\alpha_s$. The full dependence of the differential rate on the mass of the final-state quark is taken into account. We discuss the implications of our results for the precision determination of the CKM matrix element $|V_{cb}|$.\n",
      "\n",
      "---\n",
      "\n",
      "# Kolya: an open-source package for inclusive semileptonic $B$ decays\n",
      "\n",
      "We introduce the code kolya, an open-source tool for phenomenological analyses of inclusive semileptonic $B$ meson decays. It contains a library to compute predictions for the total rate and various kinematic moments within the framework of the heavy quark expansion, utilizing the so-called kinetic scheme. The library currently includes power corrections up to $1/m_b^5$. All available QCD perturbative corrections are implemented via interpolation grids for fast numerical evaluation. We also include effects from new physics parameterised as Wilson coefficients of dimension-six operators in the weak effective theory below the electroweak scale. The library is interfaced to CRunDec for easy evaluation of the quark masses and strong coupling constant at different renormalization scales. The library is developed in Python and does not require compilation. It can be used in an interactive Jupyter notebook session.\n",
      "\n",
      "---\n",
      "\n",
      "# Moments of the electron energy spectrum and partial branching fraction of $B\\ensuremath{\\rightarrow}{X}_{c}e\\ensuremath{\\nu}$ decays at the Belle detector\n",
      "\n",
      "We report a measurement of the inclusive electron energy spectrum for charmed semileptonic decays of B mesons in a 140 fb−1 data sample collected at the Υ(4S) resonance with the Belle detector at the KEKB asymmetric energy e+e− collider. We determine the first four moments of the electron energy spectrum for threshold values of the electron energy between 0.4 and 2.0 GeV. In addition, we provide values of the partial branching fraction (zeroth moment) for the same electron threshold energies, and independent measurements of the B+ and B0 partial branching fractions at 0.4 GeV and 0.6 GeV electron threshold energies. We measure the independent B+ and B0 partial branching fractions with electron threshold energies of 0.4 GeV to be ΔB(B+→Xceν)=(10.79±0.25(stat.)±0.27(sys.))% and ΔB(B0→Xceν)=(10.08±0.30(stat.)±0.22(sys.))%. Full correlations between all measurements are evaluated.\n",
      "\n",
      "---\n",
      "\n",
      "# Measurement of the inclusive semileptonic $B$ meson branching fraction in 62.8 fb$^{-1}$ of Belle II data\n",
      "\n",
      "We report a measurement of the branching fraction of inclusive semileptonic $B$ meson decays $B\\to X_c\\ell\\nu\\ell$ in $\\Upsilon(4S)\\to B\\bar B$~data recorded by the Belle II experiment at the SuperKEKB asymmetric-energy $e^+e^-$ collider and corresponding to 62.8 fb$^{-1}$ of integrated luminosity. Only a charged lepton (electon or muon) is reconstructed and the signal yield is determined from a fit to the lepton momentum distribution in the center-of-mass frame of the colliding beams. Averaging the result in the electron and muon channels, we find ${\\cal B}(B\\to X_c\\ell\\nu_\\ell) = (9.75\\pm 0.03(\\text{stat})\\pm 0.47(\\text{sys}))\\%$.\n",
      "\n",
      "---\n",
      "\n",
      "# Measurement and interpretation of moments in inclusive semileptonic decays $\\overline{B}\\ensuremath{\\rightarrow}{X}_{c}{\\ensuremath{\\ell}}^{\\ensuremath{-}}\\overline{\\ensuremath{\\nu}}$\n",
      "\n",
      "We present results for the moments of observed spectra in inclusive semileptonic B-meson decays to charm hadrons ¯¯¯B→Xcℓ−¯ν. Moments of the hadronic-mass and the combined mass-and-energy spectra for different minimum electron or muon momenta between 0.8 and 1.9 GeV/c are obtained from a sample of 232×106 Υ(4S)→B¯¯¯B events, collected with the BABAR detector at the PEP-II asymmetric-energy B-meson factory at SLAC. We also present a reevaluation of the moments of electron-energy spectra and partial decay fractions B(¯¯¯B→Xce−¯ν) for minimum electron momenta between 0.6 and 1.5 GeV/c based on a sample of 51×106 Υ(4S)→B¯¯¯B events. The measurements are used for the extraction of the total decay fraction, the Cabibbo-Kobayashi-Maskawa (CKM) matrix element |Vcb|, the quark masses mb and mc, and four heavy-quark QCD parameters in the framework of a Heavy-Quark Expansion (HQE). We find B(¯¯¯B→Xcℓ−¯ν)=(10.64±0.17±0.06)% and |Vcb|=(42.05±0.45±0.70)×10−3.\n",
      "\n",
      "---\n",
      "\n",
      "# Three loop calculations and inclusive Vcb\n",
      "\n",
      "We discuss the impact of the recent O(αs3) calculations of the semileptonic width of the b quark and of the relation between pole and kinetic heavy quark masses by Fael et al. on the inclusive determination of |Vcb|. The most notable effect is a reduction of the uncertainty. Our final result is |Vcb|=42.16(51)10−3.\n",
      "\n",
      "---\n",
      "\n",
      "# Vcb determination from inclusive b → c decays: an alternative method\n",
      "\n",
      "The determination of Vcb relies on the Heavy-Quark Expansion and the extraction of the non-perturbative matrix elements from inclusive b → c decays. The proliferation of these matrix elements complicates their extraction at 1/m4b and higher, thereby limiting the Vcb extraction. Reparametrization invariance links diﬀerent operators in the HeavyQuark expansion thus reducing the number of independent operators at 1/m4b to eight for the total rate. We show that this reduction also holds for spectral moments as long as they are deﬁned by reparametrization invariant weight-functions. This is valid in particular for the leptonic invariant mass spectrum (q2), i.e. the diﬀerential rate and its moments. Currently, Vcb is determined by ﬁtting the energy and hadronic mass moments, which do not manifest this parameter reduction and depend on the full set of 13 matrix elements up to 1/m4b . In light of this, we propose an experimental analysis of the q2 moments to open the possibility of a model-independent Vcb extraction from semileptonic decays including the 1/m4b terms in a fully data-driven way.\n",
      "\n",
      "---\n",
      "\n",
      "# Fit to moments of inclusive $B\\ensuremath{\\rightarrow}{X}_{c}\\ensuremath{\\ell}\\overline{\\ensuremath{\\nu}}$ and $B\\ensuremath{\\rightarrow}{X}_{s}\\ensuremath{\\gamma}$ decay distributions using heavy quark expansions in the kinetic scheme\n",
      "\n",
      "We present a fit to measured moments of inclusive distributions in 𝐵→𝑋𝑐⁢ℓ⁢‾𝜈 and 𝐵→𝑋𝑠⁢𝛾 decays to extract values for the Cabibbo-Kobayashi-Maskawa (CKM) matrix element |𝑉𝑐⁢𝑏|, the 𝑏- and 𝑐-quark masses, and higher-order parameters that appear in the heavy quark expansion. The fit is carried out using theoretical calculations in the kinetic scheme and includes moment measurements of the BABAR, Belle, CDF, CLEO, and DELPHI collaborations for which correlation matrices have been published. We find |𝑉𝑐⁢𝑏|=(41.96±0.23exp ±0.35HQE±0.59𝛤SL)×10−3 and 𝑚𝑏=4.590±0.025exp ±0.030HQE GeV where the errors are experimental and theoretical respectively. We also derive values for the heavy quark distribution function parameters 𝑚𝑏 and 𝜇2𝜋 in different theoretical schemes that can be used as input for the determination of |𝑉𝑢⁢𝑏|.\n",
      "\n",
      "---\n",
      "\n",
      "# Kinetic Heavy Quark Mass to Three Loops\n",
      "\n",
      "We compute three-loop corrections to the relation between the heavy quark masses defined in the pole and kinetic schemes. Using known relations between the pole and ‾MS quark masses, we can establish precise relations between the kinetic and ‾MS charm and bottom masses. As compared to two loops, the precision is improved by a factor of 2 to 3. Our results constitute important ingredients for the precise determination of the Cabibbo–Kobayashi–Maskawa matrix element |𝑉𝑐⁢𝑏| at Belle II.\n",
      "\n",
      "---\n",
      "\n",
      "# Inclusive $$B\\rightarrow X_c \\ell {\\bar{\\nu }}_\\ell$$and $$B\\rightarrow X_u \\ell {\\bar{\\nu }}_\\ell$$decays: current status and future prospects\n",
      "\n",
      "The inclusive semileptonic $$B\\rightarrow X_c \\ell {\\bar{\\nu }}_\\ell$$and $$B\\rightarrow X_u \\ell {\\bar{\\nu }}_\\ell$$decays allow for the extraction of the CKM elements $$|V_{cb}|$$and $$|V_{ub}|$$, respectively. These extractions are based on the Heavy-Quark Expansion, where recent progress on both the experimental and theoretical side allow for impressively precise results. We review the recent developments in the study of inclusive decays and give an outlook for the future.\n",
      "\n",
      "---\n",
      "\n",
      "# Semileptonic decays in the limit of a heavy daughter quark\n",
      "\n",
      "The rate of the semileptonic decay b→cℓν is calculated with O(α2s) accuracy, as an expansion around the limit of equal masses of the b and c quarks. Recent results obtained around the limit of the c-quark much lighter than b are confirmed. Details of the new expansion method are described.\n",
      "\n",
      "---\n",
      "\n",
      "# Inclusive semileptonic B decays and |Vcb|: In memoriam Kolya Uraltsev\n",
      "\n",
      "Publishes important review articles and original articles on the subject of Particles and Fields (High-Energy Physics) and topics intersecting with Gravitation and Cosmology.\n",
      "\n",
      "---\n",
      "\n",
      "# Measurement of the inclusive semileptonic branching fraction of B mesons and |Vcb|\n",
      "\n",
      "We present a measurement of the electron spectrum from inclusive semileptonic B decay, using 5.1 fb−1 of ϒ(4S) data collected with the Belle detector. A high-momentum lepton tag was used to separate the semileptonic B decay electrons from secondary decay electrons. We obtained the branching fraction, B(B→Xe+ν)=(10.90±0.12±0.49)%, with minimal model dependence. From this measurement, we derive a value for the Cabibbo–Kobayashi–Maskawa matrix element |Vcb|=0.0408±0.0010(exp)±0.0025(th).\n",
      "\n",
      "---\n",
      "\n",
      "# High power $n$ of ${m}_{b}$ in $b$-flavored widths and $n=5\\ensuremath{\\rightarrow}\\mathbf{\\ensuremath{\\infty}}$ limit\n",
      "\n",
      "The leading term in the semileptonic width of heavy flavor hadrons depends on the fifth power of the heavy quark mass. We present an analysis where this power can be self-consistently treated as a free parameter 𝑛 and the width can be studied in the limit 𝑛→∞. The resulting expansion elucidates why the small velocity (SV) treatment is relevant for the inclusive semileptonic 𝑏→𝑐 transition. The extended SV limit (ESV limit) is introduced. The leading terms in the perturbative 𝛼𝑠 expansion enhanced by powers of 𝑛 are automatically resummed by using the low-scale Euclidean mass. The large-𝑛 treatment explains why the scales of order 𝑚𝑏/𝑛 are appropriate. On the other hand, the scale cannot be too small since the factorially divergent perturbative corrections associated with running of 𝛼𝑠 show up. Both requirements are met if we use the short-distance mass normalized at a scale around 𝑚𝑏/𝑛∼1⁢GeV. A convenient definition of such low-scale operator-product-expansion-compatible masses is briefly discussed.\n",
      "\n",
      "---\n",
      "\n",
      "# PERTURBATIVE CORRECTIONS TO THE SEMILEPTONIC b-DECAY MOMENTS: $E<sup>ℓ</sup>_cut$ DEPENDENCE AND RUNNING-αs EFFECTS IN THE OPE APPROACH\n",
      "\n",
      "We have calculated the perturbative corrections to all the structure functions in the semileptonic decays of a heavy quark. Assuming an arbitrary gluon mass as a technical tool allowed to obtain in parallel all the BLM corrections. We report the basic applications, viz. perturbative corrections to the hadronic mass and energy moments with full dependence on the charge lepton energy cut. In the adopted scheme with the OPE momentum scale separation around 1 GeV the perturbative corrections to $⟨M²_X⟩$ are small and practically independent of Ecut; the BLM corrections are small, too. The corrections to the second mass squared moment show some decrease with Ecut consistent with the effect of the Darwin operator, within the previously estimated theoretical uncertainty. Perturbative corrections in the pole-type schemes appear significant and vary with Eℓ, decreasing the moments at higher cuts. The hardness of hadronic moments is quantitatively illustrated for different cuts on Eℓ.\n",
      "\n",
      "---\n",
      "\n",
      "# Hadronic spectral moments in semileptonic $B$ decays with a lepton energy cut\n",
      "\n",
      "We compute the first two moments 〈(𝑠𝐻−𝑚2𝐷)1,2〉 of the final hadronic invariant mass in the inclusive decay →𝐵⁢𝑋𝑐⁢𝓁⁢¯𝜈, in the presence of a cut 𝐸min𝓁 on the charged lepton energy. These moments may be measured directly by experiments at the 𝛶⁡(4⁢𝑆) using the neutrino reconstruction technique, which requires such a cut. Measurement of these moments will place constraints on the nonperturbative parameters ¯𝛬 and 𝜆1, which are relevant for extracting the quark masses 𝑚𝑏 and 𝑚𝑐, as well as the CKM angle 𝑉cb. We include terms of order 𝛼2𝑠⁢𝛽0 and 1/𝑚3𝑏 in the operator product expansion, and use the latter to estimate the theoretical uncertainty in the extraction of ¯𝛬 and 𝜆1.\n",
      "\n",
      "---\n",
      "\n",
      "# Measurement of Lepton Mass Squared Moments in $B \\to X_c \\ell \\bar \\nu_{\\ell}$ Decays with the Belle II Experiment\n",
      "\n",
      "We present measurements of the first to fourth moments of the lepton mass squared $q^2$ of \\mbox{$B \\to X_c \\, \\ell\\, \\bar \\nu_{\\ell}$} decays for $\\ell = e, \\mu$ and with $X_c$ a hadronic system containing a charm quark. These results use a sample of electron-positron collisions at the $\\Upsilon(4S)$ resonance corresponding to $62.8 \\, \\mathrm{fb}^{-1}$ of integrated luminosity and collected by the Belle II experiment in 2019 and 2020. To identify the $X_c$ system and reconstruct $q^2$, one of the $B$ mesons from an $\\Upsilon(4S) \\to B \\kern 0.18em\\overline{\\kern -0.18em B}$ decay is fully reconstructed in a hadronic decay mode using a multivariate $B$ tagging algorithm. We report raw and central moments for $ q^2 > 1.5 \\; \\mathrm{GeV^2/c^4}$ up to $q^2 > 8.5 \\; \\mathrm{GeV^2/c^4}$, probing up to 77\\% of the accessible \\mbox{$B \\to X_c \\, \\ell\\, \\bar \\nu_{\\ell}$} phase space. This is the first measurement of moments in the experimentally challenging range of $[ 1.5, 2.5 ] \\, \\mathrm{GeV^2/c^4}$.\n",
      "\n",
      "---\n",
      "\n",
      "# $B$ decay shape variables and the precision determination of $|{V}_{\\mathrm{cb}}|$ and ${m}_{b}$\n",
      "\n",
      "We present expressions for shape variables of B decay distributions in several different mass schemes, to order 𝛼2𝑠⁢𝛽0 and 𝛬3QCD⁢/𝑚3𝑏. Such observables are sensitive to the b quark mass and matrix elements in the heavy quark effective theory, and recent measurements allow precision determinations of some of these parameters. We perform a combined fit to recent experimental results from CLEO, BABAR, and DELPHI, and discuss the theoretical uncertainties due to nonperturbative and perturbative effects. We discuss the possible discrepancy between the OPE prediction, recent BABAR results and the measured branching fraction to D and 𝐷* states. We find |𝑉cb|=(40.8±0.9)×10−3 and 𝑚1⁢𝑆𝑏=4.74±0.10⁢GeV, where the errors are dominated by experimental uncertainties.\n",
      "\n",
      "---\n",
      "\n",
      "# NNLO QCD corrections to the q2 spectrum of inclusive semileptonic B-meson decays\n",
      "\n",
      "We calculate the next-to-next-to-leading order QCD corrections to the leptonic invariant mass (q2) spectrum of semileptonic b → c inclusive decays, taking into account the mass of the charm quark and the charged lepton in the final state. We obtain analytic results in terms of generalized polylogarithms and present numerical studies of the $$ \\mathcal{O} $$($$ {\\alpha}_s^2 $$) corrections to the q2 spectrum of b → $$ c\\ell {\\overline{\\nu}}_{\\ell } $$decays, for ℓ = e, μ and τ, in the kinetic scheme. Our computation can be used to incorporate the recent measurements of q2 moments by Belle and Belle II into global fits of inclusive semileptonic B-decays.\n",
      "\n",
      "---\n",
      "\n",
      "# Moments of semileptonic B decay distributionsin the 1/m b expansion\n",
      "\n",
      "We report the OPE-based predictions for a number of lepton energy and hadronic mass moments in the inclusive semileptonic B → Xc ν decays with a lower cut on the charged lepton energy. We rely on the direct OPE approach where no expansion in the charm mass is employed and the theoretical input is a limited set of underlying OPE parameters including mb and mc. A Wilsonian treatment with a “hard” cutoﬀ is applied using running low-scale masses mQ(µ) and a kinetic expectation value µ2π(µ). This leaves for perturbative corrections only genuinely short-distance eﬀects and makes them numerically small. Predictions are also given for the modiﬁed hadronic moments of the kinematic variable NX2 which is a combination of MX2 and EX . The measurement of such moments would allow a more reliable extraction to be made of higher-order non-perturbative heavy quark parameters from experiment.\n",
      "\n",
      "---\n",
      "\n",
      "# Imprecated, yet impeccable: on the theoretical evaluation of Γ(B→Xcℓν)<math><mtext>Γ(B→X</mtext><msub><mi></mi><mn>c</mn></msub><mspace xmlns=\"true\" sp=\"0.2\" width=\"2px\" linebreak=\"nobreak\" is=\"true\"></mspace><mtext>ℓν)</mtext></math>\n",
      "\n",
      "We present a detailed evaluation of the total semileptonic B meson width in terms of |Vcb| and heavy quark parameters (quark masses and the expectation values of local heavy quark operators). Special attention is given to perturbative corrections which can precisely be calculated in a scheme with a hard Wilsonian cutoff at a scale around 1 GeV appropriate for the OPE, and to the potential impact of higher-order power corrections. We point out that the latter require control over possible contributions from four-quark operators containing charm quark fields. Analytical expressions are given which allow evaluating the width with various choices of parameters; ready-to-use expressions showing the dependence on the heavy quark parameters are presented as well. We illustrate these results by commenting on how these parameters can be extracted and what accuracy is likely to be achievable in the near future.\n",
      "\n",
      "---\n",
      "\n",
      "# Third order corrections to the semileptonic $b\\ensuremath{\\rightarrow}c$ and the muon decays\n",
      "\n",
      "We compute corrections of order α3s to the decay b→cℓ¯ν taking into account massive charm quarks. In the on-shell scheme large three-loop corrections are found. However, in the kinetic scheme the three-loop corrections are below 1% and thus perturbation theory is well under control. We furthermore provide results for the order α3s corrections to b→uℓ¯ν and the third-order QED corrections to the muon decay which will be important input for reducing the uncertainty of the Fermi coupling constant GF.\n",
      "\n",
      "---\n",
      "\n",
      "# Improved particle-flow event reconstruction with scalable neural networks for current and future particle detectors\n",
      "\n",
      "Efficient and accurate algorithms are necessary to reconstruct particles in the highly granular detectors anticipated at the High-Luminosity Large Hadron Collider and the Future Circular Collider. We study scalable machine learning models for event reconstruction in electron-positron collisions based on a full detector simulation. Particle-flow reconstruction can be formulated as a supervised learning task using tracks and calorimeter clusters. We compare a graph neural network and kernel-based transformer and demonstrate that we can avoid quadratic operations while achieving realistic reconstruction. We show that hyperparameter tuning significantly improves the performance of the models. The best graph neural network model shows improvement in the jet transverse momentum resolution by up to 50% compared to the rule-based algorithm. The resulting model is portable across Nvidia, AMD and Habana hardware. Accurate and fast machine-learning based reconstruction can significantly improve future measurements at colliders.\n",
      "\n",
      "---\n",
      "\n",
      "# Precise αs determination from charmonium sum rules\n",
      "\n",
      "The strong coupling, αs, governs perturbative Quantum Chromodynamics (QCD) and is one of the free parameters of the Standard Model. We introduce a new…\n",
      "\n",
      "---\n",
      "\n",
      "# αs and |Vcs| determination, and CKM unitarity test, from W decays at NNLO\n",
      "\n",
      "The hadronic (ΓhadW) and total (ΓtotW) widths of the W boson, computed at least at next-to-next-to-leading-order (NNLO) accuracy, are combined to deri…\n",
      "\n",
      "---\n",
      "\n",
      "# Reliable Perturbative Results for Strong Interactions?\n",
      "\n",
      "An explicit calculation shows perturbation theory to be arbitrarily good for the deep Euclidean Green's functions of any Yang-Mills theory and of many Yang-Mills theories with fermions. Under the hypothesis that spontaneous symmetry breakdown is of dynamical origin, these symmetric Green's functions are the asymptotic forms of the physically significant spontaneously broken solution, whose coupling could be strong., This article appears in the following collection:\n",
      "\n",
      "---\n",
      "\n",
      "# Ultraviolet Behavior of Non-Abelian Gauge Theories\n",
      "\n",
      "It is shown that a wide class of non-Abelian gauge theories have, up to calculable logarithmic corrections, free-field-theory asymptotic behavior. It is suggested that Bjorken scaling may be obtained from strong-interaction dynamics based on non-Abelian gauge symmetry., This article appears in the following collection:\n",
      "\n",
      "---\n",
      "\n",
      "# Asymptotically Free Gauge Theories. I\n",
      "\n",
      "Asymptotically free gauge theories of the strong interactions are constructed and analyzed. The reasons for doing this are recounted, including a review of renormalization-group techniques and their application to scaling phenomena. The renormalization-group equations are derived for Yang-Mills theories. The parameters that enter into the equations are calculated to lowest order and it is shown that these theories are asymptotically free. More specifically the effective coupling constant, which determines the ultraviolet behavior of the theory, vanishes for large spacelike momenta. Fermions are incorporated and the construction of realistic models is discussed. We propose that the strong interactions be mediated by a \"color\" gauge group which commutes with SU(3) × SU(3). The problem of symmetry breaking is discussed. It appears likely that this would have a dynamical origin. It is suggested that the gauge symmetry might not be broken and that the severe infrared singularities prevent the occurrence of noncolor singlet physical states. The deep-inelastic structure functions, as well as the electron-positron total annihilation cross section are analyzed. Scaling obtains up to calculable logarithmic corrections, and the naive light-cone or parton-model results follow. The problems of incorporating scalar mesons and breaking the symmetry by the Higgs mechanism are explained in detail.\n",
      "\n",
      "---\n",
      "\n",
      "# Three-Triplet Model with Double $\\mathrm{SU}(3)$ Symmetry\n",
      "\n",
      "With a view to avoiding some of the kinematical and dynamical difficulties involved in the single-triplet quark model, a model for the low-lying baryons and mesons based on three triplets with integral charges is proposed, somewhat similar to the two-triplet model introduced earlier by one of us (Y. N.). It is shown that in a 𝑈⁡(3) scheme of triplets with integral charges, one is naturally led to three triplets located symmetrically about the origin of 𝐼3−𝑌 diagram under the constraint that the Nishijima-Gell-Mann relation remains intact. A double SU⁡(3) symmetry scheme is proposed in which the large mass splittings between different representations are ascribed to one of the SU⁡(3), while the other SU⁡(3) is the usual one for the mass splittings within a representation of the first SU⁡(3).\n",
      "\n",
      "---\n",
      "\n",
      "# Symmetries of Baryons and Mesons\n",
      "\n",
      "The system of strongly interacting particles is discussed, with electromagnetism, weak interactions, and gravitation considered as perturbations. The electric current 𝑗𝛼, the weak current 𝐽𝛼, and the gravitational tensor 𝜃𝛼⁢𝛽 are all well-defined operators, with finite matrix elements obeying dispersion relations. To the extent that the dispersion relations for matrix elements of these operators between the vacuum and other states are highly convergent and dominated by contributions from intermediate one-meson states, we have relations like the Goldberger-Treiman formula and universality principles like that of Sakurai according to which the 𝜌 meson is coupled approximately to the isotopic spin. Homogeneous linear dispersion relations, even without subtractions, do not suffice to fix the scale of these matrix elements; in particular, for the nonconserved currents, the renormalization factors cannot be calculated, and the universality of strength of the weak interactions is undefined. More information than just the dispersion relations must be supplied, for example, by field-theoretic models; we consider, in fact, the equal-time commutation relations of the various parts of 𝑗4 and 𝐽4. These nonlinear relations define an algebraic system (or a group) that underlies the structure of baryons and mesons. It is suggested that the group is in fact 𝑈⁡(3)×𝑈⁡(3), exemplified by the symmetrical Sakata model. The Hamiltonian density 𝜃44 is not completely invariant under the group; the noninvariant part transforms according to a particular representation of the group; it is possible that this information also is given correctly by the symmetrical Sakata model. Various exact relations among form factors follow from the algebraic structure. In addition, it may be worthwhile to consider the approximate situation in which the strangeness-changing vector currents are conserved and the Hamiltonian is invariant under 𝑈⁡(3); we refer to this limiting case as \"unitary symmetry.\" In the limit, the baryons and mesons form degenerate supermultiplets, which break up into isotopic multiplets when the symmetry-breaking term in the Hamiltonian is \"turned on.\" The mesons are expected to form unitary singlets and octets; each octet breaks up into a triplet, a singlet, and a pair of strange doublets. The known pseudoscalar and vector mesons fit this pattern if there exists also an isotopic singlet pseudoscalar meson 𝜒0. If we consider unitary symmetry in the abstract rather than in connection with a field theory, then we find, as an attractive alternative to the Sakata model, the scheme of Ne'eman and Gell-Mann, which we call the \"eightfold way\"; the baryons 𝑁, 𝛬, 𝛴, and 𝛯 form an octet, like the vector and pseudoscalar meson octets, in the limit of unitary symmetry. Although the violations of unitary symmetry must be quite large, there is some hope of relating certain violations to others. As an example of the methods advocated, we present a rough calculation of the rate of in terms of that of .\n",
      "\n",
      "---\n",
      "\n",
      "# Reconstruction and classification of tau lepton decays with ILD\n",
      "\n",
      "Tau lepton decays with up to two $$\\pi ^0$$s in the final state – $$\\tau ^+ \\rightarrow \\pi ^+ \\bar{\\nu }_\\tau $$, $$\\rho ^+ (\\pi ^+\\pi ^0) \\bar{\\nu }_\\tau $$, and $$\\mathrm {a}_{1}^{+}(\\pi ^+\\pi ^0\\pi ^0) \\bar{\\nu }_\\tau $$– are used to study the performance of the barrel region of the silicon-tungsten electromagnetic calorimeter (Si-W ECAL) of the International Large Detector (ILD) at the future $$\\mathrm{e}^{+} \\mathrm{e}^{-} $$International Linear Collider. Correct reconstruction of the tau decay mode is crucial for constraining the spin state of tau lepton and measuring the Higgs boson CP state in $$\\mathrm{H}{}{} \\rightarrow \\tau ^+\\tau ^-$$decays. We find that about 95 % of $$\\pi ^+ \\bar{\\nu }_\\tau $$, and 90 % of $$\\rho ^+\\bar{\\nu }_\\tau $$and $$\\mathrm {a}_{1}^{+}\\bar{\\nu }_\\tau $$decays produced by the $$\\mathrm{e}^{+} \\mathrm{e}^{-} \\rightarrow {\\mathrm{Z}^{0}}^*\\rightarrow \\tau ^+\\tau ^-$$process at an $$e^\\pm $$beam energy of 125 GeV are correctly reconstructed. In a smaller ILD detector, with the inner Si-W ECAL radius reduced by about 20 %, these efficiencies are reduced by at most 2 %. The $$\\pi ^0$$mass resolution remains below 10 %. Since failures in tau lepton reconstruction are mainly due to photons, an increase of the ILD magnetic field from 3.5 to 4 T does not bring any significant improvement.\n",
      "\n",
      "---\n",
      "\n",
      "# WHIZARD—simulating multi-particle processes at LHC and ILC\n",
      "\n",
      "We describe the universal Monte-Carlo (parton-level) event generator WHIZARD (http://whizard.event-generator.org), version 2. The program automatically computes complete tree-level matrix elements, integrates them over phase space, evaluates distributions of observables, and generates unweighted partonic event samples. These are showered and hadronized by calling external codes, either automatically from within the program or via standard interfaces. There is no conceptual limit on the process complexity; using current hardware, the program has successfully been applied to hard scattering processes with up to eight particles in the final state. Matrix elements are computed as helicity amplitudes, so spin and color correlations are retained. For event generation, processes can be concatenated with full spin correlation, so factorized approximations to cascade decays are possible when complete matrix elements are not desired. The Standard Model, the MSSM, and many alternative models such as Little Higgs, anomalous couplings, or effects of extra dimensions or noncommutative SM extensions have been implemented. Using standard interfaces to parton shower and hadronization programs, WHIZARD covers physics at hadron, lepton, and photon colliders.\n",
      "\n",
      "---\n",
      "\n",
      "# Data Unfolding Methods in High Energy Physics\n",
      "\n",
      "A selection of unfolding methods commonly used in High Energy Physics is compared. The methods discussed here are: bin-by-bin correction factors, matrix inversion, template fit, Tikhonov regularisation and two examples of iterative methods. Two procedures to choose the strength of the regularisation are tested, namely the L-curve scan and a scan of global correlation coefficients. The advantages and disadvantages of the unfolding methods and choices of the regularisation strength are discussed using a toy example.\n",
      "\n",
      "---\n",
      "\n",
      "# FCC-ee: The Lepton Collider\n",
      "\n",
      "In response to the 2013 Update of the European Strategy for Particle Physics, the Future Circular Collider (FCC) study was launched, as an international collaboration hosted by CERN. This study covers a highest-luminosity high-energy lepton collider (FCC-ee) and an energy-frontier hadron collider (FCC-hh), which could, successively, be installed in the same 100 km tunnel. The scientific capabilities of the integrated FCC programme would serve the worldwide community throughout the 21st century. The FCC study also investigates an LHC energy upgrade, using FCC-hh technology. This document constitutes the second volume of the FCC Conceptual Design Report, devoted to the electron-positron collider FCC-ee. After summarizing the physics discovery opportunities, it presents the accelerator design, performance reach, a staged operation scenario, the underlying technologies, civil engineering, technical infrastructure, and an implementation plan. FCC-ee can be built with today’s technology. Most of the FCC-ee infrastructure could be reused for FCC-hh. Combining concepts from past and present lepton colliders and adding a few novel elements, the FCC-ee design promises outstandingly high luminosity. This will make the FCC-ee a unique precision instrument to study the heaviest known particles (Z, W and H bosons and the top quark), offering great direct and indirect sensitivity to new physics.\n",
      "\n",
      "---\n",
      "\n",
      "# Comparison of unfolding methods using RooFitUnfold\n",
      "\n",
      "In this paper we describe RooFitUnfold, an extension of the RooFit statistical software package to treat unfolding problems, and which includes most of the unfolding methods that commonly used in particle physics. The package provides a common interface to these algorithms as well as common uniform methods to evaluate their performance in terms of bias, variance and coverage. In this paper we exploit this common interface of RooFitUnfold to compare the performance of unfolding with the Richardson–Lucy, Iterative Dynamically Stabilized, Tikhonov, Gaussian Process, bin-by-bin and inversion methods on several example problems.\n",
      "\n",
      "---\n",
      "\n",
      "# Cross section measurements of the e+e− → D*+D*− and e+e− → D*+D− processes at center-of-mass energies from 4.085 to 4.600 GeV\n",
      "\n",
      "The Born cross sections of the e+e− → D*+D*− and e+e− → D*+D− processes are measured using e+e− collision data collected with the BESIII experiment at center-of-mass energies from 4.085 to 4.600 GeV, corresponding to an integrated luminosity of 15.7 fb−1. The results are consistent with and more precise than the previous measurements by the Belle, Babar and CLEO collaborations. The measurements are essential for understanding the nature of vector charmonium and charmonium-like states.\n",
      "\n",
      "---\n",
      "\n",
      "# Review of Particle Physics\n",
      "\n",
      "The Review summarizes much of particle physics and cosmology. Using data from previous editions, plus 2,143 new measurements from 709 papers, we list, evaluate, and average measured properties of gauge bosons and the recently discovered Higgs boson, leptons, quarks, mesons, and baryons. We summarize searches for hypothetical particles such as supersymmetric particles, heavy bosons, axions, dark photons, etc. Particle properties and search limits are listed in Summary Tables. We give numerous tables, figures, formulae, and reviews of topics such as Higgs Boson Physics, Supersymmetry, Grand Unified Theories, Neutrino Mixing, Dark Energy, Dark Matter, Cosmology, Particle Detectors, Colliders, Probability and Statistics. Among the 120 reviews are many that are new or heavily revised, including a new review on Machine Learning, and one on Spectroscopy of Light Meson Resonances.The Review is divided into two volumes. Volume 1 includes the Summary Tables and 97 review articles. Volume 2 consists of the Particle Listings and contains also 23 reviews that address specific aspects of the data presented in the Listings.The complete Review (both volumes) is published online on the website of the Particle Data Group (pdg.lbl.gov) and in a journal. Volume 1 is available in print as the PDG Book. A Particle Physics Booklet with the Summary Tables and essential tables, figures, and equations from selected review articles is available in print, as a web version optimized for use on phones, and as an Android app.\n",
      "\n",
      "---\n",
      "\n",
      "# Very High-Energy Collisions of Hadrons\n",
      "\n",
      "Proposals are made predicting the character of longitudinal-momentum distributions in hadron collisions of extreme energies.\n",
      "\n",
      "---\n",
      "\n",
      "# High-Energy Inelastic $e\\ensuremath{-}p$ Scattering at 6\\ifmmode^\\circ\\else\\textdegree\\fi{} and 10\\ifmmode^\\circ\\else\\textdegree\\fi{}\n",
      "\n",
      "Cross sections for inelastic scattering of electrons from hydrogen were measured for incident energies from 7 to 17 GeV at scattering angles of 6° to 10° covering a range of squared four-momentum transfers up to 7.4 (G⁢e⁢V/𝑐)2. For low center-of-mass energies of the final hadronic system the cross section shows prominent resonances at low momentum transfer and diminishes markedly at higher momentum transfer. For high excitations the cross section shows only a weak momentum-transfer dependence., This article appears in the following collection:\n",
      "\n",
      "---\n",
      "\n",
      "# Observed Behavior of Highly Inelastic Electron-Proton Scattering\n",
      "\n",
      "Results of electron-proton inelastic scattering at 6° and 10° are discussed, and values of the structure function 𝑊2 are estimated. If the interaction is dominated by transverse virtual photons, 𝜈⁢𝑊2 can be expressed as a function of 𝜔=2⁢𝑀⁢𝜈𝑞2 within experimental errors for 𝑞2>1 (G⁢e⁢V/𝑐)2 and 𝜔>4, where 𝜈 is the invariant energy transfer and 𝑞2 is the invariant momentum transfer of the electron. Various theoretical models and sum rules are briefly discussed., This article appears in the following collection:\n",
      "\n",
      "---\n",
      "\n",
      "# Electroweak fits at LEP\n",
      "\n",
      "High precision electroweak measurements performed over ten years at LEP and SLC have allowed to constrain the Standard Model of electroweak interactions. The model have been used to predict the mass of the top quark and to set limits on the mass of the Higgs boson.\n",
      "\n",
      "---\n",
      "\n",
      "# Pole mass renormalon and its ramifications\n",
      "\n",
      "I review the structure of the leading infrared renormalon divergence of the relation between the pole mass and the $$\\overline{\\mathrm{MS}}$$ mass of a heavy quark, with applications to the top, bottom and charm quark. That the pole quark mass definition must be abandoned in precision computations is a well-known consequence of the rapidly diverging series. The definitions and physics motivations of several leading renormalon-free, short-distance mass definitions suitable for processes involving nearly on-shell heavy quarks are discussed.\n",
      "\n",
      "---\n",
      "\n",
      "# Experimental observation of lepton pairs of invariant mass around 95 GeV/c2 at the CERN SPS collider\n",
      "\n",
      "We report the observation of four electron-positron pairs and one muon pair which have the signature of a two-body decay of a particle of mass ∼ 95 GeV/c2. These events fit well the hypothesis that they are produced by the process p̄ + p → Z0 + X (with Z0 → ℓ+ + ℓ−), where Z0 is the Intermediate Vector Boson postulated by the electroweak theories as the mediator of weak neutral currents.\n",
      "\n",
      "---\n",
      "\n",
      "# Evidence for Z0→e+e− at the CERN pp collider\n",
      "\n",
      "From a search for electron pairs produced in pp collisions at s = 550 GeV we report the observation of eight events which we interpret as resulting from the process p+p→Z0+ anything, followed by the decay Z0→e++e− or Z0→e++e−+γ, where Z0 is the neutral Intermediate Vector Boson postulated by the unified electroweak theory. We use four of these events to measure the Z0 mass MZ = 91.9 ± 1.3 ± 1.4 (systematic) GeV/c2.\n",
      "\n",
      "---\n",
      "\n",
      "# Observation of single isolated electrons of high transverse momentum in events with missing transverse energy at the CERN pp collider\n",
      "\n",
      "We report the results of a search for single isolated electrons of high transverse momentum at the CERN pp collider. Above 15 GeV/c, four events are found having large missing transverse energy along a direction opposite in azimuth to that of the high-pT electron. Both the configuration of the events and their number are consistent with the expectations from the process p+p→W±+anything, with W→e+ν, where W± is the charged Intermediate Vector Boso postulated by the unified electroweak theory.\n",
      "\n",
      "---\n",
      "\n",
      "# Experimental observation of isolated large transverse energy electrons with associated missing energy at s=540 GeV\n",
      "\n",
      "We report the results of two searches made on data recorded at the CERN SPS Proton-Antiproton Collider: one for isolated large-ET electrons, the other for large-ET neutrinos using the technique of missing transverse energy. Both searches converge to the same events, which have the signature of a two-body decay of a particle of mass ∼80 GeV/c2. The topology as well as the number of events fits well the hypothesis that they are produced by the proces p̄+p→W±+X, with W± →e±+ν; where W± is the Intermediate Vector Boson postulated by the unified theory of weak and electromagnetic inter- actions.\n",
      "\n",
      "---\n",
      "\n",
      "# Observation of Top Quark Production in $\\overline{\\mathit{p}}\\mathit{p}$ Collisions with the Collider Detector at Fermilab\n",
      "\n",
      "We establish the existence of the top quark using a 67⁢pb−1 data sample of ¯𝑝⁢𝑝 collisions at √𝑠=1.8⁢TeV collected with the Collider Detector at Fermilab (CDF). Employing techniques similar to those we previously published, we observe a signal consistent with 𝑡⁢¯𝑡 decay to WWb⁢¯𝑏, but inconsistent with the background prediction by 4.8⁢𝜎. Additional evidence for the top quark is provided by a peak in the reconstructed mass distribution. We measure the top quark mass to be 176±8⁢(stat)±10⁢(syst)⁢GeV⁢/𝑐2, and the 𝑡⁢¯𝑡 production cross section to be 6.8+3.6−2.4⁢pb., This article appears in the following collection:\n",
      "\n",
      "---\n",
      "\n",
      "# Evidence for Anomalous Lepton Production in ${e}^{+}\\ensuremath{-}{e}^{\\ensuremath{-}}$ Annihilation\n",
      "\n",
      "We have found events of the form 𝑒++𝑒−→𝑒±+𝜇∓+missing⁢energy, in which no other charged particles or photons are detected. Most of these events are detected at or above a center-of-mass energy of 4 GeV. The missing-energy and missing-momentum spectra require that at least two additional particles be produced in each event. We have no conventional explanation for these events., This article appears in the following collection:\n",
      "\n",
      "---\n",
      "\n",
      "# Discovery of a Narrow Resonance in ${e}^{+}{e}^{\\ensuremath{-}}$ Annihilation\n",
      "\n",
      "We have observed a very sharp peak in the cross section for 𝑒+⁢𝑒−→hadrons, 𝑒+⁢𝑒−, and possibly 𝜇+⁢𝜇− at a center-of-mass energy of 3.105±0.003 GeV. The upper limit to the full width at half-maximum is 1.3 MeV., This article appears in the following collection:\n",
      "\n",
      "---\n",
      "\n",
      "# Experimental Observation of a Heavy Particle $J$\n",
      "\n",
      "We report the observation of a heavy particle 𝐽, with mass 𝑚=3.1 GeV and width approximately zero. The observation was made from the reaction 𝑝+Be→𝑒++𝑒−+𝑥 by measuring the 𝑒+⁢𝑒− mass spectrum with a precise pair spectrometer at the Brookhaven National Laboratory's 30-GeV alternating-gradient synchrotron., This article appears in the following collection:\n",
      "\n",
      "---\n",
      "\n",
      "# Review of Particle Physics\n",
      "\n",
      "The Review summarizes much of particle physics and cosmology. Using data from previous editions, plus 2,717 new measurements from 869 papers, we list, evaluate, and average measured properties of gauge bosons and the recently discovered Higgs boson, leptons, quarks, mesons, and baryons. We summarize searches for hypothetical particles such as supersymmetric particles, heavy bosons, axions, dark photons, etc. Particle properties and search limits are listed in Summary Tables. We give numerous tables, figures, formulae, and reviews of topics such as Higgs Boson Physics, Supersymmetry, Grand Unified Theories, Neutrino Mixing, Dark Energy, Dark Matter, Cosmology, Particle Detectors, Colliders, Probability and Statistics. Most of the 120 reviews are updated, including many that are heavily revised.\n",
      "\n",
      "---\n",
      "\n",
      "# A Multi-dimensional Unfolding Method Based on Bayes Theorem\n",
      "\n",
      "Bayes' Theorem offers a natural way to unfold experimental distributions in order to get the best estimates of the true ones. The weak point of the Bayes approach, namely the need of the knowledge of the initial distribution, can be overcome by an iterative procedure. Since the method proposed here does not make use of continuous variables, but simply of cells in the spaces of the true and of the measured quantities, it can be applied in multidimensional problems.\n",
      "\n",
      "---\n",
      "\n",
      "# The International Linear Collider Technical Design Report - Volume 4: Detectors\n",
      "\n",
      "The International Linear Collider Technical Design Report (TDR) describes in four volumes the physics case and the design of a 500 GeV centre-of-mass energy linear electron-positron collider based on superconducting radio-frequency technology using Niobium cavities as the accelerating structures. The accelerator can be extended to 1 TeV and also run as a Higgs factory at around 250 GeV and on the Z0 pole. A comprehensive value estimate of the accelerator is give, together with associated uncertainties. It is shown that no significant technical issues remain to be solved. Once a site is selected and the necessary site-dependent engineering is carried out, construction can begin immediately. The TDR also gives baseline documentation for two high-performance detectors that can share the ILC luminosity by being moved into and out of the beam line in a \"push-pull\" configuration. These detectors, ILD and SiD, are described in detail. They form the basis for a world-class experimental programme that promises to increase significantly our understanding of the fundamental processes that govern the evolution of the Universe.\n",
      "\n",
      "---\n",
      "\n",
      "# BESⅢ-CsI(Tl)晶体量能器时间信息的研究\n",
      "\n",
      "O57; BESⅢ-CsI(Tl)晶体量能器采用FADC的DAQ电子学读出系统.通过扫描信号幅度的分布寻找信号峰位.为了降低扫描时间窗内(3μs)的低能本底计数、提高能量分辨和降低无效计数率,除了传统的输出信号峰位(表征沉积能量)之外,我们引出另一个较粗的时间信息,即对应信号峰位的扫描步长数,其步长精度为50ns.本文将通过电子束流实验研究对这一时间信息的特点及如何利用时间信息进行详细的分析和讨论.\n",
      "\n",
      "---\n",
      "\n",
      "# 在北京正负电子对撞机(BEPC)上τ质量的实验测量\n",
      "\n",
      "在北京高能物理研究所正负电子对撞机(BEPC)上进行了τ轻子质量测量。τ~+τ~-事例由北京谱仪(BES)探测,总积分亮度为5000nb~(-1)。用最大似然函数法选择逼近阈值的测量点能量,并最终确定τ轻子的质量为1776.9±0.4±0.2MeV\n",
      "\n",
      "---\n",
      "\n",
      "# 在$e^+e^-$对撞过程中τ轻子对产生的阈行为\n",
      "\n",
      "利用结构函数方法,足够精确地给出了在e~+e~-对撞过程中考虑了各种QED辐射修正效应后的τ轻子产生的阈行为解析表达式(这里包括了始态辐射修正、真空极化效应、库仑效应和终态修正效应等),这个阈行为用来为BEs测量τ轻子的质量值.\n",
      "\n",
      "---\n",
      "\n",
      "# Design and construction of the new BESIII endcap time-of-flight system with MRPC technology\n",
      "\n",
      "In order to improve the particle identification capability, the Beijing Spectrometer (BESIII) collaboration has upgraded the End-cap Time-Of-Flight detector (ETOF) based on Multi-gap Resistive Plate Chamber (MRPC) technology. In this paper, the design and engineering development of each part of the project are reported. There are 72 MRPC modules, forming 2 rings. Adjacent modules are staggered placed to avoid dead regions. Each MRPC module contains 12-layer thin gaps to get fast signals with high efficiency and 12 strips to readout the induced signals from two ends, effectively reducing the timing uncertainties from the scattering and positioning. Also, the analog–digital conversion is done near the MRPC and only the digital signals are transferred through thin coax cables, ensuring good signal-to-noise ratio. The complex electromagnetic noises in the BESIII colliding area are well shielded to protect the tiny signals from the MRPC. After careful correction and calibration, the total time resolution of upgraded ETOF system is 65ps.\n",
      "\n",
      "---\n",
      "\n",
      "# The OPAL detector at LEP\n",
      "\n",
      "The OPAL detector at the e+e− storage ring LEP is designed to provide precise measurements of charged particles and of electromagnetic energy over nearly the full solid angle. Its main elements are a central tracking system, a solenoidal coil, an electromagnetic calorimeter made of lead glass, a hadron calorimeter made of iron and wire chambers, and a muon detector. A pair of forward detectors is used to measure the luminosity and to identify particles emitted at small angles with respect to the beam line. In this paper all detector elements are described and their performance is discussed.\n",
      "\n",
      "---\n",
      "\n",
      "# Measurement of CKM element $|V_{cb}|$ from $W$ boson decays at the future Higgs factories\n",
      "\n",
      "This study investigates the precision measurement of the CKM matrix element $|V_{cb}|$ through semileptonic $WW$ events at future Higgs factories, $i.e.$, FCC-ee, ILC, C$^3$, and CEPC. We use full detector simulation to generate the $WW \\to \\ell \\nu cb$ signal events and various backgrounds at $\\sqrt{s} = 240$ GeV with unpolarized beams. The relative statistical uncertainties are projected to be 0.91\\% for the muon channel and 1.2\\% for the electron channel, assuming a baseline integrated luminosity of 5 ab$^{-1}$. The sensitivities at other Higgs factory scenarios are also projected. Possible contributors to systematic uncertainties are discussed, with the most prominent one being the systematics of flavor-tagging and mistagging rates. Combining with $WW$ threshold runs, the relative systematic uncertainty can be further reduced.\n",
      "\n",
      "---\n",
      "\n",
      "# Test beam studies of silicon timing for use in calorimetry\n",
      "\n",
      "The high luminosity upgrade of the Large Hadron Collider (HL-LHC) at CERN is expected to provide instantaneous luminosities of 5×1034cm−2s−1. The high luminosities expected at the HL-LHC will be accompanied by a factor of 5–10 more pileup compared with LHC conditions in 2015, further increasing the challenge for particle identification and event reconstruction. Precision timing allows us to extend calorimetric measurements into such a high density environment by subtracting the energy deposits from pileup interactions. Calorimeters employing silicon as the active component have recently become a viable choice for the HL-LHC and future collider experiments which face very high radiation environments. In this paper, we present studies of basic calorimetric and precision timing measurements using a prototype composed of tungsten absorber and silicon sensor as the active medium. We show that for the bulk of electromagnetic showers induced by electrons in the range of 20–30GeV, we can achieve time resolutions better than 25ps per single pad sensor.\n",
      "\n",
      "---\n",
      "\n",
      "# Time-assisted energy reconstruction in a highly-granular hadronic calorimeter\n",
      "\n",
      "The software compensation algorithms developed for the CALICE Analog Hadron Calorimeter are extended to incorporate time information on the cell level, and the performance is studied in GEANT4 simulations with a detector model of a highly-granular SiPM-on-tile calorimeter. The addition of nanosecond-level time resolution is found to result in significant improvement of the energy resolution by approximately 3 % to 4 % for local software compensation compared to the software compensation based on local energy density alone, with further improvement possible with better timing resolution. The high correlation of energy density and time variables show that both provide sensitivity to correlated underlying shower features, which limits the potential of timing information when used as a global rather than a local variable.\n",
      "\n",
      "---\n",
      "\n",
      "# On the use of neural networks for energy reconstruction in high-granularity calorimeters\n",
      "\n",
      "We contrasted the performance of deep neural networks — Convolutional Neural Network (CNN) and Graph Neural Network (GNN) — to current state of the art energy regression methods in a finely 3D-segmented calorimeter simulated by GEANT4. This comparative benchmark gives us some insight to assess the particular latent signals neural network methods exploit to achieve superior resolution. A CNN trained solely on a pure sample of pions achieved substantial improvement in the energy resolution for both single pions and jets over the conventional approaches. It maintained good performance for electron and photon reconstruction. We also used the Graph Neural Network (GNN) with edge convolution to assess the importance of timing information in the shower development for improved energy reconstruction. We implement a simple simulation based correction to the energy sum derived from the fraction of energy deposited in the electromagnetic shower component. This serves as an approximate dual-readout analogue for our benchmark comparison. Although this study does not include the simulation of detector effects, such as electronic noise, the margin of improvement seems robust enough to suggest these benefits will endure in real-world application. We also find reason to infer that the CNN/GNN methods leverage latent features that concur with our current understanding of the physics of calorimeter measurement.\n",
      "\n",
      "---\n",
      "\n",
      "# Fast-timing Capabilities of Silicon Sensors for the CMS High-Granularity Calorimeter at the High-Luminosity LHC\n",
      "\n",
      "We report on the signal timing capabilities of thin silicon sensors when traversed by multiple simultaneous minimum ionizing particles (MIP). Three different planar sensors, 133, 211, and 285 μm thick in depletion thickness, have been exposed to high energy muons and electrons at CERN. We describe signal shape and timing resolution measurements as well as the response of these devices as a function of the multiplicity of MIPs. We compare these measurements to simulations where possible. We achieve better than 20 ps timing resolution for signals larger than a few tens of MIPs.\n",
      "\n",
      "---\n",
      "\n",
      "# Measurement of Angular Coefficients of $\\bar{B} \\to D^* \\ell \\bar{\\nu}_\\ell$: Implications for $|V_{cb}|$ and Tests of Lepton Flavor Universality\n",
      "\n",
      "We measure the complete set of angular coefficients $J_i$ for exclusive $\\bar{B} \\to D^* \\ell \\bar{\\nu}_\\ell$ decays ($\\ell = e, \\mu$). Our analysis uses the full $711\\,\\mathrm{fb}^{-1}$ Belle data set with hadronic tag-side reconstruction. The results allow us to extract the form factors describing the $B \\to D^*$ transition and the Cabibbo-Kobayashi-Maskawa matrix element $|V_{\\rm cb}|$. Using recent lattice QCD calculations for the hadronic form factors, we find $|V_{\\rm cb}| = (41.0 \\pm 0.7) \\times 10^3 $ using the BGL parameterization, compatible with determinations from inclusive semileptonic decays. We search for lepton flavor universality violation as a function of the hadronic recoil parameter $w$, and investigate the differences of the electron and muon angular distributions. We find no deviation from Standard Model expectations.\n",
      "\n",
      "---\n",
      "\n",
      "# First Simultaneous Determination of Inclusive and Exclusive $|{V}_{ub}|$\n",
      "\n",
      "首次同时确定 Cabibbo-Kobayashi-Maskawa 矩阵元素的绝对值𝑉𝑢⁢𝑏使用包容性和独占衰减是在ϒ⁡(4⁢𝑆)共振，对应于积分光度711 fb−1.我们分析碰撞事件，其中𝐵介子在强子模式下完全重建。这允许重建强子𝑋𝑢半轻体系统𝑏→𝑢⁢ℓ⁢¯𝜈ℓ衰变。我们分开独家𝐵→π⁢ℓ⁢¯𝜈ℓ来自其他包容性的衰变𝐵→𝑋𝑢⁢ℓ⁢¯𝜈ℓ以及具有二维拟合的背景，该背景利用了𝑋𝑢系统与四动量传递𝑞2在𝐵和𝑋𝑢系统。将我们的测量结果与来自晶格 QCD 和 QCD 计算的信息相结合，将包含部分速率以及关于形状的外部实验信息相结合。𝐵→π⁢ℓ⁢¯𝜈ℓ外形尺寸，我们确定|𝑉excl𝑢⁢𝑏|=(3.78±0.23±0.16±0.14)×10−3和|𝑉我ncl𝑢⁢𝑏|=(3.88±0.20±0.31±0.09)×10−3，不确定性分别为统计误差、系统误差和理论误差。的比率|𝑉excl𝑢⁢𝑏|/|𝑉我ncl𝑢⁢𝑏|=0.97±0.12与 Unity 兼容。\n",
      "\n",
      "---\n",
      "\n",
      "# Detectors and Physics at a Future Linear Collider\n",
      "\n",
      "An electron-positron linear collider is an option for future large particle accelerator projects. Such a collider would focus on precision tests of the Higgs boson properties. This thesis describes three studies related to the optimisation of highly granular calorimeters and one study on the sensitivity of Higgs couplings at CLIC.\n",
      "\n",
      "---\n",
      "\n",
      "# GNN-based end-to-end reconstruction in the CMS Phase 2 High-Granularity Calorimeter\n",
      "\n",
      "We present the current stage of research progress towards a one-pass, completely Machine Learning (ML) based imaging calorimeter reconstruction. The model used is based on Graph Neural Networks (GNNs) and directly analyzes the hits in each HGCAL endcap. The ML algorithm is trained to predict clusters of hits originating from the same incident particle by labeling the hits with the same cluster index. We impose simple criteria to assess whether the hits associated as a cluster by the prediction are matched to those hits resulting from any particular individual incident particles. The algorithm is studied by simulating two tau leptons in each of the two HGCAL endcaps, where each tau may decay according to its measured standard model branching probabilities. The simulation includes the material interaction of the tau decay products which may create additional particles incident upon the calorimeter. Using this varied multiparticle environment we can investigate the application of this reconstruction technique and begin to characterize energy containment and performance.\n",
      "\n",
      "---\n",
      "\n",
      "# Cluster time measurement with CEPC calorimeter\n",
      "\n",
      "We have developed an algorithm dedicated to timing reconstruction in highly granular calorimeters (HGC). The performance of this algorithm is evaluated on an electromagnetic calorimeter (ECAL) with geometries comparable to the electromagnetic compartment (CE-E) of the CMS endcap calorimeter upgrade at HL-LHC and conceptual Particle Flow oriented ECAL’s for future Higgs factories. The time response of individual channel is parameterized according to the CMS experimental result (Akchurin et al. in Nucl Instrum Methods Phys Res Sect A Accel Spectrom Detect Assoc Equip 859:31, 2017). The particle Time-of-Flight (ToF) can be measured with a resolution of 5–20 ps for electromagnetic (EM) showers and 80–160 ps for hadronic showers above 1 GeV. The presented algorithm provides comparable reconstruction with the $$E_{\\textrm{hit}}^2$$weighting strategy and can significantly improve the time resolution compared to a simple averaging of the fast component of the time spectrum. The effects of three detector configurations are also quantified in this study. ToF resolution depends linearly on the timing resolution of a single silicon sensor and improves statistically with increasing incident particle energy. The timing layers at depth of 6–9 radiation lengths provide higher timing performance for EM showers. A clustering algorithm that vetoes isolated hits improves ToF resolution.\n",
      "\n",
      "---\n",
      "\n",
      "# Measurement of the B0<math><mtext>B</mtext><msup><mi></mi><mn><mspace xmlns=\"true\" sp=\"0.2\" width=\"2px\" linebreak=\"nobreak\" is=\"true\"></mspace><mtext>0</mtext></mn></msup></math> and <i>B</i>− meson lifetimes\n",
      "\n",
      "The lifetimes of the B0 and B− mesons are measured using a sample of about four million hadronic Z decays collected from 1991 to 1995 with the Aleph detector at LEP. The data sample has been recently reprocessed, achieving a substantial improvement in the tracking performance. Semileptonic decays of B0 and B− mesons are partially reconstructed by identifying events containing a lepton with an associated D★+ or D0 meson. The proper time of the B meson is estimated from the measured decay length and the momentum of the D-lepton system. A fit to the proper time of 1880 D★+ℓ− and 2856 D0ℓ− candidates yields the following results: τB0=1.518±0.053±0.034 ps, τB−=1.648±0.049±0.035 ps, τB−/τB0=1.085±0.059±0.018.\n",
      "\n",
      "---\n",
      "\n",
      "# A precise measurement of the B + , B0 and mean b-hadron lifetime with the DELPHI detector at LEP I\n",
      "\n",
      "Final results from the DELPHI Collaboration on the lifetime of B +  and B0 mesons and the mean b-hadron lifetime, are presented using the data collected at the Z0 peak in 1994 and 1995. Elaborate, inclusive, secondary vertexing methods have been employed to ensure a b-hadron reconstruction with good efficiency. To separate samples of B +  and B0 mesons, high performance neural network techniques are used that achieve very high purity signals. The results obtained are: $$ \\tau_{\\mathrm B}^ + = 1.624 \\pm 0.014\\;\\;(stat) \\pm 0.018\\; (syst) ps $$$$ \\tau_{\\mathrm B}^0\\quad = 1.531 \\pm 0.021 \\;\\;(stat)\\pm 0.031 \\; (syst) ps $$$$ \\frac{\\tau_{{\\mathrm B}^ + }}{\\tau_{{\\mathrm B}^0}} = 1.060 \\pm 0.021 \\;\\;(stat)\\pm 0.024\\;(syst) $$and for the average b-hadron lifetime: $$ \\tau_{{\\mathrm b}} = 1.570 \\pm 0.005\\;\\;(stat) \\pm 0.008 \\; (syst) ps. $$\n",
      "\n",
      "---\n",
      "\n",
      "# Measurement of differential distributions of $B\\ensuremath{\\rightarrow}{D}^{*}\\ensuremath{\\ell}{\\overline{\\ensuremath{\\nu}}}_{\\ensuremath{\\ell}}$ and implications on $|{V}_{cb}|$\n",
      "\n",
      "We present a measurement of the differential shapes of exclusive 𝐵→𝐷*⁢ℓ⁢¯𝜈ℓ (𝐵=𝐵−,¯𝐵0 and ℓ=𝑒, 𝜇) decays with hadronic tag-side reconstruction for the full 711 fb−1 Belle dataset. We extract the Caprini-Lellouch-Neubert (CLN) and Boyd-Grinstein-Lebed (BGL) form factor parameters and use an external input for the absolute branching fractions to determine the Cabibbo-Kobayashi-Maskawa matrix element and find |𝑉𝑐⁢𝑏|CLN=(40.2±0.9)×10−3 and |𝑉𝑐⁢𝑏|BGL=(40.7±1.0)×10−3 with the zero-recoil lattice QCD point ℱ⁡(1)=0.906±0.013. We also perform a study of the impact of beyond zero-recoil lattice QCD calculations on the |𝑉𝑐⁢𝑏| determinations. Additionally, we present the lepton-flavor universality ratio 𝑅𝑒⁢𝜇=ℬ⁡(𝐵→𝐷*⁢𝑒⁢¯𝜈𝑒)/ℬ⁡(𝐵→𝐷*⁢𝜇⁢¯𝜈𝜇)=0.993±0.023±0.023, the electron and muon forward-backward asymmetry and their difference Δ⁢𝐴𝐹⁢𝐵=0.028±0.028±0.008, and the electron and muon 𝐷* longitudinal polarization fraction and their difference Δ⁢𝐹𝐷*𝐿=0.030±0.025±0.007. The uncertainties quoted correspond to the statistical and systematic uncertainties, respectively.\n",
      "\n",
      "---\n",
      "\n",
      "# Measurement of the CKM matrix element $|{V}_{cb}|$ from ${B}^{0}\\ensuremath{\\rightarrow}{D}^{*\\ensuremath{-}}{\\ensuremath{\\ell}}^{+}{\\ensuremath{\\nu}}_{\\ensuremath{\\ell}}$ at Belle\n",
      "\n",
      "We present a new measurement of the Cabibbo-Kobayashi-Maskawa matrix element |𝑉𝑐⁢𝑏| from 𝐵0→𝐷*−⁢ℓ+⁢𝜈ℓ decays, reconstructed with the full Belle data set of 711 fb−1 integrated luminosity. Two form factor parametrizations, originally conceived by the Caprini-Lellouch-Neubert (CLN) and the Boyd, Grinstein and Lebed (BGL) groups, are used to extract the product ℱ⁡(1)⁢𝜂EW⁢|𝑉𝑐⁢𝑏| and the decay form factors, where ℱ⁡(1) is the normalization factor and 𝜂EW is a small electroweak correction. In the CLN parametrization we find ℱ⁡(1)⁢𝜂EW⁢|𝑉𝑐⁢𝑏|=(35.06±0.15±0.56)×10−3, 𝜌2=1.106±0.031±0.007, 𝑅1⁡(1)=1.229±0.028±0.009, 𝑅2⁡(1)=0.852±0.021±0.006. For the BGL parametrization we obtain ℱ⁡(1)⁢𝜂EW⁢|𝑉𝑐⁢𝑏|=(34.93±0.23±0.59)×10−3, which is consistent with the world average when correcting for ℱ⁡(1)⁢𝜂EW. The branching fraction of 𝐵0→𝐷*−⁢ℓ+⁢𝜈ℓ is measured to be ℬ⁡(𝐵0→𝐷*−⁢ℓ+⁢𝜈ℓ)=(4.90±0.02±0.16)%. We also present a new test of lepton flavor universality violation in semileptonic 𝐵 decays, ℬ⁡(𝐵0→𝐷*−⁢𝑒+⁢𝜈)ℬ⁡(𝐵0→𝐷*−⁢𝜇+⁢𝜈)=1.01±0.01±0.03. The errors quoted correspond to the statistical and systematic uncertainties, respectively. This is the most precise measurement of ℱ⁡(1)⁢𝜂EW⁢|𝑉𝑐⁢𝑏| and form factors to date and the first experimental study of the BGL form factor parametrization in an experimental measurement.\n",
      "\n",
      "---\n",
      "\n",
      "# Model-independent extraction of |<i>V</i>cb| from ⁎B¯→D⁎ℓν‾<math><mover accent=\"true\" is=\"true\"><mrow is=\"true\"><mi is=\"true\">B</mi></mrow><mrow is=\"true\"><mo stretchy=\"false\" is=\"true\">¯</mo></mrow></mover><mo stretchy=\"false\" is=\"true\">→</mo><msup is=\"true\"><mrow is=\"true\"><mi is=\"true\">D</mi></mrow><mrow is=\"true\"><mo is=\"true\">⁎</mo></mrow></msup><mi is=\"true\">ℓ</mi><mover accent=\"true\" is=\"true\"><mrow is=\"true\"><mi is=\"true\">ν</mi></mrow><mo is=\"true\">‾</mo></mover></math>\n",
      "\n",
      "We fit the unfolded data of B¯0→D⁎+ℓν‾ from the Belle experiment, where ℓ≡e,μ, using a method independent of heavy quark symmetry to extrapolate to zero-recoil and extract the value of |Vcb|. This results in |Vcb|=(41.9−1.9+2.0)×10−3, which is robust to changes in the theoretical inputs and very consistent with the value extracted from inclusive semileptonic B decays.\n",
      "\n",
      "---\n",
      "\n",
      "# High-precision $\\alpha_s$ measurements from LHC to FCC-ee\n",
      "\n",
      "This document provides a writeup of all contributions to the workshop on \"High precision measurements of $\\alpha_s$: From LHC to FCC-ee\" held at CERN, Oct. 12--13, 2015. The workshop explored in depth the latest developments on the determination of the QCD coupling $\\alpha_s$ from 15 methods where high precision measurements are (or will be) available. Those include low-energy observables: (i) lattice QCD, (ii) pion decay factor, (iii) quarkonia and (iv) $\\tau$ decays, (v) soft parton-to-hadron fragmentation functions, as well as high-energy observables: (vi) global fits of parton distribution functions, (vii) hard parton-to-hadron fragmentation functions, (viii) jets in $e^\\pm$p DIS and $\\gamma$-p photoproduction, (ix) photon structure function in $\\gamma$-$\\gamma$, (x) event shapes and (xi) jet cross sections in $e^+e^-$ collisions, (xii) W boson and (xiii) Z boson decays, and (xiv) jets and (xv) top-quark cross sections in proton-(anti)proton collisions. The current status of the theoretical and experimental uncertainties associated to each extraction method, the improvements expected from LHC data in the coming years, and future perspectives achievable in $e^+e^-$ collisions at the Future Circular Collider (FCC-ee) with $\\cal{O}$(1--100 ab$^{-1}$) integrated luminosities yielding 10$^{12}$ Z bosons and jets, and 10$^{8}$ W bosons and $\\tau$ leptons, are thoroughly reviewed. The current uncertainty of the (preliminary) 2015 strong coupling world-average value, $\\alpha_s(m_Z)$ = 0.1177 $\\pm$ 0.0013, is about 1\\%. Some participants believed this may be reduced by a factor of three in the near future by including novel high-precision observables, although this opinion was not universally shared. At the FCC-ee facility, a factor of ten reduction in the $\\alpha_s$ uncertainty should be possible, mostly thanks to the huge Z and W data samples available.\n",
      "\n",
      "---\n",
      "\n",
      "# Improved measurement of CP-violation parameters $\\mathrm{sin}﻿2{\\ensuremath{\\phi}}_{1}$ and $|\\ensuremath{\\lambda}|$, $B$ meson lifetimes, and ${B}^{0}$-${\\overline{B}}^{0}$ mixing parameter $\\ensuremath{\\Delta}{m}_{d}$\n",
      "\n",
      "We present a precise measurement of the standard model 𝐶⁢𝑃-violation parameter sin 2⁢𝜙1, the direct 𝐶⁢𝑃 violation parameter |𝜆|, the lifetimes of charged and neutral 𝐵 mesons and their ratio, and the 𝐵0-‾𝐵0 mixing parameter 𝛥⁢𝑚𝑑 based on a sample of 152×106 𝐵⁢‾𝐵 pairs collected at the 𝛶⁡(4⁢𝑆) resonance with the Belle detector at the KEKB asymmetric-energy 𝑒+⁢𝑒− collider. One of two 𝐵 mesons is fully reconstructed in a 𝐶⁢𝑃-eigenstate or a flavor-eigenstate decay channel. The flavor of the accompanying 𝐵 meson is identified from its decay products. From the distributions of the time interval between the two 𝐵 meson decay points, we obtain sin 2⁢𝜙1=0.728±0.056⁢(stat)±0.023⁢(syst), |𝜆|=1.007±0.041⁢(stat)±0.033⁢(syst), 𝜏𝐵0=[1.534±0.008⁢(stat)±0.010⁢(syst)] ps, 𝜏𝐵+=[1.635±0.011⁢(stat)±0.011⁢(syst)] ps, 𝜏𝐵+/𝜏𝐵0=1.066±0.008⁢(stat)±0.008⁢(syst) and 𝛥⁢𝑚𝑑=[0.511±0.005⁢(stat)±0.006⁢(syst)] ps−1. The results for sin 2⁢𝜙1 and |𝜆| are consistent with the standard model expectations. The significance of the observed deviation from unity in the lifetime ratio exceeds 5 standard deviations.\n",
      "\n",
      "---\n",
      "\n",
      "# Measurement of $b$ Hadron Lifetimes in Exclusive Decays Containing a $J/\\ensuremath{\\psi}$ in $p\\overline{p}$ Collisions at $\\sqrt{s}=1.96\\text{ }\\text{ }\\mathrm{TeV}$\n",
      "\n",
      "We report on a measurement of 𝑏-hadron lifetimes in the fully reconstructed decay modes 𝐵+→𝐽/𝜓⁢𝐾+, 𝐵0→𝐽/𝜓⁢𝐾*⁢(892)0, 𝐵0→𝐽/𝜓⁢𝐾0𝑠, and 𝛬0𝑏→𝐽/𝜓⁢𝛬0 using data corresponding to an integrated luminosity of 4.3 fb−1, collected by the CDF II detector at the Fermilab Tevatron. The measured lifetimes are 𝜏⁡(𝐵+)=[1.639±0.009⁢(stat)±0.009⁢(syst)] ps, 𝜏⁡(𝐵0)=[1.507±0.010⁢(stat)±0.008⁢(syst)] ps, and 𝜏⁡(𝛬0𝑏)=[1.537±0.045⁢(stat)±0.014⁢(syst)] ps. The lifetime ratios are 𝜏⁡(𝐵+)/𝜏⁡(𝐵0)=[1.088±0.009⁢(stat)±0.004⁢(syst)] and 𝜏⁡(𝛬0𝑏)/𝜏⁡(𝐵0)=[1.020±0.030⁢(stat)±0.008⁢(syst)]. These are the most precise determinations of these quantities from a single experiment.\n",
      "\n",
      "---\n",
      "\n",
      "# Bottom and charm mass determinations from global fits to $$ Q\\overline{Q} $$bound states at N3LO\n",
      "\n",
      "The bottomonium spectrum up to n = 3 is studied within Non-Relativistic Quantum Chromodynamics up to N3LO. We consider finite charm quark mass effects both in the QCD potential and the $$ \\overline{\\mathrm{MS}} $$-pole mass relation up to third order in the Y-scheme counting. The u = 1/2 renormalon of the static potential is canceled by expressing the bottom quark pole mass in terms of the MSR mass. A careful investigation of scale variation reveals that, while n = 1, 2 states are well behaved within perturbation theory, n = 3 bound states are no longer reliable. We carry out our analysis in the nℓ = 3 and nℓ = 4 schemes and conclude that, as long as finite mc effects are smoothly incorporated in the MSR mass definition, the difference between the two schemes is rather small. Performing a fit to $$ b\\overline{b} $$bound states we find $$ {\\overline{m}}_b\\left({\\overline{m}}_b\\right) $$= 4.216 ± 0.039 GeV. We extend our analysis to the lowest lying charmonium states finding $$ {\\overline{m}}_c\\left({\\overline{m}}_c\\right) $$= 1.273 ± 0.054 GeV. Finally, we perform simultaneous fits for $$ {\\overline{m}}_b $$and αsfinding $$ {\\alpha}_s^{\\left({n}_f=5\\right)}\\left({m}_Z\\right)=0.1178\\pm 0.0051 $$. Additionally, using a modified version of the MSR mass with lighter massive quarks we are able to predict the uncalculated $$ \\mathcal{O}\\left({\\alpha}_s^4\\right) $$virtual massive quark corrections to the relation between the $$ \\overline{\\mathrm{MS}} $$and pole masses.\n",
      "\n",
      "---\n",
      "\n",
      "# Novel method to reliably determine the QCD coupling from Ruds measurements and its effects to muon g − 2 and $$ \\alpha \\left({M}_Z^2\\right) $$within the tau-charm energy region\n",
      "\n",
      "We present a novel method for precisely determining the QCD running coupling from Ruds measurements in electron-positron annihilation. When calculating the fixed-order perturbative QCD (pQCD) approximant of Ruds, its effective coupling constant $$ {\\alpha}_s\\left({Q}_{\\ast}^2\\right) $$is determined by using the principle of maximum conformality, a systematic scale-setting method for gauge theories, whose resultant pQCD series satisfies all the requirements of renormalization group. Contribution due to the uncalculated higher-order (UHO) terms is estimated by using the Bayesian analysis. Using Ruds data measured by the KEDR detector at 22 centre-of-mass energies between 1.84 GeV and 3.72 GeV, we obtain $$ {\\alpha}_s\\left({M}_Z^2\\right) $$= $$ {0.1227}_{-0.0132}^{+0.0117}\\left(\\exp .\\right)\\pm 0.0016\\left(\\textrm{the}.\\right) $$, where the theoretical uncertainty (the.) is negligible compared to the experimental one (exp.). Numerical analyses confirm that the new method for calculating Ruds removes conventional renormalization scale ambiguity, and the residual scale dependence due to the UHO-terms will also be highly suppressed due to a more convergent pQCD series. This leads to a significant stabilization of the perturbative series, and a significant reduction of theoretical uncertainty. It thus provides a reliable theoretical basis for precise determination of the QCD running coupling from Ruds measurements at future Tau-Charm Facility. It can also be applied for the precise determination of the hadronic contributions to muon g − 2 and QED coupling $$ \\alpha \\left({M}_Z^2\\right) $$within the tau-charm energy range.\n",
      "\n",
      "---\n",
      "\n",
      "# Non-Lagrangian Models of Current Algebra\n",
      "\n",
      "An alternative is proposed to specific Lagrangian models of current algebra. In this alternative there are no explicit canonical fields, and operator products at the same point [say, jμ(x)jμ(x)] have no meaning. Instead, it is assumed that scale invariance is a broken symmetry of strong interactions, as proposed by Kastrup and Mack. Also, a generalization of equal-time commutators is assumed: Operator products at short distances have expansions involving local fields multiplying singular functions. It is assumed that the dominant fields are the SU(3)×SU(3) currents and the SU(3)×SU(3) multiplet containing the pion field. It is assumed that the pion field scales like a field of dimension Δ, where Δ is unspecified within the range 1≤Δ<4; the value of Δ is a consequence of renormalization. These hypotheses imply several qualitative predictions: The second Weinberg sum rule does not hold for the difference of the K∗ and axial-K∗ propagators, even for exact SU(2)×SU(2); electromagnetic corrections require one subtraction proportional to the I=1, Iz=0σ field; η→3π and π0→2γ are allowed by current algebra. Octet dominance of nonleptonic weak processes can be understood, and a new form of superconvergence relation is deduced as a consequence. A generalization of the Bjorken limit is proposed.\n",
      "\n",
      "---\n",
      "\n",
      "# Charmonium: Comparison with experiment\n",
      "\n",
      "The charmonium model, formulated in detail in an earlier publication, is compared in a comprehensive fashion with the data on the ψ family. The parameters of the \"naive\" model, in which the system is described as a c¯c pair, are determined from the observed positions of ψ, ψ′, and the P states. The model then yields a successful description of the spectrum of spin-triplet states above the charm threshold. It also accounts for the ratio of the leptonic widths of ψ′ and ψ. When the c¯c potential is applied to the Υ family, it accounts, without any readjustment of parameters, for the positions of the 2S and 3S levels and for the leptonic widths of Υ and Υ′ relative to that of ψ. The model does not give acceptable values of the absolute leptonic widths, a shortcoming which is ascribed to large quantum-chromodynamic corrections to the van Royen-Weisskopf formula. The calculated E1 rates are about twice the values observed in the ψ family. This naive model is also extended with considerable success to mesons composed of one heavy and one light quark. A significant extension of the model is achieved by incorporating coupling to charmed-meson decay channels. This gives a satisfactory understanding of ψ(3772) as the 13D1 c¯c state, mixed via open and closed decay channels to 23S. The model has decay amplitudes that are oscillatory functions of the decay momentum; these oscillations are a direct consequence of the radial nodes in the c¯c parent states. These amplitudes provide a qualitative understanding of the observed peculiar branching ratios into various charmed-meson channels near the resonance at 4.03 GeV, which is assigned to 33S. The coupling of the c¯c states below the charm threshold to closed decay channels modifies the bound states and leads to reduction of about 20% in E1 rates in comparison to those of the naive model.\n",
      "\n",
      "---\n",
      "\n",
      "# REvolver: Automated running and matching of couplings and masses in QCD\n",
      "\n",
      "In this article we present REvolver, a C++ library for renormalization group evolution and automatic flavor matching of the QCD coupling and quark masses, as well as precise conversion between various quark mass renormalization schemes. The library systematically accounts for the renormalization group evolution of low-scale short-distance masses which depend linearly on the renormalization scale and sums logarithmic terms of high and low scales that are missed by the common logarithmic renormalization scale evolution. The library can also be accessed through Mathematica and Python interfaces and provides renormalization group evolution for complex renormalization scales as well.\n",
      "Program summary\n",
      "Program Title: REvolver CPC Library link to program files: https://doi.org/10.17632/m6cjfmzsxb.1 Developer's repository link: https://gitlab.com/REvolver-hep/REvolver Code Ocean capsule: https://codeocean.com/capsule/6150064 Licensing provisions: GPLv3 or later Programming language: C++, Python, Wolfram Language Nature of problem: The strong coupling and the quark masses are fundamental parameters of QCD that are scheme and renormalization-scale dependent. The choice of scheme depends on the active number of flavors and the range of scales, and is dictated by the requirements to minimize the size of corrections and to sum large logarithmic corrections to all orders. For the strong coupling and the quark masses at high scales, the MS‾ scheme with logarithmic scale dependence is used. For quark masses at low scales, short-distance mass schemes with linear scale-dependence are used. The REvolver library provides conversions for the strong coupling and the most common quark mass schemes, with renormalization scale evolution implemented such that all types of large logarithmic terms are summed to all orders, accounting for flavor threshold effects and state-or-the-art correction terms. The pole mass, which is not a short-distance mass and contains a sizable renormalon ambiguity, is treated as a derived quantity. Solution method: Renormalization group equations are solved for complex-valued scales to machine precision based on fast-converging iterative algorithms and analytic all-order expressions. Matching relations for the strong coupling at flavor thresholds are computed in a way that gives equal results for upward and downward evolution. Core objects allow to define an arbitrary number of physical scenarios for strong coupling values and quark mass spectra, where options for precision and matching scales can be set freely, and values for quark masses in all common schemes including the pole mass can be extracted. All REvolver routines are implemented entirely in C++ and can be accessed through Mathematica and Python interfaces.\n",
      "\n",
      "---\n",
      "\n",
      "# Jet origin identification and measurement of rare hadronic decays of Higgs boson at $e^+e^-$ collider\n",
      "\n",
      "To enhance the scientific discovery power of high-energy collider experiments, we propose and realize the concept of jet origin identification that categorizes jets into 5 quark species $(b,c,s,u,d)$, 5 anti-quarks $(\\bar{b},\\bar{c},\\bar{s},\\bar{u},\\bar{d})$, and gluon. Using state-of-the-art algorithms and simulated $\\nu\\bar{\\nu}H, H\\rightarrow jj$ events at 240~GeV center-of-mass energy at the electron-positron Higgs factory, the jet origin identification simultaneously reaches jet flavor tagging efficiencies of 92\\%, 79\\%, 67\\%, 37\\%, and 41\\% and jet charge flip rates of 18\\%, 7\\%, 15\\%, 15\\%, and 19\\% for $b$, $c$, $s$, $u$, and $d$ quarks, respectively. We apply the jet origin identification to Higgs rare and exotic decay measurements at the nominal luminosity of the Circular Electron Positron Collider (CEPC), and conclude that the upper limits on the branching ratios of $H\\rightarrow s \\bar{s}, u\\bar{u}, d\\bar{d}$, and $H\\rightarrow sb, db, uc, ds$ can be determined to $2\\!\\!\\times\\!\\!10^{-4}$ to $1\\!\\!\\times\\!\\!10^{-3}$ at 95\\% confidence level. The derived upper limit for $H\\rightarrow s \\bar{s}$ decay is approximately three times the prediction of the Standard Model.\n",
      "\n",
      "---\n",
      "\n",
      "# SVD Approach to Data Unfolding\n",
      "\n",
      "Distributions measured in high energy physics experiments are usually distorted and/or transformed by various detector effects. A regularization method for unfolding these distributions is re-formulated in terms of the Singular Value Decomposition (SVD) of the response matrix. A relatively simple, yet quite efficient unfolding procedure is explained in detail. The concise linear algorithm results in a straightforward implementation with full error propagation, including the complete covariance matrix and its inverse. Several improvements upon widely used procedures are proposed, and recommendations are given how to simplify the task by the proper choice of the matrix. Ways of determining the optimal value of the regularization parameter are suggested and discussed, and several examples illustrating the use of the method are presented.\n",
      "\n",
      "---\n",
      "\n",
      "# The QCD running coupling\n",
      "\n",
      "We review the present theoretical and empirical knowledge for αs, the fundamental coupling underlying the interactions of quarks and gluons in Quantum Chromodynamics (QCD). The dependence of αs(Q2) on momentum transfer Q encodes the underlying dynamics of hadron physics—from color confinement in the infrared domain to asymptotic freedom at short distances. We review constraints on αs(Q2) at high Q2, as predicted by perturbative QCD, and its analytic behavior at small Q2, based on models of nonperturbative dynamics. In the introductory part of this review, we explain the phenomenological meaning of the coupling, the reason for its running, and the challenges facing a complete understanding of its analytic behavior in the infrared domain. In the second, more technical, part of the review, we discuss the behavior of αs(Q2) in the high momentum transfer domain of QCD. We review how αs is defined, including its renormalization scheme dependence, the definition of its renormalization scale, the utility of effective charges, as well as “Commensurate Scale Relations” which connect the various definitions of the QCD coupling without renormalization-scale ambiguity. We also report recent significant measurements and advanced theoretical analyses which have led to precise QCD predictions at high energy. As an example of an important optimization procedure, we discuss the “Principle of Maximum Conformality”, which enhances QCD’s predictive power by removing the dependence of the predictions for physical observables on the choice of theoretical conventions such as the renormalization scheme. In the last part of the review, we discuss the challenge of understanding the analytic behavior αs(Q2) in the low momentum transfer domain. We survey various theoretical models for the nonperturbative strongly coupled regime, such as the light-front holographic approach to QCD. This new framework predicts the form of the quark-confinement potential underlying hadron spectroscopy and dynamics, and it gives a remarkable connection between the perturbative QCD scale Λ and hadron masses. One can also identify a specific scale Q0 which demarcates the division between perturbative and nonperturbative QCD. We also review other important methods for computing the QCD coupling, including lattice QCD, the Schwinger–Dyson equations and the Gribov–Zwanziger analysis. After describing these approaches and enumerating their conflicting predictions, we discuss the origin of these discrepancies and how to remedy them. Our aim is not only to review the advances in this difficult area, but also to suggest what could be an optimal definition of αs(Q2) in order to bring better unity to the subject.\n",
      "\n",
      "---\n",
      "\n",
      "# Behavior of the effective QCD coupling ${\\ensuremath{\\alpha}}_{\\ensuremath{\\tau}}(s)$ at low scales\n",
      "\n",
      "The hadronic decays of the τ lepton can be used to determine the effective charge ατ(m2τ′) for a hypothetical τ lepton with a mass in the range 0<mτ′<mτ. This definition provides a fundamental definition of the QCD coupling at low mass scales. We study the behavior of ατ at low mass scales directly from first principles and without any renormalization-scheme dependence by looking at the experimental data from the OPAL Collaboration. The results are consistent with the freezing of the physical coupling at mass scales s=m2τ′ of order 1GeV2 with a magnitude ατ∼0.9±0.1.\n",
      "\n",
      "---\n",
      "\n",
      "# One-prong $\\tau$decays with kaons\n",
      "\n",
      "One-prong $\\tau$decays into final states involving kaons are studied with about 161 000 $\\tau^+\\tau^-$events collected by the ALEPH detector from 1991 to 1995. Charged kaons are identified by dE/dx measurement, while $K^0_L$'s are detected through their interaction in calorimeters. Branching ratios are measured for the inclusive mode, $B(\\tau^-\\rightarrow K^-X\\nu_\\tau)=(1.52 \\pm 0.04\\pm0.04)\\%$, where X can be any system of neutral particles, and for the exclusive modes \\[ \\begin{array}{rcl} B(\\tau^-\\to K^-\\nu_\\tau) &=& (6.96\\pm0.25\\pm0.14)\\times 10^{-3}, B(\\tau^-\\to K^-\\pi^0\\nu_\\tau) &=& (4.44\\pm0.26\\pm0.24)\\times 10^{-3}, B(\\tau^-\\to K^-\\pi^0\\pi^0\\nu_\\tau) &=& (0.56\\pm0.20\\pm0.15)\\times 10^{-3}, B(\\tau^-\\to K^-\\pi^0\\pi^0\\pi^0\\nu_\\tau) &=& (0.37\\pm0.21\\pm0.11)\\times 10^{-3}, B(\\tau^-\\to K^-K^{0}\\nu_\\tau) &=& (1.62\\pm0.21\\pm0.11)\\times 10^{-3}, B(\\tau^-\\to K^{-}K^{0}\\pi^0\\nu_\\tau) & =& (1.43\\pm 0.25\\pm0.15)\\times 10^{-3}, B(\\tau^-\\to \\overline{K^0} \\pi^{-}\\nu_\\tau) &=& (9.28\\pm 0.45\\pm0.34)\\times 10^{-3}, B(\\tau^-\\to \\overline{K^0} \\pi^{-}\\pi^0\\nu_\\tau) &=& (3.47\\pm0.53\\pm0.37)\\times10^{-3}, \\end{array} \\] where the first error is statistical and the second is systematical. Upper limits for $B(\\tau^-\\to \\overline{K^0}\\pi^{-}\\pi^0\\pi^0\\nu_\\tau)$and $B(\\tau^-\\to K^{-}K^{0}\\pi^0\\pi^0\\nu_\\tau)$are also obtained. Mass spectra in the final states are investigated in order to study the relevant dynamics.\n",
      "\n",
      "---\n",
      "\n",
      "# Three-prong τ decays with charged kaons\n",
      "\n",
      "Final states with charged kaons in three-prong τ decays are studied by exploiting the particle identification from the dE/dx measurement. The results are based on a sample of about 1.6 × 105 detected τ pairs collected with the ALEPH detector between 1991 and 1995 around the Z peak. The following branching ratios have been measured: B(τ- → K−K+π−ντ) = (1.63 ± 0.21 ± 0.17) × 10−3, B(τ− → K−π+π−ντ) = (2.14 ± 0.37 ± 0.29) × 10−3, B(τ− → K−K+π−π0ντ) = (0.75 ± 0.29 ± 0.15) × 10−3, and B(τ− → K−π+π−π0ντ) = (0.61 ± 0.39 ± 0.18) × 10−3. The first two measurements are more precise than the current world averages, while the last two channels are investigated for the first time. The 95% C.L. upper limit on the branching ratio for the decay τ− → K−K+K−ντ is 0.19 × 10−3. A study of intermediate states occurring in the K−K+π−ντ and K−π+π−ντ decays is also presented.\n",
      "\n",
      "---\n",
      "\n",
      "# $K^0_S$production in $\\tau$decays\n",
      "\n",
      "From a sample of about 160k $\\mbox{Z}\\!\\!\\to\\!\\!\\tau^+\\tau^-$candidates collected with the ALEPH detector at LEP between 1991 and 1995, $\\tau$lepton decays involving $K^0_S\\!\\to\\!\\pi^+\\pi^-$are studied. The $K^0_SK^0_L$associated production in $\\tau$decays is also investigated. The branching ratios are measured for the inclusive decay $B(\\tau^-\\!\\!\\to\\!\\!K^0_SX^-\\nu_\\tau)=(9.70\\!\\p m\\!0.58\\!\\pm\\!0.62)\\times10^{-3}$, where $X^-$can be anything, and for the exclusive decays \\[ \\begin{array}{rcl} B(\\tau^-\\!\\!\\to\\!\\!\\overline{K}^0\\pi^-\\nu_\\tau)&=& (8.55\\!\\pm\\!1.17\\! \\pm\\!0.66)\\times10^{-3} ,\\\\ B(\\tau^-\\!\\!\\to\\!\\!\\overline{K}^0\\pi^-\\pi^0\\nu_\\tau)&=& (2.94\\!\\pm\\! 0.73\\!\\pm\\!0.37)\\times10^{-3},\\\\ B(\\tau^-\\!\\!\\to\\!\\!\\overline{K}^0K^-\\nu_\\tau)&=& (1.58\\!\\pm\\!0.42\\!\\pm\\! 0.17)\\times10^{-3},\\\\ B(\\tau^-\\!\\!\\to\\!\\!\\overline{K}^0K^-\\pi^0\\nu_\\tau)&=& (1.52\\!\\p m\\!0.76\\! \\pm\\!0.21)\\times10^{-3}. \\end{array} \\] The decay $\\tau^-\\!\\!\\to\\!\\!K^0_SK^0_L\\pi^-\\nu_\\tau$is studied for the first time, giving a branching ratio \\[ \\begin{array}{rcl} B(\\tau^-\\!\\!\\to\\!\\!K^0_SK^0_L\\pi^-\\nu_\\tau)&=& (1.01\\!\\pm\\!0.23\\!\\pm\\!0.13)\\times10^{-3}. \\end{array} \\] The channels $\\tau^- \\!\\!\\!\\to\\!\\!\\! K^0_SK^0_S\\pi^-\\nu_\\tau $, $\\tau^- \\!\\!\\!\\to\\!\\!\\! K^0_SK^0_S\\pi^-\\pi^0\\nu_\\tau $, $\\tau^-\\!\\!\\!\\to\\!\\!\\! K^0_SK^0_L\\pi^-\\pi^0\\nu_\\tau $, $\\tau^- \\!\\!\\!\\to\\!\\!\\! \\overline{K}^0\\pi^-\\pi^0\\pi^0\\nu_\\tau$, $\\tau^- \\!\\!\\!\\to\\!\\!\\! K^0K^-\\pi^0\\pi^0\\nu_\\tau$and $\\tau^- \\!\\!\\!\\to\\!\\!\\! K^0h^+h^-h^-\\nu_\\tau$are also investigated. In addition, mass spectra in the $K^0_Sh^-$and $K^0_Sh^-\\pi^0$final states are analysed to provide information on the intermediate states produced in the decays.\n",
      "\n",
      "---\n",
      "\n",
      "# A study of one-prong Tau decays with a charged kaon\n",
      "\n",
      "From an analysis of the ionisation energy loss of charged particles selected from 110326 ${\\rm e}^+{\\rm e}^- \\rightarrow \\tau^+\\tau^-$candidates recorded by the OPAL detector at ${\\rm e}^+{\\rm e}^-$centre-of-mass energies near the Z$^0$resonance, we determine the one-prong tau decay branching ratios:\n",
      "\n",
      "---\n",
      "\n",
      "# Physics prospects at the Belle II experiment\n",
      "\n",
      "A review of the flavour physics program for the Belle II experiment is presented, including projections for precision on key observables. The Belle II experiment is located at the second generation asymmetric e+e− collider SuperKEKB. It will be used to search for new phenomena at the flavour frontier.\n",
      "\n",
      "---\n",
      "\n",
      "# STCF Conceptual Design Report: Volume 1 -- Physics & Detector\n",
      "\n",
      "The Super $\\tau$-Charm facility (STCF) is an electron-positron collider proposed by the Chinese particle physics community. It is designed to operate in a center-of-mass energy range from 2 to 7 GeV with a peak luminosity of $0.5\\times 10^{35}{\\rm cm}^{-2}{\\rm s}^{-1}$ or higher. The STCF will produce a data sample about a factor of 100 larger than that by the present $\\tau$-Charm factory -- the BEPCII, providing a unique platform for exploring the asymmetry of matter-antimatter (charge-parity violation), in-depth studies of the internal structure of hadrons and the nature of non-perturbative strong interactions, as well as searching for exotic hadrons and physics beyond the Standard Model. The STCF project in China is under development with an extensive R\\&D program. This document presents the physics opportunities at the STCF, describes conceptual designs of the STCF detector system, and discusses future plans for detector R\\&D and physics case studies.\n",
      "\n",
      "---\n",
      "\n",
      "# Measurement and interpretation of moments in inclusive semileptonic decays $\\overline{B}\\ensuremath{\\rightarrow}{X}_{c}{\\ensuremath{\\ell}}^{\\ensuremath{-}}\\overline{\\ensuremath{\\nu}}$\n",
      "\n",
      "我们给出了在包容性半光子中观测光谱矩的结果B-介子衰变为魅力强子¯¯¯B→Xcℓ−¯ν.0.8 和 0.8 之间不同最小电子或μ介子动量的强子质量矩和组合质能谱1.9 GeV（吉瓦）/c是从以下样品中获得的232×106 Υ(4S)→B¯¯¯B事件，用 BABAR 探测器在 PEP-II 非对称能量处收集B-SLAC介子工厂。我们还提出了对电子能谱和部分衰变分数矩的重新评估B(¯¯¯B→Xce−¯ν)最小电子动量a 在 0.6 和1.5 GeV（吉瓦）/c基于51×106 Υ(4S)→B¯¯¯B事件。测量结果用于提取总衰变分数，即 Cabibbo-Kobayashi-Maskawa （CKM） 基体元素|Vcb|、夸克质量mb和mc，以及重夸克膨胀（HQE）框架中的四个重夸克QCD参数。我们发现B(¯¯¯B→Xcℓ−¯ν)=(10.64±0.17±0.06)%和|Vcb|=(42.05±0.45±0.70)×10−3.\n",
      "\n",
      "---\n",
      "\n",
      "# Precise Measurement of the ${e}^{+}{e}^{\\ensuremath{-}}\\ensuremath{\\rightarrow}{D}_{s}^{*+}{D}_{s}^{*\\ensuremath{-}}$ Cross Sections at Center-of-Mass Energies from Threshold to 4.95 GeV\n",
      "\n",
      "The process e+e−→D*+sD*−s is studied with a semi-inclusive method using data samples at center-of-mass energies from threshold to 4.95 GeV collected with the BESIII detector operating at the Beijing Electron Positron Collider. The Born cross sections of the process are measured for the first time with high precision in this energy region. Two resonance structures are observed in the energy-dependent cross sections around 4.2 and 4.4 GeV. By fitting the cross sections with a coherent sum of three Breit-Wigner amplitudes and one phase-space amplitude, the two significant structures are assigned masses of (4186.8±8.7±30) and (4414.6±3.4±6.1) MeV/c2, widths of (55±15±53) and (122.5±7.5±8.1) MeV, where the first errors are statistical and the second ones are systematic. The inclusion of a third Breit-Wigner amplitude is necessary to describe a structure around 4.79 GeV.\n",
      "\n",
      "---\n",
      "\n",
      "# Systematic Errors: facts and fictions\n",
      "\n",
      "The treatment of systematic errors is often mishandled. This is due to lack of understanding and education, based on a fundamental ambiguity as to what is meant by the term. This note addresses the problems and oﬀers guidance to good practice.\n",
      "\n",
      "---\n",
      "\n",
      "# High Luminosity Large Hadron Collider HL-LHC\n",
      "\n",
      "HL-LHC federates the efforts and R&D of a large international community towards the ambitious HL- LHC objectives and contributes to establishing the European Research Area (ERA) as a focal point of global research cooperation and a leader in frontier knowledge and technologies. HL-LHC relies on strong participation from various partners, in particular from leading US and Japanese laboratories. This participation will be required for the execution of the construction phase as a global project. In particular, the US LHC Accelerator R&D Program (LARP) has developed some of the key technologies for the HL-LHC, such as the large-aperture niobium-tin ($Nb_{3}Sn) quadrupoles and the crab cavities. The proposed governance model is tailored accordingly and should pave the way for the organization of the construction phase.\n",
      "\n",
      "---\n",
      "\n",
      "# FCC Physics Opportunities\n",
      "\n",
      "We review the physics opportunities of the Future Circular Collider, covering its e+e-, pp, ep and heavy ion programmes. We describe the measurement capabilities of each FCC component, addressing the study of electroweak, Higgs and strong interactions, the top quark and flavour, as well as phenomena beyond the Standard Model. We highlight the synergy and complementarity of the different colliders, which will contribute to a uniquely coherent and ambitious research programme, providing an unmatchable combination of precision and sensitivity to new physics.\n",
      "\n",
      "---\n",
      "\n",
      "# CLEO-c and CESR-c: A new frontier in strong and weak interactions\n",
      "\n",
      "We report on the physics potential of a charm and QCD factory, based on a proposal for the conversion of the existing CESR machine and CLEO detector: “CESR-c and OLEO-c”. Such a facility will make major contributions to the field of quark flavor physics in this decade. It may also provide the best chance for understanding non-perturbative QCD, which is essential to understanding the strongly-coupled sectors of the new physics that lies beyond the Standard Model.\n",
      "\n",
      "---\n",
      "\n",
      "# The EvtGen particle decay simulation package\n",
      "\n",
      "With several new B-physics experiments now taking data, the physics of B-meson decays will be studied in greater detail than previously possible. It is important to have a simulation of the underlying physics processes that is able to accurately describe this data. The EvtGen package provides a framework for the implementation of physics processes relevant to decays of B mesons and other resonances. Models of time dependent CP asymmetries in neutral B meson decays, semileptonic form-factor models, and a full decay table for B decays are a few of the implemented features.\n",
      "\n",
      "---\n",
      "\n",
      "# Coherent exclusive exponentiation for precision Monte Carlo calculations\n",
      "\n",
      "We present the new coherent exclusive exponentiation (CEEX), the older exclusive exponentiation (EEX), and the semianalytical inclusive exponentiation (IEX) for the process e−e+→f¯f+nγ, where f=μ,τ,d,u,s,c,b, which are valid for center-of-mass energies from the τ lepton threshold to 1 TeV, that is, for CERN LEP1, LEP2, the SLC, future linear colliders, and b,c,τ factories, etc. The approaches are based on Yennie-Frautschi-Suura exponentiation. In CEEX, the effects due to photon emission from initial beams and outgoing fermions are calculated in QED up to second order, including all interference effects. Electroweak corrections are included to first order, at the amplitude level. Beams can be polarized longitudinally and transversely, and all spin correlations are incorporated in an exact manner. The EEX is more primitive, lacks initial-final interferences, but it is valuable for testing the newer CEEX. The IEX provides us with a set of sophisticated semianalytical formulas for the total cross section and selected inclusive distributions, which are mainly used for cross-checks of the Monte Carlo results. We analyze numerical results at the Z peak, 189 GeV and 500 GeV for simple kinematical cuts (comparisons with inclusive exponentiation) and for realistic experimental cuts. The physical precision and technical precision are determined for the total cross section and for the charge asymmetry.\n",
      "\n",
      "---\n",
      "\n",
      "# The $$\\uptau $$challenges at FCC-ee\n",
      "\n",
      "At FCC-ee, about $$1.7 \\times 10^{11}\\,\\hbox {Z} \\rightarrow \\uptau ^+\\uptau ^-$$events will be produced. This high statistics in the clean $$\\hbox {e}^+\\hbox {e}^-$$environment opens the possibility of much improved determinations of $$\\uptau $$-lepton properties and, via the measurement of the $$\\uptau $$polarisation, of the neutral-current couplings of electrons and $$\\tau $$s. Improved measurements of $$\\uptau $$-lepton properties—lifetime, leptonic branching fractions, and mass—allow important tests of lepton universality. The experimental challenge is to match as far as possible statistical uncertainties generally at the $$10^{-5}$$level. This applies in particular to the lifetime measurement, which is derived from the 2.2-mm $$\\uptau $$average flight distance, and for the branching fraction and polarisation measurements, where the cross-channel contamination is of particular concern. These issues raise strict detector requirements, in particular, on the accuracy of the construction and alignment of the vertex detector and of the precise calorimetric separation and measurement of photons and $$\\uppi ^0$$s in the collimated $$\\uptau $$decay topologies.\n",
      "\n",
      "---\n",
      "\n",
      "# The gluon mass generation mechanism: A concise primer\n",
      "\n",
      "We present a pedagogical overview of the nonperturbative mechanism that endows gluons with a dynamical mass. This analysis is performed based on pure Yang–Mills theories in the Landau gauge, within the theoretical framework that emerges from the combination of the pinch technique with the background field method. In particular, we concentrate on the Schwinger–Dyson equation satisfied by the gluon propagator and examine the necessary conditions for obtaining finite solutions within the infrared region. The role of seagull diagrams receives particular attention, as do the identities that enforce the cancellation of all potential quadratic divergences.We stress the necessity of introducing nonperturbative massless poles in the fully dressed vertices of the theory in order to trigger the Schwinger mechanism, and explain in detail the instrumental role of these poles in maintaining the Becchi–Rouet–Stora–Tyutin symmetry at every step of the mass-generating procedure. The dynamical equation governing the evolution of the gluon mass is derived, and its solutions are determined numerically following implementation of a set of simplifying assumptions. The obtained mass function is positive definite, and exhibits a power law running that is consistent with general arguments based on the operator product expansion in the ultraviolet region. A possible connection between confinement and the presence of an inflection point in the gluon propagator is briefly discussed.\n",
      "\n",
      "---\n",
      "\n",
      "# Measurement of the $\\tau$-lepton mass with the Belle~II experiment\n",
      "\n",
      "We present a measurement of the $\\tau$-lepton mass using a sample of about 175 million $e^+e^- \\to \\tau^+\\tau^-$ events collected with the Belle II detector at the SuperKEKB $e^+e^-$ collider at a center-of-mass energy of $10.579\\,\\mathrm{Ge\\kern -0.1em V}$. This sample corresponds to an integrated luminosity of $190\\,\\mathrm{fb^{-1}}$. We use the kinematic edge of the $\\tau $ pseudomass distribution in the decay ${\\tau^-\\to\\pi^-\\pi^+\\pi^-\\nu_\\tau}$ and measure the $\\tau$ mass to be $1777.09 \\pm 0.08 \\pm 0.11 \\,\\mathrm{Me\\kern -0.1em V\\!/c^2}$, where the first uncertainty is statistical and the second systematic. This result is the most precise to date.\n",
      "\n",
      "---\n",
      "\n",
      "# Studies on $\\tau$ decays at Belle II\n",
      "\n",
      "Tau leptons are powerful tools to probe physics beyond the Standard Model (SM). The Belle II experiment is installed at the SuperKEKB asymmetric energy electron-positron collider and aims at collecting the world's largest sample of tau pair events $e^{+}e^{-}\\rightarrow \\tau^+ \\tau^-$. Direct searches for new invisible mediators, charged lepton flavor violation in $\\tau$ decays, and tests of the SM via precision measurements of $\\tau$ lepton properties and couplings are reported in the following article. The results presented here are based on the data collected by Belle II during 2019-2021.\n",
      "\n",
      "---\n",
      "\n",
      "# Hadronic energy resolution of a highly granular scintillator-steel hadron calorimeter using software compensation techniques\n",
      "\n",
      "The energy resolution of a highly granular 1 m3 analogue scintillator-steel hadronic calorimeter is studied using charged pions with energies from 10 GeV to 80 GeV at the CERN SPS. The energy resolution for single hadrons is determined to be approximately 58%/√E/GeV. This resolution is improved to approximately 45%/√E/GeV with software compensation techniques. These techniques take advantage of the event-by-event information about the substructure of hadronic showers which is provided by the imaging capabilities of the calorimeter. The energy reconstruction is improved either with corrections based on the local energy density or by applying a single correction factor to the event energy sum derived from a global measure of the shower energy density. The application of the compensation algorithms to geant4 simulations yield resolution improvements comparable to those observed for real data.\n",
      "\n",
      "---\n",
      "\n",
      "# Software compensation in particle flow reconstruction\n",
      "\n",
      "The particle flow approach to calorimetry benefits from highly granular calorimeters and sophisticated software algorithms in order to reconstruct and identify individual particles in complex event topologies. The high spatial granularity, together with analogue energy information, can be further exploited in software compensation. In this approach, the local energy density is used to discriminate electromagnetic and purely hadronic sub-showers within hadron showers in the detector to improve the energy resolution for single particles by correcting for the intrinsic non-compensation of the calorimeter system. This improvement in the single particle energy resolution also results in a better overall jet energy resolution by improving the energy measurement of identified neutral hadrons and improvements in the pattern recognition stage by a more accurate matching of calorimeter energies to tracker measurements. This paper describes the software compensation technique and its implementation in particle flow reconstruction with the Pandora Particle Flow Algorithm (PandoraPFA). The impact of software compensation on the choice of optimal transverse granularity for the analogue hadronic calorimeter option of the International Large Detector (ILD) concept is also discussed.\n",
      "\n",
      "---\n",
      "\n",
      "# Electromagnetic response of a highly granular hadronic calorimeter\n",
      "\n",
      "The CALICE collaboration is studying the design of high performance electromagnetic and hadronic calorimeters for future International Linear Collider detectors. For the hadronic calorimeter, one option is a highly granular sampling calorimeter with steel as absorber and scintillator layers as active material. High granularity is obtained by segmenting the scintillator into small tiles individually read out via silicon photo-multipliers (SiPM). A prototype has been built, consisting of thirty-eight sensitive layers, segmented into about eight thousand channels. In 2007 the prototype was exposed to positrons and hadrons using the CERN SPS beam, covering a wide range of beam energies and angles of incidence. The challenge of cell equalization and calibration of such a large number of channels is best validated using electromagnetic processes. The response of the prototype steel-scintillator calorimeter, including linearity and uniformity, to electrons is investigated and described.\n",
      "\n",
      "---\n",
      "\n",
      "# The CMS barrel calorimeter response to particle beams from 2 to 350 GeV/c\n",
      "\n",
      "The response of the CMS barrel calorimeter (electromagnetic plus hadronic) to hadrons, electrons and muons over a wide momentum range from 2 to 350 GeV/c has been measured. To our knowledge, this is the widest range of momenta in which any calorimeter system has been studied. These tests, carried out at the H2 beam-line at CERN, provide a wealth of information, especially at low energies. The analysis of the differences in calorimeter response to charged pions, kaons, protons and antiprotons and a detailed discussion of the underlying phenomena are presented. We also show techniques that apply corrections to the signals from the considerably different electromagnetic (EB) and hadronic (HB) barrel calorimeters in reconstructing the energies of hadrons. Above 5 GeV/c, these corrections improve the energy resolution of the combined system where the stochastic term equals 84.7±1.6% and the constant term is 7.4±0.8%. The corrected mean response remains constant within 1.3% rms.\n",
      "\n",
      "---\n",
      "\n",
      "# Design, performance, and calibration of CMS forward calorimeter wedges\n",
      "\n",
      "We report on the test beam results and calibration methods using high energy electrons, pions and muons with the CMS forward calorimeter (HF). The HF calorimeter covers a large pseudorapidity region ($3\\leq|\\eta|\\leq5$), and is essential for a large number of physics channels with missing transverse energy. It is also expected to play a prominent role in the measurement of forward tagging jets in weak boson fusion channels in Higgs production. The HF calorimeter is based on steel absorber with embedded fused-silica-core optical fibers where Cherenkov radiation forms the basis of signal generation. Thus, the detector is essentially sensitive only to the electromagnetic shower core and is highly non-compensating (e/h≈5). This feature is also manifest in narrow and relatively short showers compared to similar calorimeters based on ionization. The choice of fused-silica optical fibers as active material is dictated by its exceptional radiation hardness. The electromagnetic energy resolution is dominated by photoelectron statistics and can be expressed in the customary form as $\\frac{a}{\\sqrt{E}}\\oplus{b}$. The stochastic term a is 198% and the constant term b is 9%. The hadronic energy resolution is largely determined by the fluctuations in the neutral pion production in showers, and when it is expressed as in the electromagnetic case, a = 280% and b = 11%.\n",
      "\n",
      "---\n",
      "\n",
      "# Testing QCD with τ decays\n",
      "\n",
      "The invariant-mass distribution of the hadronic state in τ decay can be used for testing fundamental aspects of the strong interactions. Using standard QCD techniques, it is possible to compute certain weighted integrals of the hadronic spectrum. We work out some QCD predictions which will be useful for analysing the data. They provide a direct way to simultaneously measure αs(mτ2) and the parameters characterizing the non-perturbative dynamics, allowing for a better control of the theoretical errors in the determination of αs(mτ2).\n",
      "\n",
      "---\n",
      "\n",
      "# Measurement of αS from τ decays\n",
      "\n",
      "We present measurements of spectral moments extracted from the invariant mass distributions of the final states of hadronic τ decay products recorded in the CLEO detector. From a fit of theoretical predictions to the measurements of spectral moments and the total hadronic decay width of the τ, we determine the strong coupling constant and a set of non-perturbative QCD parameters. The strong coupling constant is measured to be αs(mτ) = 0.306 ± 0.024, which when extrapolated to the Z mass, yields αs(Mz) = 0.114 ± 0.003.\n",
      "\n",
      "---\n",
      "\n",
      "# The perturbative QCD prediction to Rτ revisited\n",
      "\n",
      "The perturbative QCD prediction to the total hadronic width of the tau lepton is re-examined. A more convergent perturbative expansion is proposed, which is associated with a smaller renormalization-scheme dependence and better-defined higher-order uncertainties.\n",
      "\n",
      "---\n",
      "\n",
      "# Prospects for $$ {B}_{(s)}^0 $$→ π0π0 and $$ {B}_{(s)}^0 $$→ ηη modes and corresponding CP asymmetries at Tera-Z\n",
      "\n",
      "The physics potential of measuring $$ {B}_{(s)}^0 $$→ π0π0 and $$ {B}_{(s)}^0 $$→ ηη decays via four-photon final states at Tera-Z phase of CEPC or FCC-ee is investigated in this paper. We propose an electromagnetic calorimeter (ECAL) with both high energy resolution and excellent separation power to efficiently reconstruct π0 and η from hadronic final states with high photon multiplicity. The resulting B-meson mass resolution is approximately 30 MeV, allowing 3 σ separation between B0 and $$ {B}_s^0 $$. With the assistance of the b-jet tagging, the relative sensitivities to B0 → π0π0, $$ {B}_s^0 $$→ π0π0, B0 → ηη, and $$ {B}_s^0 $$→ ηη signal strengths at Tera-Z are projected as 0.45%, 4.5%, 18%, and 0.95%, respectively. Their dependence on various detector performances is also discussed. In addition, B0 → π0π0 and its two isospin-related modes are paid special attention due to their roles in the determination of the CKM angle α (ϕ2). The anticipated precisions of their branching-ratio and CP-asymmetry measurements at Tera-Z are evaluated. We show that the measurement of the time-integrated B0 → π0π0 CP asymmetry at Tera-Z is complementary to B-factory ones. The precision on α combining Z- and B-factory results reaches 0.4°, lower than the systematic uncertainties attached to isospin breaking.\n",
      "\n",
      "---\n",
      "\n",
      "# αs and the τ hadronic width: fixed-order, contour- improved and higher-order perturbation theory\n",
      "\n",
      "The determination of αs from hadronic τ decays is revisited, with a special emphasis on the question of higher-order perturbative corrections and different possibilities of resumming the perturbative series with the renormalisation group: fixed-order (FOPT) vs. contour-improved perturbation theory (CIPT). The difference between these approaches has evolved into a systematic effect that does not go away as higher orders in the perturbative expansion are added. We attempt to clarify under which circumstances one or the other approach provides a better approximation to the true result. To this end, we propose to describe the Adler function series by a model that includes the exactly known coefficients and theoretical constraints on the large-order behaviour originating from the operator product expansion and the renormalisation group. Within this framework we find that while CIPT is unable to account for the fully resummed series, FOPT smoothly approaches the Borel sum, before the expected divergent behaviour sets in at even higher orders. Employing FOPT up to the fifth order to determine αs in the Mτ scheme, we obtain αs(Mτ) = 0.320+0.012−0.007, corresponding to αs(MZ) = 0.1185+0.0014−0.0009. Improving this result by including yet higher orders from our model yields αs(Mτ) = 0.316±0.006, which after evolution leads to αs(MZ) = 0.1180±0.0008. Our results are lower than previous values obtained from τ decays.\n",
      "\n",
      "---\n",
      "\n",
      "# Duality violations in τ hadronic spectral moments\n",
      "\n",
      "Evidence is presented for the necessity of including duality violations in a consistent description of spectral function moments employed in the precision determination of αs from τ decay. A physically motivated ansatz for duality violations in the spectral functions enables us to perform fits to spectral moments employing both pinched and unpinched weights. We describe our analysis strategy and provide some preliminary findings. Final numerical results await completion of an ongoing re-determination of the ALEPH covariance matrices incorpo-rating correlations due to the unfolding procedure which are absent from the currently posted versions. To what extent this issue affects existing analyses and our own work will require further study.\n",
      "\n",
      "---\n",
      "\n",
      "# Perturbative expansion of τ hadronic spectral function moments and αsextractions\n",
      "\n",
      "Various moments of the hadronic spectral functions have been employed in the determination of the strong coupling αsfrom tau decays. In this work we study the behaviour of their perturbative series under different assumptions for the large-order behaviour of the Adler function, extending previous work on the tau hadronic width. We find that the moments can be divided into a small number of classes, whose characteristics depend only on generic features of the moment weight function and Adler function series. Some moments that are commonly employed in αsanalyses from τ decays should be avoided because of their perturbative instability. This conclusion is corroborated by a simplified αsextraction from individual moments. Furthermore, under reasonable assumptions for the higher-order behaviour of the perturbative series, fixed-order perturbation theory (FOPT) provides the preferred framework for the renormalization group improvement of all moments that show good perturbative behaviour. Finally, we provide further evidence for the plausibility of the description of the Adler function in terms of a small number of leading renormalon singularities.\n",
      "\n",
      "---\n",
      "\n",
      "# The determination of αSfrom τ decays revisited\n",
      "\n",
      "We revisit the determination of αS(mτ2) using a fit to inclusive τ hadronic spectral moments in light of (1) the recent calculation of the fourth-order perturbative coefficient K4 in the expansion of the Adler function, (2) new precision measurements from BABAR of e+e− annihilation cross sections, which decrease the uncertainty in the separation of vector and axial-vector spectral functions, and (3) improved results from BABAR and Belle on τ branching fractions involving kaons. We estimate that the fourth-order perturbative prediction reduces the theoretical uncertainty, introduced by the truncation of the series, by 20% with respect to earlier determinations. We discuss to some detail the perturbative prediction of two different methods: fixed-order perturbation theory (FOPT) and contour-improved perturbative theory (CIPT). The corresponding theoretical uncertainties are studied at the τ and Z mass scales. The CIPT method is found to be more stable with respect to the missing higher order contributions and to renormalization scale variations. It is also shown that FOPT suffers from convergence problems along the complex integration contour. Nonperturbative contributions extracted from the most inclusive fit are small, in agreement with earlier determinations. Systematic effects from quark-hadron duality violation are estimated with simple models and found to be within the quoted systematic errors. The fit based on CIPT gives αS(mτ2)=0.344±0.005±0.007, where the first error is experimental and the second theoretical. After evolution to MZwe obtain αS(MZ2)=0.1212±0.0005±0.0008±0.0005, where the errors are respectively experimental, theoretical and due to the evolution. The result is in agreement with the corresponding N3LO value derived from essentially the Z width in the global electroweak fit. The αS(MZ2) determination from τ decays is the most precise one to date.\n",
      "\n",
      "---\n",
      "\n",
      "# A Measurement of the Michel Parameters in Leptonic Decays of the Tau\n",
      "\n",
      "We have measured the spectral shape Michel parameters ρ and η using leptonic decays of the τ, recorded by the CLEO II detector. Assuming e−μ universality in the vectorlike couplings, we find ρeμ=0.735±0.013±0.008 and ηeμ=−0.015±0.061±0.062, where the first error is statistical and the second systematic. We also present measurements for the parameters for e and μ final states separately.\n",
      "\n",
      "---\n",
      "\n",
      "# τ→π~±2π~0v结构函数的测量\n",
      "\n",
      "首次对τ→π2π0v衰变的结构函数进行了模型无关的实验测量，并与KS模型、IMR模型和Feindt模型进行了比较，在误差范围内，三种理论模型与实验结果一致．与OPAL组测量的τ→3π±v道的结构函数相比，在0．5＜Q2＜2．75GeV2范围内未发现明显差异．\n",
      "\n",
      "---\n",
      "\n",
      "# Tau mass measurement at BES-III\n",
      "\n",
      "A scan of the threshold region of the process\n",
      "              e\n",
      "              +\n",
      "              e\n",
      "              −\n",
      "              → τ\n",
      "              +\n",
      "              τ\n",
      "              −\n",
      "              with integrated luminosity about 140 pb\n",
      "              −1\n",
      "              was performed with the BES-III detector at the BEPC-II collider in order to measure the τ-lepton mass. The beam energy was determined by the Compton backscattering method. To verify the measurement accuracy scans of the\n",
      "              J\n",
      "              /ψ and ψ\n",
      "              ′\n",
      "              resonances were performed.\n",
      "\n",
      "---\n",
      "\n",
      "# τ~±→π~±+nπ~0+v_τ(n=0,1,2)衰变分支比测量\n",
      "\n",
      "基于北京谱仪收集的4.03GeV 质心系能量下 e~+e~-对撞数据,分析τ~±τ~■→e~±π~■+nπ~0+v′s(n=0,1,2)事例,给出分支比值 Br(τ~±→π~±v_τ)=(11.64±0.49_(-0.73)~(+0.76)%,Br(τ~±→π~±π~0v_τ)=(24.00±1.34_(-1.30)~(1.36)%,Br(τ~±→π~±2π~0v_τ)=(9.39±1.68_(-1.66)~(1.69)%.\n",
      "\n",
      "---\n",
      "\n",
      "# Measurement of the Cross Section for ${e}^{+}{e}^{\\ensuremath{-}}\\ensuremath{\\rightarrow}\\text{Hadrons}$ at Energies from 2.2324 to 3.6710 GeV\n",
      "\n",
      "Based on electron-positron collision data collected with the BESIII detector operating at the Beijing Electron-Positron Collider II storage rings, the value of R≡σ(e+e−→hadrons)/σ(e+e−→μ+μ−) is measured at 14 center-of-mass energies from 2.2324 to 3.6710 GeV. The resulting uncertainties are less than 3.0% and are dominated by systematic uncertainties.\n",
      "\n",
      "---\n",
      "\n",
      "# 博士论文—J/psi共振参数测量\n",
      "\n",
      "中国科学院高能物理研究所机构知识库(IHEP OpenIR)以发展机构知识能力和知识管理能力为目标，快速实现对本机构知识资产的收集、长期保存、合理传播利用，积极建设对知识内容进行捕获、转化、传播、利用和审计的能力，逐步建设包括知识内容分析、关系分析和能力审计在内的知识服务能力，开展综合知识管理。\n",
      "\n",
      "---\n",
      "\n",
      "# Shower fractal dimension analysis in a highly-granular calorimeter\n",
      "\n",
      "We report on an investigation of the self-similar structure of particle showers recorded at a highly-granular calorimeter. On both simulated and experimental data, a strong correlation between the number of hits and the spatial scale of the readout channels is observed, from which we define the shower fractal dimension. The measured fractal dimension turns out to be strongly dependent on particle type, which enables new approaches for particle identification. A logarithmic dependence of the particle energy on the fractal dimension is also observed.\n",
      "\n",
      "---\n",
      "\n",
      "# Graph Neural Networks in Particle Physics\n",
      "\n",
      "Particle physics is a branch of science aiming at discovering the fundamental laws of matter and forces. Graph neural networks are trainable functions which operate on graphs---sets of elements and their pairwise relations---and are a central method within the broader field of geometric deep learning. They are very expressive and have demonstrated superior performance to other classical deep learning approaches in a variety of domains. The data in particle physics are often represented by sets and graphs and as such, graph neural networks offer key advantages. Here we review various applications of graph neural networks in particle physics, including different graph constructions, model architectures and learning objectives, as well as key open problems in particle physics for which graph neural networks are promising.\n",
      "\n",
      "---\n",
      "\n",
      "# Particle Flow Performance at CLIC\n",
      "\n",
      "Particle Flow has been used very successfully in the studies for linear colliders. At CLIC with an energy of 3 TeV considerable machine background is present in the detector. Using timing cuts based on particle ﬂow objects this background can be reduced signiﬁcantly. A systematic study is carried out to understand the dependence of the jet energy resolution on the jet energy and angle. The performance of particle ﬂow is evaluated based on the energy and mass resolution of W and Z particles in full simulation and reconstruction in the presence of background for both detector concepts considered for CLIC.\n",
      "\n",
      "---\n",
      "\n",
      "# CLD -- A Detector Concept for the FCC-ee\n",
      "\n",
      "This note gives a conceptual description and illustration of the CLD detector, based on the work for a detector at CLIC. CLD is one of the detectors envisaged at a future 100 km $e^+e^-$ circular collider (FCC-ee). The note also contains a brief description of the simulation and reconstruction tools used in the linear collider community, which have been adapted for physics and performance studies of CLD. The detector performance is described in terms of single particles, particles in jets, jet energy and angular resolution, and flavour tagging. The impact of beam-related backgrounds (incoherent $e^+e^-$ pairs and synchrotron radiation photons) on the performance is also discussed.\n",
      "\n",
      "---\n",
      "\n",
      "# Performance of particle flow calorimetry at CLIC\n",
      "\n",
      "The particle flow approach to calorimetry can provide unprecedented jet energy resolution at a future high energy collider, such as the International Linear Collider (ILC). However, the use of particle flow calorimetry at the proposed multi-TeV Compact Linear Collider (CLIC) poses a number of significant new challenges. At higher jet energies, detector occupancies increase, and it becomes increasingly difficult to resolve energy deposits from individual particles. The experimental conditions at CLIC are also significantly more challenging than those at previous electron–positron colliders, with increased levels of beam-induced backgrounds combined with a bunch spacing of only 0.5ns. This paper describes the modifications made to the PandoraPFA particle flow algorithm to improve the jet energy reconstruction for jet energies above 250GeV. It then introduces a combination of timing and pT cuts that can be applied to reconstructed particles in order to significantly reduce the background. A systematic study is performed to understand the dependence of the jet energy resolution on the jet energy and angle, and the physics performance is assessed via a study of the energy and mass resolution of W and Z particles in the presence of background at CLIC. Finally, the missing transverse momentum resolution is presented, and the fake missing momentum is quantified. The results presented in this paper demonstrate that high granularity particle flow calorimetry leads to a robust and high resolution reconstruction of jet energies and di-jet masses at CLIC.\n",
      "\n",
      "---\n",
      "\n",
      "# QCD formulation of the tau decay and determination of ΛMS¯\n",
      "\n",
      "We present a simple formulation of the inclusive and exclusive semi-hadronic decays of the tau lepton using QCD-duality finite energy sum rules (FESRs). We find that the tau decay is a good laboratory for measuring the QCD scaleΛ. Within the present experimental accuracy, we obtain ΛMS¯ ⋍ 100–200 MeV to four loops. This prediction can be sensibly improved once the experimental situation has been clarified.\n",
      "\n",
      "---\n",
      "\n",
      "# Perturbative QCD corrections to the ratio R for \\ensuremath{\\tau} decay\n",
      "\n",
      "The perturbative QCD correction to the semihadronic decay rate of a heavy lepton is expressed as an expansion in αs. In the case of the τ lepton, the ratio of the semihadronic and electronic decay rates is R=3[1+αs/π+5.20(αs/π)2 +104.0(αs/π)3]. The use of R to give a precise determination of αs is advocated.\n",
      "\n",
      "---\n",
      "\n",
      "# QCD predictions for the decay of the \\ensuremath{\\tau} lepton\n",
      "\n",
      "The semileptonic decay rate of a heavy lepton is shown to be rigorously calculable by use of perturbative QCD. Even the τ lepton is heavy enough for the perturbative approximation to be accurate. The prediction for the ratio R=Γ(τ→vτ+hadrons)/Γ(τ→vτ+e−+v¯e) is 3.29, with an uncertainty of about 1% due to the uncertainty in the Λ parameter of QCD. Nonperturbative corrections to this prediction are estimated to be on the order of 1%. More importantly, these corrections are shown to be negative because of a fortuitous cancellation of the leading contribution from the gluon condensate. The resulting prediction is significantly smaller than the present experimental result R=3.65±0.13.\n",
      "\n",
      "---\n",
      "\n",
      "# Standard Model Theory for the FCC-ee Tera-Z stage\n",
      "\n",
      "The future 100-km circular collider FCC at CERN is planned to operate in one of its modes as an electron-positron FCC-ee machine. We give an overview comparing the theoretical status to the experimental demands of one of four foreseen FCC-ee operating stages, Z-boson resonance energy physics, called the FCC-ee Tera-Z stage for short. The FCC-ee Tera-Z will deliver the highest integrated luminosities as well as very small systematic errors for a study of the Standard Model (SM) with unprecedented precision. In fact, the FCC-ee Tera-Z will allow the study of at least one more perturbative order in quantum field theory compared to the LEP/SLC precision. The real problem is that the present precision of theoretical calculations of the various SM observables does not match that of the anticipated experimental measurements. The bottle-necks to overcoming this situation are identified. In particular, the issues of precise QED unfolding and the correct calculation of SM pseudo-observables are critically reviewed. In an Executive Summary, we specify which basic theoretical calculations are needed to meet the strong experimental expectations at the FCC-ee Tera-Z. Several methods, techniques and tools needed for higher-order multi-loop calculations are presented. By inspection of the Z-boson partial and total decay width analyses, it is argued that at the beginning of operation of the FCC-ee Tera-Z, the theory predictions may be tuned to be precise enough not to limit the physics interpretation of the measurements. This statement is based on anticipated progress in analytical and numerical calculations of multi-loop and multi-scale Feynman integrals and on the completion of two-loop electroweak radiative corrections to the SM pseudo-observables this year. However, the above statement is conditional as the theoretical issues demand a very dedicated and focused investment by the community.\n",
      "\n",
      "---\n",
      "\n",
      "# Theory for the FCC-ee : Report on the 11th FCC-ee Workshop\n",
      "\n",
      "The Future Circular Collider (FCC) at CERN, a proposed 100-km circular facility with several colliders in succession, culminates with a 100 TeV proton-proton collider. It offers a vast new domain of exploration in particle physics, with orders of magnitude advances in terms of Precision, Sensitivity and Energy. The implementation plan foresees, as a first step, an Electroweak Factory electron-positron collider. This high luminosity facility, operating between 90 and 365 GeV centre-of-mass energy, will study the heavy particles of the Standard Model, Z, W, Higgs, and top with unprecedented accuracy. The Electroweak Factory $e^+e^-$ collider constitutes a real challenge to the theory and to precision calculations, triggering the need for the development of new mathematical methods and software tools. A first workshop in 2018 had focused on the first FCC-ee stage, the Tera-Z, and confronted the theoretical status of precision Standard Model calculations on the Z-boson resonance to the experimental demands. The second workshop in January 2019, which is reported here, extended the scope to the next stages, with the production of W-bosons (FCC-ee-W), the Higgs boson (FCC-ee-H) and top quarks (FCC-ee-tt). In particular, the theoretical precision in the determination of the crucial input parameters, alpha_QED, alpha_QCD, M_W, m_t at the level of FCC-ee requirements is thoroughly discussed. The requirements on Standard Model theory calculations were spelled out, so as to meet the demanding accuracy of the FCC-ee experimental potential. The discussion of innovative methods and tools for multi-loop calculations was deepened. Furthermore, phenomenological analyses beyond the Standard Model were discussed, in particular the effective theory approaches. The reports of 2018 and 2019 serve as white papers of the workshop results and subsequent developments.\n",
      "\n",
      "---\n",
      "\n",
      "# High precision determination of the gluon fusion Higgs boson cross-section at the LHC\n",
      "\n",
      "We present the most precise value for the Higgs boson cross-section in the gluon-fusion production mode at the LHC. Our result is based on a perturbative expansion through N3LO in QCD, in an effective theory where the top-quark is assumed to be infinitely heavy, while all other Standard Model quarks are massless. We combine this result with QCD corrections to the cross-section where all finite quark-mass effects are included exactly through NLO. In addition, electroweak corrections and the first corrections in the inverse mass of the top-quark are incorporated at three loops. We also investigate the effects of threshold resummation, both in the traditional QCD framework and following a SCET approach, which resums a class of π2 contributions to all orders. We assess the uncertainty of the cross-section from missing higher-order corrections due to both perturbative QCD effects beyond N3LO and unknown mixed QCD-electroweak effects. In addition, we determine the sensitivity of the cross-section to the choice of parton distribution function (PDF) sets and to the parametric uncertainty in the strong coupling constant and quark masses. For a Higgs mass of mH= 125 GeV and an LHC center-of-mass energy of 13 TeV, our best prediction for the gluon fusion cross-section isσ=48.58pb−3.27pb+2.22pbtheory±1.56pb3.20%PDF+αs.$$ \\sigma =48.58\\;{\\mathrm{pb}}_{-3.27\\;\\mathrm{p}\\mathrm{b}}^{+2.22\\;\\mathrm{p}\\mathrm{b}}\\left(\\mathrm{theory}\\right)\\pm 1.56\\;\\mathrm{p}\\mathrm{b}\\left(3.20\\%\\right)\\left(\\mathrm{P}\\mathrm{D}\\mathrm{F}+{\\alpha}_s\\right). $$\n",
      "\n",
      "---\n",
      "\n",
      "# Leading QCD-induced four-loop contributions to the β-function of the Higgs self-coupling in the SM and vacuum stability\n",
      "\n",
      "We present analytical results for the leading top-Yukawa and QCD contribution to the β-function for the Higgs self-coupling λ of the Standard Model at four-loop level, namely the part ∝ yt4gs6independently confirming a result given in [1]. We also give the contribution ∝ yt2gs6of the anomalous dimension of the Higgs field as well as the terms ∝ ytgs8to the top-Yukawa β-function which can also be derived from the anomalous dimension of the top quark mass. We compare the results with the RG functions of the correlators of two and four scalar currents in pure QCD and find a new relation between the anomalous dimension γ0 of the QCD vacuum energy and the anomalous dimension γmSSappearing in the RG equation of the correlator of two scalar currents. Together with the recently computed top-Yukawa and QCD contributions to βgs[2, 3] the β-functions presented here constitute the leading four-loop contributions to the evolution of the Higgs self-coupling. A numerical estimate of these terms at the scale of the top-quark mass is presented as well as an analysis of the impact on the evolution of λ up to the Planck scale and the vacuum stability problem.\n",
      "\n",
      "---\n",
      "\n",
      "# Particle Identification Using Boosted Decision Trees in the Semi-Digital Hadronic Calorimeter Prototype\n",
      "\n",
      "The CALICE Semi-Digital Hadronic CALorimeter (SDHCAL) prototype using Glass Resistive Plate Chambers as a sensitive medium is the ﬁrst technological prototype of a family of high-granularity calorimeters developed by the CALICE collaboration to equip the experiments of future leptonic colliders. It was exposed to beams of hadrons, electrons and muons several times in the CERN PS and SPS beamlines between 2012 and 2018. We present here a new method of particle identiﬁcation within the SDHCAL using the Boosted Decision Trees (BDT) method applied to the data collected in 2015. The performance of the method is tested ﬁrst with Geant4-based simulated events and then on the data collected by the SDHCAL in the energy range between 10 and 80 GeV with 10 GeV energy steps. The BDT method is then used to reject the electrons and muons that contaminate the SPS hadron beams.\n",
      "\n",
      "---\n",
      "\n",
      "# 4D tracking with ultra-fast silicon detectors\n",
      "\n",
      "The evolution of particle detectors has always pushed the technological limit in order to provide enabling technologies to researchers in all fields of science. One archetypal example is the evolution of silicon detectors, from a system with a few channels 30 years ago, to the tens of millions of independent pixels currently used to track charged particles in all major particle physics experiments. Nowadays, silicon detectors are ubiquitous not only in research laboratories but in almost every high-tech apparatus, from portable phones to hospitals. In this contribution, we present a new direction in the evolution of silicon detectors for charge particle tracking, namely the inclusion of very accurate timing information. This enhancement of the present silicon detector paradigm is enabled by the inclusion of controlled low gain in the detector response, therefore increasing the detector output signal sufficiently to make timing measurement possible. After providing a short overview of the advantage of this new technology, we present the necessary conditions that need to be met for both sensor and readout electronics in order to achieve 4D tracking. In the last section, we present the experimental results, demonstrating the validity of our research path.\n",
      "\n",
      "---\n",
      "\n",
      "# 4-Dimensional Tracking with Ultra-Fast Silicon Detectors\n",
      "\n",
      "The evolution of particle detectors has always pushed the technological limit in order to provide enabling technologies to researchers in all fields of science. One archetypal example is the evolution of silicon detectors, from a system with a few channels 30 years ago, to the tens of millions of independent pixels currently used to track charged particles in all major particle physics experiments. Nowadays, silicon detectors are ubiquitous not only in research laboratories but in almost every high-tech apparatus, from portable phones to hospitals. In this contribution, we present a new direction in the evolution of silicon detectors for charge particle tracking, namely the inclusion of very accurate timing information. This enhancement of the present silicon detector paradigm is enabled by the inclusion of controlled low gain in the detector response, therefore increasing the detector output signal sufficiently to make timing measurement possible. After providing a short overview of the advantage of this new technology, we present the necessary conditions that need to be met for both sensor and readout electronics in order to achieve 4-dimensional tracking. In the last section we present the experimental results, demonstrating the validity of our research path.\n",
      "\n",
      "---\n",
      "\n",
      "# Test beam studies of silicon timing for use in calorimetry\n",
      "\n",
      "The high luminosity upgrade of the Large Hadron Collider (HL-LHC) at CERN is expected to provide instantaneous luminosities of 5 × 1034 cm−2 s−1. The high luminosities expected at the HL-LHC will be accompanied by a factor of 5–10 more pileup compared with LHC conditions in 2015, further increasing the challenge for particle identiﬁcation and event reconstruction. Precision timing allows us to extend calorimetric measurements into such a high density environment by subtracting the energy deposits from pileup interactions. Calorimeters employing silicon as the active component have recently become a viable choice for the HL-LHC and future collider experiments which face very high radiation environments. In this paper, we present studies of basic calorimetric and precision timing measurements using a prototype composed of tungsten absorber and silicon sensor as the active medium. We show that for the bulk of electromagnetic showers induced by electrons in the range of 20–30 GeV, we can achieve time resolutions better than 25 ps per single pad sensor.\n",
      "\n",
      "---\n",
      "\n",
      "# Investigation of fast timing capabilities of silicon sensors for the CMS high granularity calorimeter at HL-LHC\n",
      "\n",
      "The High Granularity Calorimeter (HGCAL) is the technology choice of the CMS collaboration for the endcap calorimetry upgrade planned to cope with the harsh radiation and unprecedented in-time event pileup projected at the High Luminosity-LHC era. In this context, proﬁting from fast-timing information ( tens of picoseconds) embedded in the calorimeter would represent a unique capability for resolving information from individual collisions at the HL-LHC. This will enhance the reconstruction and physics capabilities of the CMS detector in terms of pileup mitigation and particle identiﬁcation. The HGCAL is realized as a sampling calorimeter, including 40 layers of silicon pad detectors with pad areas of 0.5 ?? 1.0 cm2andthreeactivethicknesses320, 200and120m.P rototypep − in − nandn − in−p5x5mm2siliconpads, withthicknessesof 285, 211and133m, weretestedwithhigh−energyelectronsattheCERN SP S timingintheHGCAL, andthemeasuredintrinsictimingcapabilitiesf orelectromagneticshowersandminimum− ionisingparticles.\n",
      "\n",
      "---\n",
      "\n",
      "# Performance of the ALEPH detector at LEP\n",
      "\n",
      "The performance of the ALEPH detector at the LEP e+e− collider is reviewed. The accuracy of the tracking detectors to measure the impact parameter and momentum of charged tracks is specified. Calorimeters are used to measure photons and neutral hadrons, and the accuracy obtained in energy and angle is given. An essential property of the detector is its ability to identify particles; the performance in identification of electrons, muons, neutrinos (from missing energy), charged hadrons, π0's and V0's is described.\n",
      "\n",
      "---\n",
      "\n",
      "# The CLEO II detector\n",
      "\n",
      "The new detector for data recording by the CLEO collaboration at the Cornell Electron Storage Ring is described. This detector has been designed to optimize studying e+ e− annihilation into hadronic matter at a total energy of 10 GeV. It consists of high precesion charged particle tracking chambers and an electromagnetic calorimeter together with systems for particle identification. The design of the detector and its performance over the first year and a half of operation are presented.\n",
      "\n",
      "---\n",
      "\n",
      "# Jet Charge Measurement Using the Leading Charged Particles at e+e− → Z → qq¯ Process at CEPC Z pole operation\n",
      "\n",
      "Precise jet charge reconstruction is essential for electroweak precision measurements at high energy frontier. We developed a simple jet charge reconstruction algorithm using the leading hadron in the identified jet. Testing at the MC truth level, and using the leading particle of Z pole Z → b¯b and Z → cc¯ samples, the algorithm achieves a benchmark effective tagging power value of 9.0% for the b jet and 20.0% for the c jet by Whizard195. We also find that the performance of jet charge is highly dependent on the type of the final leading charged particle, the type of leading hadron, and the source of the final leading charged particle at each jet. Moreover, the effective tagging power of jet charge is different between different generators.\n",
      "\n",
      "---\n",
      "\n",
      "# Weightfield2: A fast simulator for silicon and diamond solid state detector\n",
      "\n",
      "We have developed a fast simulation program to study the performance of silicon and diamond detectors, Weightfield2. The program uses GEANT4 libraries to simulate the energy released by an incoming particle in silicon (or diamond), and Ramo׳s theorem to generate the induced signal current. A graphical interface allows the user to configure many input parameters such as the incident particle, sensor geometry, presence and value of internal gain, doping of silicon sensor and its operating conditions, the values of an external magnetic field, ambient temperature and thermal diffusion. A simplified electronics simulator is also implemented to include the response of an oscilloscope and front-end electronics. The program has been validated by comparing its predictions for minimum ionizing and α particles with measured signals and TCAD simulations, finding very good agreement in both cases.\n",
      "\n",
      "---\n",
      "\n",
      "# Design optimization of ultra-fast silicon detectors\n",
      "\n",
      "Low-Gain Avalanche Diodes (LGAD) are silicon detectors with output signals that are about a factor of 10 larger than those of traditional sensors. In this paper we analyze how the design of LGAD can be optimized to exploit their increased output signal to reach optimum timing performances. Our simulations show that these sensors, the so-called Ultra-Fast Silicon Detectors (UFSD), will be able to reach a time resolution factor of 10 better than that of traditional silicon sensors.\n",
      "\n",
      "---\n",
      "\n",
      "# First beam tests of prototype silicon modules for the CMS High Granularity Endcap Calorimeter\n",
      "\n",
      "The High Luminosity phase of the Large Hadron Collider will deliver 10 times more integrated luminosity than the existing collider, posing significant challenges for radiation tolerance and event pileup on detectors, especially for forward calorimetry. As part of its upgrade program, the Compact Muon Solenoid collaboration is designing a high-granularity calorimeter (HGCAL) to replace the existing endcap calorimeters. It will feature unprecedented transverse and longitudinal readout and triggering segmentation for both electromagnetic and hadronic sections. The electromagnetic section and a large fraction of the hadronic section will be based on hexagonal silicon sensors of 0.5–1 cm2 cell size, with the remainder of the hadronic section being based on highly-segmented scintillators with silicon photomultiplier readout. The intrinsic high-precision timing capabilities of the silicon sensors will add an extra dimension to event reconstruction, especially in terms of pileup rejection. First hexagonal silicon modules, using the existing Skiroc2 front-end ASIC developed for CALICE, have been tested in beams at Fermilab and CERN in 2016. We present results from these tests, in terms of system stability, calibration with minimum-ionizing particles and resolution (energy, position and timing) for electrons, and the comparisons of these quantities with GEANT4-based simulation.\n",
      "\n",
      "---\n",
      "\n",
      "# Precision timing calorimetry with the CMS HGCAL\n",
      "\n",
      "The existing CMS endcap calorimeters will be replaced with a High Granularity Calorimeter (HGCAL) for operation at the High Luminosity (HL) LHC . Radiation hardness and excellent physics performance will be achieved by utilising silicon pad sensors and SiPM-on-scintillator tiles with high longitudinal and transverse segmentation. One of the major challenges of the HL-LHC will be the high pileup environment, with interaction vertices spread not only in position, but also in time. In order to efficiently reject particles originating from pileup, precision timing information of the order of 30 ps will be of great benefit. In order to meet such performance goals, the HGCAL will provide timing measurements for individual hits with signals above 12 fC (equivalent to 3–10 MIPs), such that clusters resulting from particles with pT > 5 GeV should have a timing resolution better than 30 ps. Given the complexity and size of the system, this poses a particular challenge to the readout electronics as well as to the calibration and reconstruction procedures. We present the challenges for the front-end electronics design, results from prototype tests in laboratory and beam environments, as well as anticipated timing performance from simulation.\n",
      "\n",
      "---\n",
      "\n",
      "# Software digitizer for high granular gaseous detector\n",
      "\n",
      "A sampling calorimeter using gaseous sensor layers with digital readout [1] is near perfect for “Particle Flow Algorithm” [2,3] approach, since it is homogeneous over large surfaces, robust, cost efficient, easily segmentable to any readout pad dimension and size and almost insensitive to neutrons. Monte-Carlo (MC) programs such as GEANT4 [4] simulate with high precision the energy deposited by particles. The sensor and electronic response associated to a pad are calculated in a separate “digitization” process. We develop a general method for simulating the pad response using the spatial information from a simulation done at high granularity. The digitization method proposed here has been applied to gaseous detectors including Glass Resistive Plate Chambers (GRPC) and MicroMegas, and validated on test beam data. Experimental observable such as pad multiplicity and mean number of hits at different thresholds have been reproduced with high precision.\n",
      "\n",
      "---\n",
      "\n",
      "# 博士论文-北京谱仪含粲夸克强子产生与衰变的实验研究\n",
      "\n",
      "本文介绍了利用北京谱仪上质心系能量为4.009 GeV 的数据精确测量D 0 的衰变分支比的过程，结果的误差比世界平均值精确3 倍，将相关模型的参数，例如粲夸克的磁矩等限制得更为精确。\n",
      "\n",
      "---\n",
      "\n",
      "# High performance timing detectors for high energy physics experiments and new developments for the high luminosity LHC\n",
      "\n",
      "In recent years precision timing detectors have increasingly captured the interest of the particle physicists, for their potential as time of flight detectors in high luminosity collider experiments as the LHC. In Phase-1 of the LHC, the experiments have exploited a global event description, making use of all subdetector information (tracks, calorimeter hits and muon chamber hits) to optimize the particle energy and position measurement depending on the particle type. This technique usually referred to as “particle flow” has a beneficial effect particularly on the jet energy and on the missing transverse energy resolution. In 2025 a new phase of the Large Hadron Collider will begin with increased instantaneous luminosity (HL-LHC) and a number of concurrent proton-proton interactions per bunch crossing as high as 200. Therefore the events will have very high vertex and track density, and high hit occupancy will be detected in the calorimeters. Hence the need to exploit additional measurement, like the timing information, for the track to vertex matching algorithms and for the association of calorimeter hits to tracks, in order to be able to efficiently use the particle flow technique in these harsher conditions. This lecture reviews the existing detectors with fast and precise timing measurement as well as the physics motivation for their use. It will introduce the various detector technologies able to achieve high performance in timing: Micro-channel plates, scintillation crystals coupled to high gain photodetectors, and silicon based detectors as Low Gain Avalanche devices.\n",
      "\n",
      "---\n",
      "\n",
      "# CMS precision timing physics impact for the HL-LHC upgrade\n",
      "\n",
      "As part of the Phase II upgrade program, the Compact Muon Solenoid (CMS) detector will incorporate a new timing layer designed to measure minimum ionizing particles (MIPs) with a time resolution of $\\sim$30 ps. Precision timing will mitigate the impact of the challenging levels of pileup expected at the High Luminosity LHC. The time information assigned to each track will enable the use of 4D-vertexing which will render a 5-fold pile-up reduction, thus recovering the current conditions. Precision timing will also enable new time-based isolations and improved $b$-tagging algorithms. All of this translates into a $\\sim20\\%$ gain in effective luminosity when looking at di-Higgs boson events decaying to a pair of $b$-quarks and two photons. We present the expected improvements in physics performance with precision timing with the upgraded CMS detector.\n",
      "\n",
      "---\n",
      "\n",
      "# Precision timing calorimeter for high energy physics\n",
      "\n",
      "Scintillator based calorimeter technology is studied with the aim to achieve particle detection with a time resolution on the order of a few 10ps for photons and electrons at energies of a few GeV and above. We present results from a prototype of a 1.4×1.4×11.4cm3 sampling calorimeter cell consisting of tungsten absorber plates and Cerium-doped Lutetium Yttrium Orthosilicate (LYSO) crystal scintillator plates. The LYSO plates are read out with wave lengths shifting fibers which are optically coupled to fast photo detectors on both ends of the fibers. The measurements with electrons were performed at the Fermilab Test Beam Facility (FTBF) and the CERN SPS H2 test beam. In addition to the baseline setup plastic scintillation counter and a MCP-PMT were used as trigger and as a reference for a time of flight measurement (TOF). We also present measurements with a fast laser to further characterize the response of the prototype and the photo sensors. All data were recorded using a DRS4 fast sampling digitizer. These measurements are part of an R&D program whose aim is to demonstrate the feasibility of building a large scale electromagnetic calorimeter with a time resolution on the order of 10ps, to be used in high energy physics experiments.\n",
      "\n",
      "---\n",
      "\n",
      "# 博士论文-ψ'->τ+τ-分支比的测量与BESIII μ探测器的研制\n",
      "\n",
      "对轻子普适性进行精确检验是北京谱仪的主要物理目标之一。本文的第一部分利用北京谱仪BESII在北京正负电子对撞机BEPC上采集的14M psi(2S)数据，测量了psi(2S)->tau+tau-分支比为:(3.08+-0.21+-0.38)E-3，其中第一项为统计误差，第二项为系统误差。与PDG给出的值相比，此结果在更小的误差范围内和其他实验组给出的psi(2S)到e+e-，muon+muon-的分支比的结果满足理论所预言的关系，从而更精确的检验了轻子普适性的理论。;   要在BESIII上做对此理论做进一步精确的检验，条件之一是要求muon子探测器具有更高的探测效率，更大的覆盖立体角，更好的muon/pion分辨，更低的muon子截止动量，同时还必须能在BEPCII的本底计数下稳定运行。为满足以上要求，BESIII的muon子探测器选用了阻性板室(RPC)。本文的第二部分对阻性板室的性能进行了系统的研究，实验结果表明：使用Ar/F134A/Iso-butane(50/42/8)并采用体电阻率为2×1011～2×1012ohm&#8226;cm（20c）的2mm气隙的阻性板室可以获得8000 V时效率大于95%，计数率小于0.2Hz/ cm2的优越性能，而且在经过10个“BES”年的电子辐照计量的照射后，阻性板室仍能正常工作。; BESIII将使用约1200m2的muon子探测器，为了保证其质量，利用ALEPH的流光管室对muon子探测器进行了宇宙线测试。测试结果显示，排除电子学的影响，muon子探测器的平均效率可达98%以上，空间分辨为13～16mm。muon子探测器可达到预期性能。目前，已经完成了muon子探测器在BESIII上的安装与测试。\n",
      "\n",
      "---\n",
      "\n",
      "# 博士论文-ψ(2S)共振参数的测量\n",
      "\n",
      "自从ψ（2S）粒子发现以来，不同实验组给出的ψ（2S）粒子衰变总宽度，衰变为μ<'+>μ<'->、π<'+>π<'->-Jψ和强子末太怕部分宽度及分支比的测量值一直存在差异.为了改善现状，提高测量精度，北京谱仪（BES）依据细致切实的方案在北京正负电子对撞机（BEPC）上进行了为期一周的ψ（2S）的精细扫描，获取24个能量眯近三百万在线事例.该文还详细地介绍了接收度计算中涉及到有有关概念、原则和技巧.对于误差分析的一般概念和基本原则也作了条理化、简化化的说明.详细地研究了上述各过程的系统误差.\n",
      "\n",
      "---\n",
      "\n",
      "# The Phase-2 Upgrade of the CMS Endcap Calorimeter\n",
      "\n",
      "Technical Design Report of the endcap calorimeter for the Phase-2 upgrade of the CMS experiment, in view of the HL-LHC run.\n",
      "\n",
      "---\n",
      "\n",
      "# Geant4—a simulation toolkit\n",
      "\n",
      "Geant4 is a toolkit for simulating the passage of particles through matter. It includes a complete range of functionality including tracking, geometry, physics models and hits. The physics processes offered cover a comprehensive range, including electromagnetic, hadronic and optical processes, a large set of long-lived particles, materials and elements, over a wide energy range starting, in some cases, from 250eV and extending in others to the TeV energy range. It has been designed and constructed to expose the physics models utilised, to handle complex geometries, and to enable its easy adaptation for optimal use in different sets of applications. The toolkit is the result of a worldwide collaboration of physicists and software engineers. It has been created exploiting software engineering and object-oriented technology and implemented in the C++ programming language. It has been used in applications in particle physics, nuclear physics, accelerator design, space engineering and medical physics.\n",
      "\n",
      "---\n",
      "\n",
      "# THE GAUSSIAN TRANSFORM\n",
      "\n",
      "This paper introduces the general purpose Gaussian Transform, which aims at representing a generic symmetric distribution as an infinite mixture of Gaussian distributions. We start by the mathematical formulation of the problem and continue with the investigation of the conditions of existence of such a transform. Our analysis leads to the derivation of analytical and numerical tools for the computation of the Gaussian Transform, mainly based on the Laplace and Fourier transforms, as well as of the afferent properties set (e.g. the transform of sums of independent variables).\n",
      "\n",
      "---\n",
      "\n",
      "# On the timing performance of thin planar silicon sensors\n",
      "\n",
      "We report on the signal timing capabilities of thin silicon sensors when traversed by multiple simultaneous minimum ionizing particles (MIP). Three different planar sensors, with depletion thicknesses 133, 211, and 285µm, have been exposed to high energy muons and electrons at CERN. We describe signal shape and timing resolution measurements as well as the response of these devices as a function of the multiplicity of MIPs. We compare these measurements to simulations where possible. We achieve better than 20ps timing resolution for signals larger than a few tens of MIPs.\n",
      "\n",
      "---\n",
      "\n",
      "# Search for the Lepton Flavor Violation Process $J/\\psi \\to e\\mu$ at BESIII\n",
      "\n",
      "We search for the lepton-flavor-violating decay of the $J/\\psi$ into an electron and a muon using $(225.3\\pm2.8)\\times 10^{6}$ $J/\\psi$ events collected with the BESIII detector at the BEPCII collider. Four candidate events are found in the signal region, consistent with background expectations. An upper limit on the branching fraction of $\\mathcal{B}(J/\\psi \\to e\\mu)< 1.5 \\times 10^{-7}$ (90% C.L.) is obtained.\n",
      "\n",
      "---\n",
      "\n",
      "# Detailed studies of hadronic showers and comparison to GEANT4 simulations with data from highly granular calorimeters\n",
      "\n",
      "The highly granular calorimeter prototypes of the CALICE collaboration have provided large data samples with precise three-dimensional information on hadronic showers with steel and tungsten absorbers and silicon, scintillator and gas detector readout. From these data sets, detailed measurements of the spatial structure, including longitudinal and lateral shower profiles and of the shower substructure and time structure are extracted. Recent analyses have extended these studies to different particle species in calorimeters with scintillator readout and steel and tungsten absorbers, to energies below 10 GeV in a silicon tungsten calorimeter and have provided first studies of the shower substructure with gaseous readout and unprecedented granularity of $1\\times1$~cm$^{2}$ over a full cubic meter. These results are confronted with Geant4 simulations with different hadronic physics models. They present new challenges to the simulation codes and provide the possibility to validate and improve the simulation of hadronic interactions in high-energy physics detectors.\n",
      "\n",
      "---\n",
      "\n",
      "# The H → b¯b, cc¯, gg measurement at CEPC\n",
      "\n",
      "To measure precisely the Higgs boson properties is the core physics objective of the Circular Electron Positron Collider (CEPC), a proposed electron positron Higgs/Z factory. Corresponding to the nominal CEPC Higgs operation, which designed at center-ofmass energy of 240 GeV and integrated luminosity of 5600 f b−1, the anticipated precisions of the H → b¯b, cc¯, gg signal strengths at a fully simulated data sample of the CEPC baseline detector has been estimated. Combing the measurements from llH, ννH and qqH channels, we conclude that the signal strength of H → b¯b/cc¯/gg can be measured to a relative accuracy of 0.26%/3.67%/1.31% at the CEPC. In addition, we analyze the dependence between the anticipated accuracies and the key reconstruction performance: the color singlet identiﬁcation for the qqH channel, and the ﬂavor tagging for both ννH and qqH channels. We observe that compared to the CEPC baseline reconstruction, an ideal ﬂavor tagging could boost the accuracies of H → cc/gg signal strength by 53%/19% and 157%/55% for the ννH and qqH channels, respectively. Meanwhile, an ideal color singlet identiﬁcation could also improve the accuracy of H → cc/gg at qqH channel by another factor of 0.43/0.33. Our analyses quantify the physics potential of CEPC on the H → b¯b, cc¯, gg measurements, and the impacts of improving the CSI/ﬂavor tagging performance. The latter strongly motivate the development of relative innovative detector/reconstruction algorithm development.\n",
      "\n",
      "---\n",
      "\n",
      "# Determination of the $e^ + e^- \\to \\gamma \\gamma (\\gamma)$cross-section at LEP 2\n",
      "\n",
      "A test of the benchmark QED process $e^ + e^- \\to \\gamma \\gamma (\\gamma)$is reported, using the data collected with the DELPHI detector at LEP 2. The data analysed were recorded at centre-of-mass energies ranging from 161 GeV to 208 GeV and correspond to a total integrated luminosity of 656.4 pb-1. The Born cross-section for the process $e^ + e^- \\to \\gamma \\gamma (\\gamma)$was determined, confirming the validity of QED at the highest energies ever attained in electron-positron collisions. Lower limits on the parameters of a number of possible deviations from QED, predicted within theoretical frameworks expressing physics beyond the Standard Model, were derived.\n",
      "\n",
      "---\n",
      "\n",
      "# Measurement of the e+e− → γγ(γ) cross section at LEP energies\n",
      "\n",
      "The total and the differential cross sections for the reaction e+e− → γγ(γ) have been measured with the DELPHI detector at LEP using an integrated luminosity of 36.9 pb−1. The results agree with the QED predictions and consequently there is no evidence for non-standard channels with the same experimental signature. The lower limits obtained on the QED cutoff parameters are Λ+ > 143 GeV and Λ− > 120 GeV, and the lower bound on the mass of an excited electron with an effective coupling constant λγ = 1 is 132 GeV/c2. Upper limits on the branching ratios for the decays Z0 → γγ, Z0 → π0γ, Z0 → ηγ and Z0 → γγγ have been determined to be 5.5 × 10−5, 5.5 × 10−5, 8.0 × 10−5, and 1.7 × 10−5 respectively. All the limits are at the 95% confidence level.\n",
      "\n",
      "---\n",
      "\n",
      "# Study of photon detection efficiency in e+e− → γμ+μ− process\n",
      "\n",
      "We study the photon detection efficiency using 9 billion J/ψ event collected in 2009, 2018 and 2019 using a control sample of the initial-state-radiative (ISR) process e+e− → γμ+μ−. The ISR photon in this control sample is predicted using the four momenta of two charged tracks only. This predicted photon is used to study the energy and position resolu- tions of the electromagnetic calorimeter (EMC) as well as the photon detection efficiency. The photon detection efficiency is defined as the fraction of predicted photon matched with the actual photons in the EMC. The systematic uncertainty, defined as the relative difference in efficiency between data and Monte Carlo simulation, due to photon reconstruction effi- ciency is observed to be up to the level of 0.5% in both barrel and end-cap regions. This systematic uncertainty is further improved by using the inclusive J/ψ MC sample that in- cludes the contributions of both J/ψ → μ+μ−(γ) and J/ψ → γπ+π− decays as well as a tiny background contribution of J/ψ → π+π−π0 decay. The relative difference in efficiency between data and inclusive J/ψ MC sample is found to be less than 0.2%.\n",
      "\n",
      "---\n",
      "\n",
      "# Photon Reconstruction Performance at the CEPC baseline detector\n",
      "\n",
      "The Circular Electron Positron Collider (CEPC) is a proposed Higgs/Z factory. The photon reconstruction is critical to its physics program. We study the photon reconstruction at the CEPC baseline detector, a Particle Flow oriented detector. We characterized the objective performance at both single-photon and di-photon samples. At the single-photon sample, we quantify the photon conversion rate, the differential reconstruction efficiency and energy resolution, and the identification performance. Using di-photon samples, our analysis shows that the CEPC baseline detector reaches a relative mass resolution of 1.7 - 2.2% of the Higgs boson at the $H\\to\\gamma\\gamma$ sample, and can reconstruct the $\\pi^0$ with energy as high as 20 - 30 GeV. We also investigate the impact of geometry defects on photon energy resolution and discuss the possible corrections according to the reconstructed photon position.\n",
      "\n",
      "---\n",
      "\n",
      "# Tau-lepton Physics at the FCC-ee circular e$^+$e$^-$ Collider\n",
      "\n",
      "SciPost Journals Publication Detail SciPost Phys. Proc. 1, 041 (2019) Tau-lepton Physics at the FCC-ee circular e$^+$e$^-$ Collider\n",
      "\n",
      "---\n",
      "\n",
      "# Blossom V: a new implementation of a minimum cost perfect matching algorithm\n",
      "\n",
      "We describe a new implementation of the Edmonds’s algorithm for computing a perfect matching of minimum cost, to which we refer as Blossom V. A key feature of our implementation is a combination of two ideas that were shown to be effective for this problem: the “variable dual updates” approach of Cook and Rohe (INFORMS J Comput 11(2):138–148, 1999) and the use of priority queues. We achieve this by maintaining an auxiliary graph whose nodes correspond to alternating trees in the Edmonds’s algorithm. While our use of priority queues does not improve the worst-case complexity, it appears to lead to an efficient technique. In the majority of our tests Blossom V outperformed previous implementations of Cook and Rohe (INFORMS J Comput 11(2):138–148, 1999) and Mehlhorn and Schäfer (J Algorithmics Exp (JEA) 7:4, 2002), sometimes by an order of magnitude. We also show that for large VLSI instances it is beneficial to update duals by solving a linear program, contrary to a conjecture by Cook and Rohe.\n",
      "\n",
      "---\n",
      "\n",
      "# Improving the Prompt Electromagnetic Energy Component of Jet Energy Resolution with pi0 Fitting in High Granularity Electromagnetic Calorimeters\n",
      "\n",
      "We investigate improving the hadronic jet energy resolution using mass-constrained fits of pi0 decays using high granularity electromagnetic calorimeters. Single pi0 studies have indicated a large potential for improvement in the energy resolution of pi0's, typically reducing the average energy resolution by a factor of two for 4 GeV pi0's. We apply this method to fully simulated multi-hadronic events with multiple pi0's with widely varying energies using the ILD00 detector model. Several methods for identifying the correct pairings of photons with parent pi0's were explored. The combinatorics become challenging as the number of pi0's increases and we employ the Blossom V implementation of Edmonds' matching algorithm for handling this. For events where both photons of the pi0 are detected, the resulting solutions lead to an improvement in the pi0 component of the event energy resolution for 91.2 GeV Z0 events from 18.0%/sqrt(E) to 13.9%/sqrt(E) using the ILD00 detector and its reconstruction algorithms. This can be compared to a maximum potential improvement to 12.2%/sqrt(E) if all photon pairs are matched correctly using the current photon reconstruction.\n",
      "\n",
      "---\n",
      "\n",
      "# Resolution of RD/RD⁎ puzzle\n",
      "\n",
      "One of the exciting results in flavor physics in recent times is the RD/RD⁎ puzzle. The measurements of these flavor ratios performed by the B-factory experiments, BaBar and Belle, and the LHCb experiment are about 4σ away from the Standard Model expectation. These measurements indicate that the mechanism of b→cτν¯ decay is not identical to that of b→c(μ/e)ν¯. This charge lepton universality violation is particularly intriguing because these decays occur at tree level in the Standard Model. In particular, we expect a moderately large new physics contribution to b→cτν¯. The different types of new physics amplitudes, which can explain the RD/RD⁎ puzzle, have been identified previously. In this letter, we show that the polarization fractions of τ and D⁎ and the angular asymmetries AFB and ALT in B→D⁎τν¯ decay have the capability to uniquely identify the Lorentz structure of the new physics. A measurement of these four observables will lead to such an identification.\n",
      "\n",
      "---\n",
      "\n",
      "# Jet performance at the Circular electron-positron Collider\n",
      "\n",
      "Jet reconstruction is critical for the precision measurement of Higgs boson properties and the electroweak observables at the CEPC. We analyze the jet energy and angular responses of benchmark 2- and 4-jet processes with fully simulated samples with the CEPC baseline detector geometry. We observe a relative resolution of 3.5% and 1% on the jet energy and angular measurement, for jets in the detector barrel region (|cosθ | < 0.7) with energy greater than 40 GeV. Meanwhile, the jet energy/angular scale can be controlled within 0.5/0.01% level. The differential dependences of the jet response on the jet direction and energy are extracted. We also analyze the impact on jet responses induced by different jet clustering and matching criteria, which yields a relative difference of up to 8%.\n",
      "\n",
      "---\n",
      "\n",
      "# 传感器线性度计算方法的研究\n",
      "\n",
      "&lt;正&gt; 一、前言大多数传感器的输入输出具有比例关系,这就是线性传感器,绝大多数传感器是线性传感器。即使采用了非线性测量元件的传感器,我们也通过多种途径,使其特性线性化,从而也构成线性传感器。衡量线性传感器线性优劣的指标为线性度。随参考直线的性质和引法不同,线性度有多种定义。定义一多,便易引起混乱。文献列出四种定义,文献列出五种,而文献则列出三种,使人们无所适从。在上述文献中都未给出相应的计算方法,虽然有的计算方法已为人们熟知而无必要给出。\n",
      "\n",
      "---\n",
      "\n",
      "# The BABAR detector\n",
      "\n",
      "BABAR, the detector for the SLAC PEP-II asymmetric e+e− B Factory operating at the ϒ(4S) resonance, was designed to allow comprehensive studies of CP-violation in B-meson decays. Charged particle tracks are measured in a multi-layer silicon vertex tracker surrounded by a cylindrical wire drift chamber. Electromagnetic showers from electrons and photons are detected in an array of CsI crystals located just inside the solenoidal coil of a superconducting magnet. Muons and neutral hadrons are identified by arrays of resistive plate chambers inserted into gaps in the steel flux return of the magnet. Charged hadrons are identified by dE/dx measurements in the tracking detectors and by a ring-imaging Cherenkov detector surrounding the drift chamber. The trigger, data acquisition and data-monitoring systems, VME- and network-based, are controlled by custom-designed online software. Details of the layout and performance of the detector components and their associated electronics and software are presented.\n",
      "\n",
      "---\n",
      "\n",
      "# The BaBar electromagnetic calorimeter\n",
      "\n",
      "The BaBar electromagnetic calorimeter is a hermetic, total-absorption array of CsI(Tl)-crystals, operated at the asymmetric e−e+-collider PEP-II at SLAC. The design and the status of the performance as of February 2002 is presented.\n",
      "\n",
      "---\n",
      "\n",
      "# Experimental Tests of Particle Flow Calorimetry\n",
      "\n",
      "Precision physics at future colliders requires highly granular calorimeters to support the Particle Flow Approach for event reconstruction. This article presents a review of about 10 - 15 years of R\\&D, mainly conducted within the CALICE collaboration, for this novel type of detector. The performance of large scale prototypes in beam tests validate the technical concept of particle flow calorimeters. The comparison of test beam data with simulation, of e.g.\\ hadronic showers, supports full detector studies and gives deeper insight into the structure of hadronic cascades than was possible previously.\n",
      "\n",
      "---\n",
      "\n",
      "# Performance of production modules of the Belle II pixel detector in a high-energy particle beam\n",
      "\n",
      "The Belle II experiment at the Super B factory SuperKEKB, an asymmetric $e^+e^-$ collider located in Tsukuba, Japan, is tailored to perform precision B physics measurements. The centre of mass energy of the collisions is equal to the rest mass of the $\\Upsilon(4S)$ resonance of $m_{\\Upsilon(4S)} = 10.58\\,\\rm GeV$. A high vertex resolution is essential for measuring the decay vertices of B mesons. Typical momenta of the decay products are ranging from a few tens of MeV to a few GeV and multiple scattering has a significant impact on the vertex resolution. The VerteX Detector (VXD) for Belle II is therefore designed to have as little material as possible inside the acceptance region. Especially the innermost two layers, populated by the PiXel Detector (PXD), have to be ultra-thin. The PXD is based on DEpleted P-channel Field Effect Transistors (DEPFETs) with a thickness of only $75\\,\\rm\\mu m$. Spatial resolution and hit efficiency of production detector modules were studied in beam tests performed at the DESY test beam facility. The spatial resolution was investigated as a function of the incidence angle and improvements due to charge sharing are demonstrated. The measured module performance is compatible with the requirements for Belle II.\n",
      "\n",
      "---\n",
      "\n",
      "# arXiv : Separation of two electromagnetic or electromagnetic - hadronic showers in CALICE SiW ECAL and ILD\n",
      "\n",
      "CALICE collaboration is developing highly granular calorimeters suitable for individual reconstruction of particles in the jets using Particle Flow Algorithms. Such calorimeters should provide the best jet energy resolution at future high energy $e^{+}e^{-}$ colliders. At high jet energies, typically above 70-100 GeV, the jet particle showers start to overlap, and the resolution is determined by the ability to separate them. Here, we present the results on the separation of two overlapping electromagnetic or electromagnetic - hadronic showers obtained by mixing of the single shower events collected with CALICE SiW ECAL and AHCAL physics prototypes during beam tests at CERN'07 and FermiLab'11, and using International Large Detector (ILD) Monte Carlo simulations. We use three available PFA reconstruction programs (Pandora, Garlic and Arbor).\n",
      "\n",
      "---\n",
      "\n",
      "# Separation of two overlapped electromagnetic or electromagnetic-hadronic showers in CALICE highly granular physics calorimeter prototypes using Pandora, Garlic and Arbor Particle Flow Algorithms\n",
      "\n",
      "CALICE collaboration is developing highly granular calorimetry for the future ILD detector. Usage of Particle Flow Algorithm (PFA) for individual reconstruction of particles in jets provides the best jet energy resolution. For high jet energies (typically above 70 - 100 GeV), particles start overlapping in the calorimeter, causing confusion, and recognition of individual particles becomes complicated. This is the natural limit for PFA at high energies. In this work we are presenting the results on the separation of - 2 overlapped electromagnetic showers in the CALICE silicon-tungsten electromagnetic calorimeter (SiW ECAL) physics prototype; - electromagnetic-hadron showers in the physics prototypes of SiW ECAL and the analogue scintillator-steel hadronic calorimeter (AHCAL); - photon-photon and photon-hadron showers in ILD Monte-Carlo (MC) simulation with 5 \\times 55×5 mm^2 \n",
      "2\n",
      "  and 2.5 \\times 2.52.5×2.5 mm^2 \n",
      "2\n",
      "  ECAL cell size for ILD baseline models with AHCAL or semi-digital hadronic calorimeter (SDHCAL). Physics prototype data were collected during beam tests (TB) in CERN (2007) and FermiLab (2011). Results are compared with Monte-Carlo simulations. Three different reconstruction algorithms are used:Pandora, Garlic and Arbor.\n",
      "\n",
      "---\n",
      "\n",
      "# Arbor, a new approach of the Particle Flow Algorithm\n",
      "\n",
      "The granularity of calorimeter has been revolutionary boosted for future collider experiments. The calorimeter has been pushed to a stage that the sub structure of showers especially hadronic showers can be recorded to a high precision. New reconstruction algorithms are expected from these informations. Following the idea that shower follows the topology of the tree, we developed Arbor, a Particle Flow Algorithm framework. Tested on both simulated data and test beam data, it can successfully separate nearby showers. It has comparable jet energy resolution the best PFA algorithm for International Linear Collider. More importantly, Arbor successfully tags the sub shower structure such as the trajectory of charged particles generated in shower cascade, enabling new approaches for event reconstruction with high granularity calorimeter.\n",
      "\n",
      "---\n",
      "\n",
      "# GARLIC: GAmma Reconstruction at a LInear Collider experiment\n",
      "\n",
      "The precise measurement of hadronic jet energy is crucial to maximise the physics reach of a future Linear Collider. An important ingredient required to achieve this is the efﬁcient identiﬁcation of photons within hadronic showers. One conﬁguration of the ILD detector concept employs a highly granular silicon-tungsten sampling calorimeter to identify and measure photons, and the GARLIC algorithm described in this paper has been developed to identify photons in such a calorimeter. We describe the algorithm and characterise its performance using events fully simulated in a model of the ILD detector.\n",
      "\n",
      "---\n",
      "\n",
      "# Jet Lepton identiﬁcation performance at a future electron positron Higgs Z factory\n",
      "\n",
      "The identiﬁcation of leptons inside jets is critical for the Higgs measurements and the ﬂavor physics program at the CEPC, a proposed Higgs/Z factory with main ring circumference of 100 km. Using the CEPC baseline software, we analyze the identiﬁcation performance of leptons generated inside a jet. The jet leptons can be identiﬁed with typical efﬁciency and mis-id rate of 98% and 1% for energy higher than 2GeV, with Z->bb process at 91.2 GeV center-of-mass energy. At the benchmark channel of CEPC ﬂavor program of Bc → τν with τ → eνν, the electrons are identiﬁed with inclusive efﬁciency times purity of 97%, provide sufﬁcient signal selection for the physics potential study. Compared to the single leptons, we found that these jet leptons identiﬁcation efﬁciency degrades about 1-3%, and the mis-id rate increases by less than 1% at the same working point. We analyze this degrading and found it is mainly caused by the defects of particle shower reconstruction at calorimeter. The dependence between the performance of shower reconstruction and the lepton identiﬁcation is quantiﬁed.\n",
      "\n",
      "---\n",
      "\n",
      "# Particle Flow Calorimetry and the PandoraPFA Algorithm\n",
      "\n",
      "The Particle Flow (PFlow) approach to calorimetry promises to deliver unprecedented jet energy resolution for experiments at future high energy colliders such as the proposed International Linear Collider (ILC). This paper describes the PandoraPFA particle flow algorithm which is then used to perform the first systematic study of the potential of high granularity PFlow calorimetry. For simulated events in the ILD detector concept, a jet energy resolution of sigma_E/E < 3.8 % is achieved for 40-400 GeV jets. This result, which demonstrates that high granularity PFlow calorimetry can meet the challenging ILC jet energy resolution goals, does not depend strongly on the details of the Monte Carlo modelling of hadronic showers. The PandoraPFA algorithm is also used to investigate the general features of a collider detector optimised for high granularity PFlow calorimetry. Finally, a first study of the potential of high granularity PFlow calorimetry at a multi-TeV lepton collider, such as CLIC, is presented.\n",
      "\n",
      "---\n",
      "\n",
      "# The Pandora Particle Flow Algorithm\n",
      "\n",
      "A high-energy e+e- collider, such as the ILC or CLIC, is arguably the best option to complement and extend the LHC physics programme. A lepton collider will allow for exploration of Standard Model Physics, such as precise measurements of the Higgs, top and gauge sectors, in addition to enabling a multitude of New Physics searches. However, physics analyses at such a collider will place unprecedented demands on calorimetry, with a required jet energy resolution of \\sigma(E)/E < 3.5%. To meet these requirements will need a new approach to calorimetry. The particle flow approach to calorimetry requires both fine granularity detectors and sophisticated software algorithms. It promises to deliver unparalleled jet energy resolution by fully reconstructing the paths of individual particles through the detector. The energies of charged particles can then be extracted from precise inner detector tracker measurements, whilst photon energies will be measured in the ECAL, and only neutral hadron energies (10% of jet energies) will be measured in the HCAL, largely avoiding the typically poor HCAL resolution. This document introduces the Pandora particle flow algorithms, which offer the current state of the art in particle flow calorimetry for the ILC and CLIC. The performance of the algorithms is investigated by examining the reconstructed jet energy resolution and the ability to separate the hadronic decays of W and Z bosons.\n",
      "\n",
      "---\n",
      "\n",
      "# Probing the strange Higgs coupling at lepton colliders using light-jet flavor tagging\n",
      "\n",
      "We propose a method to probe the coupling of the Higgs to strange quarks by tagging strange jets at future lepton colliders. For this purpose we describe a jet-flavor observable, $J_F$, that is correlated with the flavor of the quark associated with the hard part of the jet. Using this variable, we set up a strangeness tagger aimed at studying the decay $h\\to s\\bar{s}$. We determine the sensitivity of our method to the strange Yukawa coupling, and find it to be of the order of the standard-model expectation.\n",
      "\n",
      "---\n",
      "\n",
      "# Secondary Vertex Reconstruction Performance at CEPC\n",
      "\n",
      "Vertex reconstruct precisely is important for high level object reconstruction in the high energy physics experiment. The eﬃcient detection and reconstruction of such vertices is essential to achieve a good b/c-tagging performance. Described in this note is the performance of secondary vertex reconstruction at CEPC.\n",
      "\n",
      "---\n",
      "\n",
      "# Performance study of the full hadronic WW and ZZ events’ separation at the CEPC\n",
      "\n",
      "The full hadronic WW and ZZ events’ separation is an important benchmark for the Circular Electron Positron Collider (CEPC) detector design and reconstruction algorithm development. This separation performance is determined by the intrinsic boson mass distributions, the detector performance, and the jet confusion. The latter refers to the uncertainties induced by the jet clustering and pairing algorithms. Using the CEPC baseline simulation, we demonstrate that the full hadronic WW and ZZ events can be efﬁciently separated. We develop an analytic method that quantiﬁes the impact of each component and conclude that the jet confusion dominates the separation performance. The impacts of the Initial State Radiation (ISR) and the heavy ﬂavor jets are also analyzed and conﬁrmed to be critical for the separation performance.\n",
      "\n",
      "---\n",
      "\n",
      "# Precision Higgs physics at the CEPC\n",
      "\n",
      "The discovery of the Higgs boson with its mass around 125 GeV by the ATLAS and CMS Collaborations marked the beginning of a new era in high energy physics. The Higgs boson will be the subject of extensive studies of the ongoing LHC program. At the same time, lepton collider based Higgs factories have been proposed as a possible next step beyond the LHC, with its main goal to precisely measure the properties of the Higgs boson and probe potential new physics associated with the Higgs boson. The Circular Electron Positron Collider (CEPC) is one of such proposed Higgs factories. The CEPC is an e+e− circular collider proposed by and to be hosted in China. Located in a tunnel of approximately 100 km in circumference, it will operate at a center-of-mass energy of 240 GeV as the Higgs factory. In this paper, we present the first estimates on the precision of the Higgs boson property measurements achievable at the CEPC and discuss implications of these measurements.\n",
      "\n",
      "---\n",
      "\n",
      "# Feasibility study of TPC at electron positron colliders at $Z$ pole operation\n",
      "\n",
      "TPC is a promising technology for the future electron positron colliders. However, its application might be limited at high event rate and high hit occupancies. In this paper, we study the feasibility of using TPC at the circular electron positron collider (CEPC) at $Z$ pole using full simulated $Z \\rightarrow q\\bar{q}$ samples. By evaluating the local charge density and voxel occupancy at different TPC parameters. Our study shows that the TPC could be applied to the CEPC $Z$ pole operation if back flow ion is controlled to per mille level. We also suggest the applicable TPC parameters for FCC-ee $Z$ pole operations, whose instant luminosity is $2\\times 10^{36} \\mathrm{cm^2\\,s^{-1}}$, 2 orders of magnitude higher than that of CEPC.\n",
      "\n",
      "---\n",
      "\n",
      "# Cross section and Higgs mass measurement with Higgsstrahlung at the CEPC\n",
      "\n",
      "The Circular Electron Positron Collider (CEPC) is a future Higgs factory proposed by the Chinese high energy physics community. It will operate at a center-of-mass energy of 240–250 GeV. The CEPC will accumulate an integrated luminosity of 5 ab−1 over ten years of operation, producing one million Higgs bosons via the Higgsstrahlung and vector boson fusion processes. This sample allows a percent or even sub-percent level determination of the Higgs boson couplings. With GEANT4-based full simulation and a dedicated fast simulation tool, we have evaluated the statistical precisions of the Higgstrahlung cross section σZH and the Higgs mass mH measurement at the CEPC in the Z → µ+µ− channel. The statistical precision of σZH (mH) measurement could reach 0.97% (6.9 MeV) in the model-independent analysis which uses only the information from Z boson decays. For the standard model Higgs boson, the mH precision could be improved to 5.4 MeV by including the information from Higgs decays. The impact of the TPC size on these measurements is investigated. In addition, we studied the prospect of measuring the Higgs boson decaying into invisible ﬁnal states at the CEPC. With the Standard Model ZH production rate, the upper limit of B(H → inv.) could reach 1.2% at 95% conﬁdence level.\n",
      "\n",
      "---\n",
      "\n",
      "# The Higgs signatures at the CEPC CDR baseline\n",
      "\n",
      "As a Higgs factory, the CEPC (Circular Electron-Positron Collider) project aims at precision measurements of the Higgs boson properties. A baseline detector concept, APODIS (A PFA Oriented Detector for the HIggS factory), has been proposed for the CEPC CDR (Conceptual Design Report) study. We explore the Higgs signatures for this baseline design with νν¯ Higgs events. The detector performance for reconstructing charged particles, photons and jets is quantified with H → µµ, γγ and jet final states, respectively. The resolutions of reconstructed Higgs boson mass are comparable for the different decay modes with jets in the final states. We also analyze the H → WW* and ZZ* decay modes, where a clear separation between different decay cascades is observed.\n",
      "\n",
      "---\n",
      "\n",
      "# Experimental Tests of Particle Flow Calorimetry\n",
      "\n",
      "Precision physics at future colliders requires highly granular calorimeters to support the Particle Flow Approach for event reconstruction. This article presents a review of about 10 - 15 years of R\\&D, mainly conducted within the CALICE collaboration, for this novel type of detector. The performance of large scale prototypes in beam tests validate the technical concept of particle flow calorimeters. The comparison of test beam data with simulation, of e.g.\\ hadronic showers, supports full detector studies and gives deeper insight into the structure of hadronic cascades than was possible previously.\n",
      "\n",
      "---\n",
      "\n",
      "# Precision Measurement of sin^2 theta_W at a Reactor\n",
      "\n",
      "This paper presents a strategy for measuring sin^2 theta_W to ~1% at a reactor-based experiment, using antineutrinos electron elastic scattering. This error is comparable to the NuTeV, SLAC E158, and APV results on sin^2 theta_W, but with substantially different contributions to the systematics. An improved method for identifying antineutrino proton events, which serve both as a background and as a normalization sample, is described. The measurement can be performed using the near detector of the presently proposed reactor-based oscillation experiments. We conclude that an absolute error of delta(sin^2 theta_W)=0.0019 may be achieved.\n",
      "\n",
      "---\n",
      "\n",
      "# Monte Carlo study of particle identification at the CEPC using TPC dE / dx information\n",
      "\n",
      "The kaon identiﬁcation is crucial for the ﬂavor physics, and also beneﬁts the ﬂavor and charge reconstruction of the jets. We explore the particle identiﬁcation capability for tracks with momenta ranging from 2–20 GeV/c using the d E/d x measurements in the Time Projection Chamber at the future Circular Electron-Positron Collider. Based on Monte Carlo simulation, we anticipate that an average 3.2 σ (2.6 σ ) K /π separation can be achieved based on d E/d x information for an optimistic (conservative) extrapolation of the simulated performance to the ﬁnal system. Time-of-ﬂight (TOF) information from the Electromagnetic Calorimeter can provide K /π separation around 1 GeV/c and reduce the K / p mis-identiﬁcation rate. By combining the d E/d x and TOF information, we estimate that in the optimistic scenario a kaon selection in inclusive hadronic Z decays with both the average efﬁciency and purity approaching 95% can be achieved.\n",
      "\n",
      "---\n",
      "\n",
      "# Reconstruction of physics objects at the Circular Electron Positron Collider with Arbor\n",
      "\n",
      "After the Higgs discovery, precise measurements of the Higgs properties and the electroweak observables become vital for the experimental particle physics. A powerful Higgs/Z factory, the Circular Electron Positron Collider (CEPC) is proposed. The Particle Flow oriented detector design is proposed to the CEPC and a Particle Flow algorithm, Arbor is optimized accordingly. We summarize the physics object reconstruction performance of the Particle Flow oriented detector design with Arbor algorithm and conclude that this combination fulﬁlls the physics requirement of CEPC.\n",
      "\n",
      "---\n",
      "\n",
      "# Measurement of b quark EW couplings at ILC\n",
      "\n",
      "This paper describes an analysis performed at 250 GeV centre of mass energy for the reaction e+e‐ ‐> b with the International Linear Collider, ILC, assuming an integrated luminosity of 500 fb‐1. This measurement requires determining the b quark charge, which can be optimally performed using the precise micro‐vertex detector of the detector ILD and the charged kaon identification provided by the dE/dx information of its TPC. Given that the forward backward asymmetry is maximal for e‐L (Left‐handed electron polarisation), it has been necessary to develop a new method to correct for unavoidable angular migration due to b charge mis‐measurements. This correction is based on the reconstructed events themselves without introducing external corrections which would induce large uncertainties. With polarized beams, one can separate the Z and  vector and axial couplings to b quarks. The precision reached is at the few per mill level, and should allow to confirm/discard the deviation observed at LEP1 on the ZbRbR coupling. Model independent upper bounds on the tensor couplings, F2V and F2A, are derived using the shape of the angular distribution.\n",
      "\n",
      "---\n",
      "\n",
      "# Study of vertex optimization at the CEPC\n",
      "\n",
      "The CEPC is a planned future collider targeting precise Higgs property measurements. Its core physics program includes the determination of Br(H → bb), Br(H → cc), and Br(H → τ+τ−), whose accuracies are sensitive to the vertex (VTX) design and the performance. This study is performed on Higgsstrahlung events e+e− → ZH at √s = 240GeV, with subsequent Higgs decay to bb, cc and ττ. Using full simulation, we quantified the dependency between these physics performances and the main VTX geometry parameters: the inner radius, the material budget, and the spatial resolution.\n",
      "\n",
      "---\n",
      "\n",
      "# LCFIPlus: A framework for jet analysis in linear collider studies\n",
      "\n",
      "We report on the progress in ﬂavor identiﬁcation tools developed for a future e þ e À linear collider such as the International Linear Collider (ILC) and Compact Linear Collider (CLIC). Building on the work carried out by the LCFIVertex collaboration, we employ new strategies in vertex ﬁnding and jet ﬁnding, and introduce new discriminating variables for jet ﬂavor identiﬁcation. We present the performance of the new algorithms in the conditions simulated using a detector concept designed for the ILC. The algorithms have been successfully used in ILC physics simulation studies, such as those presented in the ILC Technical Design Report.\n",
      "\n",
      "---\n",
      "\n",
      "# Timing performance of the CMS ECAL and prospects for the future\n",
      "\n",
      "The CMS electromagnetic calorimeter (ECAL) is made of about 75000 scintillating lead tungstate crystals arranged in a barrel and two endcaps. The scintillation light is read out by avalanche photodiodes in the barrel and vacuum phototriodes in the endcaps, at which point the scintillation pulse is ampliﬁed and sampled at 40 MHz by the on-detector electronics. The fast signal from the crystal scintillation enables energy as well as time measurements from the data collected in proton-proton collisions with high energy electrons and photons. The stability of the time measurement required to maintain the energy resolution is on the order of 1 ns. The single-channel time resolution of ECAL measured at beam tests for high energy showers is better than 100 ps. The time resolution achieved with the data collected in proton-proton collisions at the LHC is presented. The time precision achieved is used in important physics measurements and also allows the study of subtle calorimetric eﬀects, such as the time response of diﬀerent crystals belonging to the same electromagnetic shower. In addition, we present prospects for the high luminosity phase of the LHC, where we expect an average of 140 concurrent interactions per bunch crossing (pile-up). It is currently being studied how precision time could be exploited for pileup mitigation and for the assignment of the collision vertex for photons. In this respect, a detailed understanding of the time performance and of the limiting factors in time resolution will be important.\n",
      "\n",
      "---\n",
      "\n",
      "# Fractal Dimension of Particle Showers Measured in a Highly Granular Calorimeter\n",
      "\n",
      "We explore the fractal nature of particle showers using Monte Carlo simulation. We define the fractal dimension of showers measured in a high granularity calorimeter designed for a future lepton collider. The shower fractal dimension reveals detailed information of the spatial configuration of the shower. It is found to be characteristic of the type of interaction and highly sensitive to the nature of the incident particle. Using the shower fractal dimension, we demonstrate a particle identification algorithm that can efficiently separate electromagnetic showers, hadronic showers, and nonshowering tracks. We also find a logarithmic dependence of the shower fractal dimension on the particle energy.\n",
      "\n",
      "---\n",
      "\n",
      "# TMVA - Toolkit for Multivariate Data Analysis\n",
      "\n",
      "In high-energy physics, with the search for ever smaller signals in ever larger data sets, it has become essential to extract a maximum of the available information from the data. Multivariate classification methods based on machine learning techniques have become a fundamental ingredient to most analyses. Also the multivariate classifiers themselves have significantly evolved in recent years. Statisticians have found new ways to tune and to combine classifiers to further gain in performance. Integrated into the analysis framework ROOT, TMVA is a toolkit which hosts a large variety of multivariate classification algorithms. Training, testing, performance evaluation and application of all available classifiers is carried out simultaneously via user-friendly interfaces. With version 4, TMVA has been extended to multivariate regression of a real-valued target vector. Regression is invoked through the same user interfaces as classification. TMVA 4 also features more flexible data handling allowing one to arbitrarily form combined MVA methods. A generalised boosting method is the first realisation benefiting from the new framework.\n",
      "\n",
      "---\n",
      "\n",
      "# Predicting protein structures with a multiplayer online game\n",
      "\n",
      "People exert significant amounts of problem solving effort playing computer games. Simple image- and text-recognition tasks have been successfully crowd-sourced through gamesi, ii, iii, but it is not clear if more complex scientific problems can be similarly solved with human-directed computing. Protein structure prediction is one such problem: locating the biologically relevant native conformation of a protein is a formidable computational challenge given the very large size of the search space. Here we describe Foldit, a multiplayer online game that engages nonscientists in solving hard prediction problems. Foldit players interact with protein structures using direct manipulation tools and user-friendly versions of algorithms from the Rosetta structure prediction methodologyiv, while they compete and collaborate to optimize the computed energy. We show that top Foldit players excel at solving challenging structure refinement problems in which substantial backbone rearrangements are necessary to achieve burial of hydrophobic residues. Players working collaboratively develop a rich assortment of new strategies and algorithms; unlike computational approaches, they explore not only conformational space but also the space of possible search strategies. The integration of human visual problem-solving and strategy development capabilities with traditional computational algorithms through interactive multiplayer games is a powerful new approach to solving computationally-limited scientific problems.\n",
      "\n",
      "---\n",
      "\n",
      "# Topological B hadron decay reconstruction and identification of b-jets with JetFitter in the ATLAS experiment at the LHC The ATLAS Collaboration\n",
      "\n",
      "The identification of jets containing heavy flavour hadron decays, in particular bottom quark initiated jets, plays a major role in the LHC physics program. The topology of b → c → s decays gives rise to two detached vertices corresponding to the band c-flavoured hadron decays. The vertices can each have high invariant mass and several associated charged tracks, giving a very distinctive signature for the identification of b-jets. This note discusses the algorithm developed for the topological reconstruction of b-flavoured hadron decays in ATLAS, its implementation and performance based on simulation and 13 TeV collision data. © 2018 CERN for the benefit of the ATLAS Collaboration. Reproduction of this article or parts of it is allowed as specified in the CC-BY-3.0 license.\n",
      "\n",
      "---\n",
      "\n",
      "# A framework for vertex reconstruction in the ATLAS experiment at LHC\n",
      "\n",
      "In anticipation of the first LHC data to come, a considerable effort has been devoted to ensure the efficient reconstruction of vertices in the ATLAS detector. This includes the reconstruction of photon conversions, long lived particles, secondary vertices in jets as well as finding and fitting of primary vertices. The implementation of the corresponding algorithms requires a modular design based on the use of abstract interfaces and a common Event Data Model. An enhanced software framework addressing various physics applications of vertex reconstruction has been developed in the ATLAS experiment. Presented in this paper are the general principles of this framework. A particular emphasis is given to the description of the concrete implementations, which are dedicated to diverse methods of vertex reconstruction.\n",
      "\n",
      "---\n",
      "\n",
      "# The measurement of the $$H\\rightarrow \\tau \\tau $$H→ττ signal strength in the future $$e^{+}e^{-}$$e+e- Higgs factories\n",
      "\n",
      "The Circular Electron Positron Collider and the International Linear Collider are two electron-positron Higgs factories. They are designed to operate at a center-of-mass energy of 240 and 250 GeV and accumulate 5.6 and 2 ab−1 of integrated luminosity. This paper estimates their performance on the H → τ +τ − benchmark measurement. Using the full simulation analysis, the CEPC is expected to measure the signal strength to a relative accuracy of 0.8%. Extrapolating to the ILC setup, we conclude the ILC can reach a relative accuracy of 1.1% or 1.2%, corresponding to two benchmark beam polarization setups. The physics requirement on the mass resolution of the Higgs boson with hadronic decay ﬁnal states is also discussed, showing that the CEPC baseline design and reconstruction fulﬁll the accuracy requirement of the H → τ +τ − signal strength.\n",
      "\n",
      "---\n",
      "\n",
      "# Measurement of the b forward-backward asymmetry and mixing using high-p⊥ leptons\n",
      "\n",
      "The B0 − B0 average mixing parameter χ and b forward–backward asymmetry A0FB(b) are measured from a sample of about 4,200,000 Z → qq events recorded with the ALEPH detector at LEP in the years 1990–1995. High transverse momentum electrons and muons produced in b semileptonic decays provide the tag of the quark ﬂavour and of its charge.\n",
      "\n",
      "---\n",
      "\n",
      "# CEPC detector performance study\n",
      "\n",
      "E-mail address: yudan@ihep.ac.cn, manqi.ruan@ihep.ac.cn c Copyright 2020 IHEP for the beneﬁt of the CEPC Collaboration. Reproduction of this article or parts of it is allowed as speciﬁed in the CC-BY-3.0 license.\n",
      "\n",
      "---\n",
      "\n",
      "# Lepton identification at particle flow oriented detector for the future $$e^{+}e^{-}$$ e + e - Higgs factories\n",
      "\n",
      "The lepton identiﬁcation is essential for the physics programs at high-energy frontier, especially for the precise measurement of the Higgs boson. For this purpose, a toolkit for multivariate data analysis (TMVA) based lepton identiﬁcation (LICH) has been developed for detectors using high granularity calorimeters. Using the conceptual detector geometry for the Circular Electron–Positron Collider (CEPC) and single charged particle samples with energy larger than 2 GeV, LICH identiﬁes electrons/muons with efﬁciencies higher than 99.5% and controls the misidentiﬁcation rate of hadron to muons/electrons to better than 1/0.5%. Reducing the calorimeter granularity by 1–2 orders of magnitude, the lepton identiﬁcation performance is stable for particles with E > 2 GeV. Applied to fully simulated eeH/μμH events, the lepton identiﬁcation performance is consistent with the single particle case: the efﬁciency of identifying all the high energy leptons in an event, is 95.5–98.5%.\n",
      "\n",
      "---\n",
      "\n",
      "# Triple Gauge Boson Couplings\n",
      "\n",
      "We present the results obtained by the \"Triple Gauge Couplings\" working group during the LEP2 Workshop (1994-1995). The report concentrates on the measurement of $WW\\gamma$ and $WWZ$ couplings in $e^-e^+\\to W^-W^+$ or, more generally, four-fermion production at LEP2. In addition the detection of new interactions in the bosonic sector via other production channels is discussed.\n",
      "\n",
      "---\n",
      "\n",
      "# Optimal observables for the measurement of three gauge boson couplings in e + e -> W + W ?\n",
      "\n",
      "We investigate the prospects of measuring anomalous couplings between gauge bosons at electron-positron-colliders with optimal observables. Such observables are shown to contain all information on the coupling parameters that can be extracted in a given reaction. Their sensitivity to the form factors in the general expressions of the triple gauge vertices WW Z and WW1, including CP violating terms and absorptive parts, is calculated in view of LEP2 and the NLC.\n",
      "\n",
      "---\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "def generate_markdown(zotero_items):\n",
    "    \"\"\"\n",
    "    根据给定的 Zotero 条目列表，生成一个包含标题和摘要的 Markdown 文档字符串。\n",
    "    \n",
    "    参数:\n",
    "        zotero_items (list of dict): 从 pyzotero 获取的条目列表，每个条目为一个 dict，\n",
    "                                      其中标题在 entry['data']['title']，\n",
    "                                      摘要在 entry['data']['abstractNote']。\n",
    "    返回:\n",
    "        str: 完整的 Markdown 文档字符串。\n",
    "    \"\"\"\n",
    "    md_lines = []\n",
    "    for entry in zotero_items:\n",
    "        # 从 entry 中提取标题\n",
    "        title = entry.get('data', {}).get('title', '').strip()\n",
    "        # 从 entry 中提取摘要\n",
    "        abstract = entry.get('data', {}).get('abstractNote', '').strip()\n",
    "        # 如果标题或摘要都为空，则跳过该条目\n",
    "        if not title and not abstract:\n",
    "            continue\n",
    "        \n",
    "        # 添加一级标题\n",
    "        md_lines.append(f\"# {title}\")\n",
    "        md_lines.append(\"\")  # 空行，用于 Markdown 格式\n",
    "        \n",
    "        # 添加摘要内容\n",
    "        md_lines.append(abstract)\n",
    "        md_lines.append(\"\")  # 空行\n",
    "        \n",
    "        # 添加分隔线，分割不同条目\n",
    "        md_lines.append(\"---\")\n",
    "        md_lines.append(\"\")  # 空行\n",
    "\n",
    "    # 将所有行拼接为一个字符串并返回\n",
    "    return \"\\n\".join(md_lines)\n",
    "\n",
    "# 调用函数生成 Markdown 文档\n",
    "markdown_document = generate_markdown(corpus)\n",
    "\n",
    "# 输出到控制台，或者写入文件\n",
    "print(markdown_document)\n",
    "# 也可以这样写入文件：\n",
    "# with open(\"zotero_items.md\", \"w\", encoding=\"utf-8\") as f:\n",
    "#     f.write(markdown_document)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "Search for the dark photon in <span class=\"nocase\">π⁰</span> decays"
      ],
      "text/plain": [
       "<IPython.core.display.Latex object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "Search for new light vector boson using J/Ψ at BESIII and Belle II"
      ],
      "text/plain": [
       "<IPython.core.display.Latex object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "Measurement of the time-like pion transition form factor at BESIII"
      ],
      "text/plain": [
       "<IPython.core.display.Latex object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "Holographic analysis of the pion"
      ],
      "text/plain": [
       "<IPython.core.display.Latex object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "Measurement of the <span class=\"nocase\">π⁰</span> electromagnetic transition form factor slope"
      ],
      "text/plain": [
       "<IPython.core.display.Latex object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "Design and construction of the BESIII detector"
      ],
      "text/plain": [
       "<IPython.core.display.Latex object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "Measurement of the spectral function for the <span class=\"nocase\">τ⁻→K⁻K<sub>S</sub>ν<sub>τ</sub></span> decay"
      ],
      "text/plain": [
       "<IPython.core.display.Latex object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "High-Statistics Study of the tau- —> pi- pi0 nu(tau) Decay"
      ],
      "text/plain": [
       "<IPython.core.display.Latex object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "The strong coupling from hadronic <span class=\"nocase\">τ</span>-decay data including <span class=\"nocase\">τ→π⁻π⁰ν<sub>τ</sub></span> from Belle"
      ],
      "text/plain": [
       "<IPython.core.display.Latex object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "Probing entanglement and testing Bell inequality violation with e+e-→τ+τ- at Belle II"
      ],
      "text/plain": [
       "<IPython.core.display.Latex object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "Quantum information and CP measurement in H→τ+τ- at future lepton colliders"
      ],
      "text/plain": [
       "<IPython.core.display.Latex object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "Tau kinematics from impact parameters"
      ],
      "text/plain": [
       "<IPython.core.display.Latex object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "Probing entanglement and testing Bell inequality violation with ${e}^{+}{e}^{\\ensuremath{-}}\\ensuremath{\\rightarrow}{\\ensuremath{\\tau}}^{+}{\\ensuremath{\\tau}}^{\\ensuremath{-}}$ at Belle II"
      ],
      "text/plain": [
       "<IPython.core.display.Latex object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "QCD predictions for the decay of the \\ensuremath{\\tau} lepton"
      ],
      "text/plain": [
       "<IPython.core.display.Latex object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "QCD and resonance physics. applications"
      ],
      "text/plain": [
       "<IPython.core.display.Latex object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "Perturbative QCD corrections to the ratio R for \\ensuremath{\\tau} decay"
      ],
      "text/plain": [
       "<IPython.core.display.Latex object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "Nonperturbative effects in $\\ensuremath{\\tau}$ decay"
      ],
      "text/plain": [
       "<IPython.core.display.Latex object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "On the perturbative QCD calculation of the <i>R</i> ratio for <i>τ</i> decay"
      ],
      "text/plain": [
       "<IPython.core.display.Latex object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "Renormalization group analysis of the τ-lepton decay within QCD"
      ],
      "text/plain": [
       "<IPython.core.display.Latex object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "The perturbative QCD prediction to Rτ revisited"
      ],
      "text/plain": [
       "<IPython.core.display.Latex object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "Testing QCD with τ decays"
      ],
      "text/plain": [
       "<IPython.core.display.Latex object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "The optimal method for the measurement of tau polarization"
      ],
      "text/plain": [
       "<IPython.core.display.Latex object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "Measurement of the branching fraction scrB(${\\mathrm{\\ensuremath{\\tau}}}^{\\mathrm{\\ensuremath{-}}}$\\ensuremath{\\rightarrow}${\\mathit{h}}^{\\mathrm{\\ensuremath{-}}}$\\ensuremath{\\rightarrow}${\\mathrm{\\ensuremath{\\pi}}}^{0}$${\\ensuremath{\\nu}}_{\\mathrm{\\ensuremath{\\tau}}}$)"
      ],
      "text/plain": [
       "<IPython.core.display.Latex object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "Measurement of the spectral functions of vector current hadronic tau decays"
      ],
      "text/plain": [
       "<IPython.core.display.Latex object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "Measurement of αS from τ decays"
      ],
      "text/plain": [
       "<IPython.core.display.Latex object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "Renormalization scheme dependence and the problem of the determination of ${\\ensuremath{\\alpha}}_{s}$ and the condensates from semileptonic $\\ensuremath{\\tau}$ decays"
      ],
      "text/plain": [
       "<IPython.core.display.Latex object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "Measurement of the Strong Coupling Constant and the Vector and Axial-Vector Spectral Functions in Hadronic Tau Decays"
      ],
      "text/plain": [
       "<IPython.core.display.Latex object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "Spectral functions from hadronic τ decays"
      ],
      "text/plain": [
       "<IPython.core.display.Latex object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "Electroweak fits at LEP"
      ],
      "text/plain": [
       "<IPython.core.display.Latex object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "Precision determination of heavy quark masses and the strong coupling constant"
      ],
      "text/plain": [
       "<IPython.core.display.Latex object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "Branching ratios and spectral functions of τ decays: Final ALEPH measurements and physics implications"
      ],
      "text/plain": [
       "<IPython.core.display.Latex object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "The physics of hadronic tau decays"
      ],
      "text/plain": [
       "<IPython.core.display.Latex object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "Order α s 4 QCD Corrections to Z and τ Decays"
      ],
      "text/plain": [
       "<IPython.core.display.Latex object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "The determination of α S from τ decays revisited"
      ],
      "text/plain": [
       "<IPython.core.display.Latex object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "Tau Decays and αs"
      ],
      "text/plain": [
       "<IPython.core.display.Latex object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "The strong coupling from the revised ALEPH data for hadronic $\\tau$ decays"
      ],
      "text/plain": [
       "<IPython.core.display.Latex object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "αs from the updated ALEPH data for hadronic τ decays"
      ],
      "text/plain": [
       "<IPython.core.display.Latex object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "Strong coupling from ${e}^{+}{e}^{\\ensuremath{-}}\\ensuremath{\\rightarrow}\\mathrm{hadrons}$ below charm"
      ],
      "text/plain": [
       "<IPython.core.display.Latex object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "Version 3 of {\\tt RunDec} and {\\tt CRunDec}"
      ],
      "text/plain": [
       "<IPython.core.display.Latex object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "Higher-order QCD corrections to hadronic τ decays from Padé approximants"
      ],
      "text/plain": [
       "<IPython.core.display.Latex object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "Precise αs determination from charmonium sum rules"
      ],
      "text/plain": [
       "<IPython.core.display.Latex object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "The strong coupling from an improved $\\tau$ vector isovector spectral function"
      ],
      "text/plain": [
       "<IPython.core.display.Latex object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "TAUOLA update for decay channels with e+e− pairs in the final state"
      ],
      "text/plain": [
       "<IPython.core.display.Latex object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "The Euclidean Adler Function and its Interplay with $\\Delta\\alpha^{\\mathrm{had}}_{\\mathrm{QED}}$ and $\\alpha_s$"
      ],
      "text/plain": [
       "<IPython.core.display.Latex object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "Strong coupling from an improved $\\ensuremath{\\tau}$ vector isovector spectral function"
      ],
      "text/plain": [
       "<IPython.core.display.Latex object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "Perturbative corrections to power suppressed effects in semileptonic B decays"
      ],
      "text/plain": [
       "<IPython.core.display.Latex object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "The three-loop relation between the MS<math><mtext>MS</mtext></math> and the pole quark masses"
      ],
      "text/plain": [
       "<IPython.core.display.Latex object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "Inclusive Semileptonic $b \\to c \\ell \\bar{\\nu}$ Decays to Order $1/m_b^5$"
      ],
      "text/plain": [
       "<IPython.core.display.Latex object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "NLO QCD Corrections to Inclusive $b \\rightarrow c \\ell \\bar{\\nu}$ Decay Spectra up to $1/m_Q^3$"
      ],
      "text/plain": [
       "<IPython.core.display.Latex object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "Kolya: an open-source package for inclusive semileptonic $B$ decays"
      ],
      "text/plain": [
       "<IPython.core.display.Latex object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "Moments of the electron energy spectrum and partial branching fraction of $B\\ensuremath{\\rightarrow}{X}_{c}e\\ensuremath{\\nu}$ decays at the Belle detector"
      ],
      "text/plain": [
       "<IPython.core.display.Latex object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "Measurement of the inclusive semileptonic $B$ meson branching fraction in 62.8 fb$^{-1}$ of Belle II data"
      ],
      "text/plain": [
       "<IPython.core.display.Latex object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "Measurement and interpretation of moments in inclusive semileptonic decays $\\overline{B}\\ensuremath{\\rightarrow}{X}_{c}{\\ensuremath{\\ell}}^{\\ensuremath{-}}\\overline{\\ensuremath{\\nu}}$"
      ],
      "text/plain": [
       "<IPython.core.display.Latex object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "Three loop calculations and inclusive Vcb"
      ],
      "text/plain": [
       "<IPython.core.display.Latex object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "Vcb determination from inclusive b → c decays: an alternative method"
      ],
      "text/plain": [
       "<IPython.core.display.Latex object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "Fit to moments of inclusive $B\\ensuremath{\\rightarrow}{X}_{c}\\ensuremath{\\ell}\\overline{\\ensuremath{\\nu}}$ and $B\\ensuremath{\\rightarrow}{X}_{s}\\ensuremath{\\gamma}$ decay distributions using heavy quark expansions in the kinetic scheme"
      ],
      "text/plain": [
       "<IPython.core.display.Latex object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "Kinetic Heavy Quark Mass to Three Loops"
      ],
      "text/plain": [
       "<IPython.core.display.Latex object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "Inclusive $$B\\rightarrow X_c \\ell {\\bar{\\nu }}_\\ell$$and $$B\\rightarrow X_u \\ell {\\bar{\\nu }}_\\ell$$decays: current status and future prospects"
      ],
      "text/plain": [
       "<IPython.core.display.Latex object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "Semileptonic decays in the limit of a heavy daughter quark"
      ],
      "text/plain": [
       "<IPython.core.display.Latex object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "Inclusive semileptonic B decays and |Vcb|: In memoriam Kolya Uraltsev"
      ],
      "text/plain": [
       "<IPython.core.display.Latex object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "Measurement of the inclusive semileptonic branching fraction of B mesons and |Vcb|"
      ],
      "text/plain": [
       "<IPython.core.display.Latex object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "High power $n$ of ${m}_{b}$ in $b$-flavored widths and $n=5\\ensuremath{\\rightarrow}\\mathbf{\\ensuremath{\\infty}}$ limit"
      ],
      "text/plain": [
       "<IPython.core.display.Latex object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "PERTURBATIVE CORRECTIONS TO THE SEMILEPTONIC b-DECAY MOMENTS: $E<sup>ℓ</sup>_cut$ DEPENDENCE AND RUNNING-αs EFFECTS IN THE OPE APPROACH"
      ],
      "text/plain": [
       "<IPython.core.display.Latex object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "Hadronic spectral moments in semileptonic $B$ decays with a lepton energy cut"
      ],
      "text/plain": [
       "<IPython.core.display.Latex object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "Measurement of Lepton Mass Squared Moments in $B \\to X_c \\ell \\bar \\nu_{\\ell}$ Decays with the Belle II Experiment"
      ],
      "text/plain": [
       "<IPython.core.display.Latex object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "$B$ decay shape variables and the precision determination of $|{V}_{\\mathrm{cb}}|$ and ${m}_{b}$"
      ],
      "text/plain": [
       "<IPython.core.display.Latex object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "NNLO QCD corrections to the q2 spectrum of inclusive semileptonic B-meson decays"
      ],
      "text/plain": [
       "<IPython.core.display.Latex object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "Moments of semileptonic B decay distributionsin the 1/m b expansion"
      ],
      "text/plain": [
       "<IPython.core.display.Latex object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "Imprecated, yet impeccable: on the theoretical evaluation of Γ(B→Xcℓν)<math><mtext>Γ(B→X</mtext><msub><mi></mi><mn>c</mn></msub><mspace xmlns=\"true\" sp=\"0.2\" width=\"2px\" linebreak=\"nobreak\" is=\"true\"></mspace><mtext>ℓν)</mtext></math>"
      ],
      "text/plain": [
       "<IPython.core.display.Latex object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "Third order corrections to the semileptonic $b\\ensuremath{\\rightarrow}c$ and the muon decays"
      ],
      "text/plain": [
       "<IPython.core.display.Latex object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "Improved particle-flow event reconstruction with scalable neural networks for current and future particle detectors"
      ],
      "text/plain": [
       "<IPython.core.display.Latex object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "Precise αs determination from charmonium sum rules"
      ],
      "text/plain": [
       "<IPython.core.display.Latex object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "αs and |Vcs| determination, and CKM unitarity test, from W decays at NNLO"
      ],
      "text/plain": [
       "<IPython.core.display.Latex object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "Reliable Perturbative Results for Strong Interactions?"
      ],
      "text/plain": [
       "<IPython.core.display.Latex object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "Ultraviolet Behavior of Non-Abelian Gauge Theories"
      ],
      "text/plain": [
       "<IPython.core.display.Latex object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "Asymptotically Free Gauge Theories. I"
      ],
      "text/plain": [
       "<IPython.core.display.Latex object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "Three-Triplet Model with Double $\\mathrm{SU}(3)$ Symmetry"
      ],
      "text/plain": [
       "<IPython.core.display.Latex object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "Symmetries of Baryons and Mesons"
      ],
      "text/plain": [
       "<IPython.core.display.Latex object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "Reconstruction and classification of tau lepton decays with ILD"
      ],
      "text/plain": [
       "<IPython.core.display.Latex object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "WHIZARD—simulating multi-particle processes at LHC and ILC"
      ],
      "text/plain": [
       "<IPython.core.display.Latex object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "Data Unfolding Methods in High Energy Physics"
      ],
      "text/plain": [
       "<IPython.core.display.Latex object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "FCC-ee: The Lepton Collider"
      ],
      "text/plain": [
       "<IPython.core.display.Latex object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "Comparison of unfolding methods using RooFitUnfold"
      ],
      "text/plain": [
       "<IPython.core.display.Latex object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "Cross section measurements of the e+e− → D*+D*− and e+e− → D*+D− processes at center-of-mass energies from 4.085 to 4.600 GeV"
      ],
      "text/plain": [
       "<IPython.core.display.Latex object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "Review of Particle Physics"
      ],
      "text/plain": [
       "<IPython.core.display.Latex object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "Very High-Energy Collisions of Hadrons"
      ],
      "text/plain": [
       "<IPython.core.display.Latex object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "High-Energy Inelastic $e\\ensuremath{-}p$ Scattering at 6\\ifmmode^\\circ\\else\\textdegree\\fi{} and 10\\ifmmode^\\circ\\else\\textdegree\\fi{}"
      ],
      "text/plain": [
       "<IPython.core.display.Latex object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "Observed Behavior of Highly Inelastic Electron-Proton Scattering"
      ],
      "text/plain": [
       "<IPython.core.display.Latex object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "Electroweak fits at LEP"
      ],
      "text/plain": [
       "<IPython.core.display.Latex object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "Pole mass renormalon and its ramifications"
      ],
      "text/plain": [
       "<IPython.core.display.Latex object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "Experimental observation of lepton pairs of invariant mass around 95 GeV/c2 at the CERN SPS collider"
      ],
      "text/plain": [
       "<IPython.core.display.Latex object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "Evidence for Z0→e+e− at the CERN pp collider"
      ],
      "text/plain": [
       "<IPython.core.display.Latex object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "Observation of single isolated electrons of high transverse momentum in events with missing transverse energy at the CERN pp collider"
      ],
      "text/plain": [
       "<IPython.core.display.Latex object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "Experimental observation of isolated large transverse energy electrons with associated missing energy at s=540 GeV"
      ],
      "text/plain": [
       "<IPython.core.display.Latex object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "Observation of Top Quark Production in $\\overline{\\mathit{p}}\\mathit{p}$ Collisions with the Collider Detector at Fermilab"
      ],
      "text/plain": [
       "<IPython.core.display.Latex object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "Evidence for Anomalous Lepton Production in ${e}^{+}\\ensuremath{-}{e}^{\\ensuremath{-}}$ Annihilation"
      ],
      "text/plain": [
       "<IPython.core.display.Latex object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "Discovery of a Narrow Resonance in ${e}^{+}{e}^{\\ensuremath{-}}$ Annihilation"
      ],
      "text/plain": [
       "<IPython.core.display.Latex object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "Experimental Observation of a Heavy Particle $J$"
      ],
      "text/plain": [
       "<IPython.core.display.Latex object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "Review of Particle Physics"
      ],
      "text/plain": [
       "<IPython.core.display.Latex object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "A Multi-dimensional Unfolding Method Based on Bayes Theorem"
      ],
      "text/plain": [
       "<IPython.core.display.Latex object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "The International Linear Collider Technical Design Report - Volume 4: Detectors"
      ],
      "text/plain": [
       "<IPython.core.display.Latex object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "BESⅢ-CsI(Tl)晶体量能器时间信息的研究"
      ],
      "text/plain": [
       "<IPython.core.display.Latex object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "在北京正负电子对撞机(BEPC)上τ质量的实验测量"
      ],
      "text/plain": [
       "<IPython.core.display.Latex object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "在$e^+e^-$对撞过程中τ轻子对产生的阈行为"
      ],
      "text/plain": [
       "<IPython.core.display.Latex object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "Design and construction of the new BESIII endcap time-of-flight system with MRPC technology"
      ],
      "text/plain": [
       "<IPython.core.display.Latex object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "The OPAL detector at LEP"
      ],
      "text/plain": [
       "<IPython.core.display.Latex object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "Measurement of CKM element $|V_{cb}|$ from $W$ boson decays at the future Higgs factories"
      ],
      "text/plain": [
       "<IPython.core.display.Latex object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "Test beam studies of silicon timing for use in calorimetry"
      ],
      "text/plain": [
       "<IPython.core.display.Latex object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "Time-assisted energy reconstruction in a highly-granular hadronic calorimeter"
      ],
      "text/plain": [
       "<IPython.core.display.Latex object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "On the use of neural networks for energy reconstruction in high-granularity calorimeters"
      ],
      "text/plain": [
       "<IPython.core.display.Latex object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "Fast-timing Capabilities of Silicon Sensors for the CMS High-Granularity Calorimeter at the High-Luminosity LHC"
      ],
      "text/plain": [
       "<IPython.core.display.Latex object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "Measurement of Angular Coefficients of $\\bar{B} \\to D^* \\ell \\bar{\\nu}_\\ell$: Implications for $|V_{cb}|$ and Tests of Lepton Flavor Universality"
      ],
      "text/plain": [
       "<IPython.core.display.Latex object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "First Simultaneous Determination of Inclusive and Exclusive $|{V}_{ub}|$"
      ],
      "text/plain": [
       "<IPython.core.display.Latex object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "Detectors and Physics at a Future Linear Collider"
      ],
      "text/plain": [
       "<IPython.core.display.Latex object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "GNN-based end-to-end reconstruction in the CMS Phase 2 High-Granularity Calorimeter"
      ],
      "text/plain": [
       "<IPython.core.display.Latex object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "Cluster time measurement with CEPC calorimeter"
      ],
      "text/plain": [
       "<IPython.core.display.Latex object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "Measurement of the B0<math><mtext>B</mtext><msup><mi></mi><mn><mspace xmlns=\"true\" sp=\"0.2\" width=\"2px\" linebreak=\"nobreak\" is=\"true\"></mspace><mtext>0</mtext></mn></msup></math> and <i>B</i>− meson lifetimes"
      ],
      "text/plain": [
       "<IPython.core.display.Latex object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "A precise measurement of the B + , B0 and mean b-hadron lifetime with the DELPHI detector at LEP I"
      ],
      "text/plain": [
       "<IPython.core.display.Latex object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "Measurement of differential distributions of $B\\ensuremath{\\rightarrow}{D}^{*}\\ensuremath{\\ell}{\\overline{\\ensuremath{\\nu}}}_{\\ensuremath{\\ell}}$ and implications on $|{V}_{cb}|$"
      ],
      "text/plain": [
       "<IPython.core.display.Latex object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "Measurement of the CKM matrix element $|{V}_{cb}|$ from ${B}^{0}\\ensuremath{\\rightarrow}{D}^{*\\ensuremath{-}}{\\ensuremath{\\ell}}^{+}{\\ensuremath{\\nu}}_{\\ensuremath{\\ell}}$ at Belle"
      ],
      "text/plain": [
       "<IPython.core.display.Latex object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "Model-independent extraction of |<i>V</i>cb| from ⁎B¯→D⁎ℓν‾<math><mover accent=\"true\" is=\"true\"><mrow is=\"true\"><mi is=\"true\">B</mi></mrow><mrow is=\"true\"><mo stretchy=\"false\" is=\"true\">¯</mo></mrow></mover><mo stretchy=\"false\" is=\"true\">→</mo><msup is=\"true\"><mrow is=\"true\"><mi is=\"true\">D</mi></mrow><mrow is=\"true\"><mo is=\"true\">⁎</mo></mrow></msup><mi is=\"true\">ℓ</mi><mover accent=\"true\" is=\"true\"><mrow is=\"true\"><mi is=\"true\">ν</mi></mrow><mo is=\"true\">‾</mo></mover></math>"
      ],
      "text/plain": [
       "<IPython.core.display.Latex object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "High-precision $\\alpha_s$ measurements from LHC to FCC-ee"
      ],
      "text/plain": [
       "<IPython.core.display.Latex object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "Improved measurement of CP-violation parameters $\\mathrm{sin}﻿2{\\ensuremath{\\phi}}_{1}$ and $|\\ensuremath{\\lambda}|$, $B$ meson lifetimes, and ${B}^{0}$-${\\overline{B}}^{0}$ mixing parameter $\\ensuremath{\\Delta}{m}_{d}$"
      ],
      "text/plain": [
       "<IPython.core.display.Latex object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "Measurement of $b$ Hadron Lifetimes in Exclusive Decays Containing a $J/\\ensuremath{\\psi}$ in $p\\overline{p}$ Collisions at $\\sqrt{s}=1.96\\text{ }\\text{ }\\mathrm{TeV}$"
      ],
      "text/plain": [
       "<IPython.core.display.Latex object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "Bottom and charm mass determinations from global fits to $$ Q\\overline{Q} $$bound states at N3LO"
      ],
      "text/plain": [
       "<IPython.core.display.Latex object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "Novel method to reliably determine the QCD coupling from Ruds measurements and its effects to muon g − 2 and $$ \\alpha \\left({M}_Z^2\\right) $$within the tau-charm energy region"
      ],
      "text/plain": [
       "<IPython.core.display.Latex object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "Non-Lagrangian Models of Current Algebra"
      ],
      "text/plain": [
       "<IPython.core.display.Latex object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "Charmonium: Comparison with experiment"
      ],
      "text/plain": [
       "<IPython.core.display.Latex object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "REvolver: Automated running and matching of couplings and masses in QCD"
      ],
      "text/plain": [
       "<IPython.core.display.Latex object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "Jet origin identification and measurement of rare hadronic decays of Higgs boson at $e^+e^-$ collider"
      ],
      "text/plain": [
       "<IPython.core.display.Latex object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "SVD Approach to Data Unfolding"
      ],
      "text/plain": [
       "<IPython.core.display.Latex object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "The QCD running coupling"
      ],
      "text/plain": [
       "<IPython.core.display.Latex object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "Behavior of the effective QCD coupling ${\\ensuremath{\\alpha}}_{\\ensuremath{\\tau}}(s)$ at low scales"
      ],
      "text/plain": [
       "<IPython.core.display.Latex object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "One-prong $\\tau$decays with kaons"
      ],
      "text/plain": [
       "<IPython.core.display.Latex object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "Three-prong τ decays with charged kaons"
      ],
      "text/plain": [
       "<IPython.core.display.Latex object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "$K^0_S$production in $\\tau$decays"
      ],
      "text/plain": [
       "<IPython.core.display.Latex object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "A study of one-prong Tau decays with a charged kaon"
      ],
      "text/plain": [
       "<IPython.core.display.Latex object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "Physics prospects at the Belle II experiment"
      ],
      "text/plain": [
       "<IPython.core.display.Latex object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "STCF Conceptual Design Report: Volume 1 -- Physics & Detector"
      ],
      "text/plain": [
       "<IPython.core.display.Latex object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "Measurement and interpretation of moments in inclusive semileptonic decays $\\overline{B}\\ensuremath{\\rightarrow}{X}_{c}{\\ensuremath{\\ell}}^{\\ensuremath{-}}\\overline{\\ensuremath{\\nu}}$"
      ],
      "text/plain": [
       "<IPython.core.display.Latex object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "Precise Measurement of the ${e}^{+}{e}^{\\ensuremath{-}}\\ensuremath{\\rightarrow}{D}_{s}^{*+}{D}_{s}^{*\\ensuremath{-}}$ Cross Sections at Center-of-Mass Energies from Threshold to 4.95 GeV"
      ],
      "text/plain": [
       "<IPython.core.display.Latex object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "Systematic Errors: facts and fictions"
      ],
      "text/plain": [
       "<IPython.core.display.Latex object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "High Luminosity Large Hadron Collider HL-LHC"
      ],
      "text/plain": [
       "<IPython.core.display.Latex object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "FCC Physics Opportunities"
      ],
      "text/plain": [
       "<IPython.core.display.Latex object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "CLEO-c and CESR-c: A new frontier in strong and weak interactions"
      ],
      "text/plain": [
       "<IPython.core.display.Latex object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "The EvtGen particle decay simulation package"
      ],
      "text/plain": [
       "<IPython.core.display.Latex object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "Coherent exclusive exponentiation for precision Monte Carlo calculations"
      ],
      "text/plain": [
       "<IPython.core.display.Latex object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "The $$\\uptau $$challenges at FCC-ee"
      ],
      "text/plain": [
       "<IPython.core.display.Latex object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "The gluon mass generation mechanism: A concise primer"
      ],
      "text/plain": [
       "<IPython.core.display.Latex object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "Measurement of the $\\tau$-lepton mass with the Belle~II experiment"
      ],
      "text/plain": [
       "<IPython.core.display.Latex object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "Studies on $\\tau$ decays at Belle II"
      ],
      "text/plain": [
       "<IPython.core.display.Latex object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "Hadronic energy resolution of a highly granular scintillator-steel hadron calorimeter using software compensation techniques"
      ],
      "text/plain": [
       "<IPython.core.display.Latex object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "Software compensation in particle flow reconstruction"
      ],
      "text/plain": [
       "<IPython.core.display.Latex object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "Electromagnetic response of a highly granular hadronic calorimeter"
      ],
      "text/plain": [
       "<IPython.core.display.Latex object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "The CMS barrel calorimeter response to particle beams from 2 to 350 GeV/c"
      ],
      "text/plain": [
       "<IPython.core.display.Latex object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "Design, performance, and calibration of CMS forward calorimeter wedges"
      ],
      "text/plain": [
       "<IPython.core.display.Latex object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "Testing QCD with τ decays"
      ],
      "text/plain": [
       "<IPython.core.display.Latex object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "Measurement of αS from τ decays"
      ],
      "text/plain": [
       "<IPython.core.display.Latex object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "The perturbative QCD prediction to Rτ revisited"
      ],
      "text/plain": [
       "<IPython.core.display.Latex object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "Prospects for $$ {B}_{(s)}^0 $$→ π0π0 and $$ {B}_{(s)}^0 $$→ ηη modes and corresponding CP asymmetries at Tera-Z"
      ],
      "text/plain": [
       "<IPython.core.display.Latex object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "αs and the τ hadronic width: fixed-order, contour- improved and higher-order perturbation theory"
      ],
      "text/plain": [
       "<IPython.core.display.Latex object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "Duality violations in τ hadronic spectral moments"
      ],
      "text/plain": [
       "<IPython.core.display.Latex object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "Perturbative expansion of τ hadronic spectral function moments and αsextractions"
      ],
      "text/plain": [
       "<IPython.core.display.Latex object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "The determination of αSfrom τ decays revisited"
      ],
      "text/plain": [
       "<IPython.core.display.Latex object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "A Measurement of the Michel Parameters in Leptonic Decays of the Tau"
      ],
      "text/plain": [
       "<IPython.core.display.Latex object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "τ→π~±2π~0v结构函数的测量"
      ],
      "text/plain": [
       "<IPython.core.display.Latex object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "Tau mass measurement at BES-III"
      ],
      "text/plain": [
       "<IPython.core.display.Latex object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "τ~±→π~±+nπ~0+v_τ(n=0,1,2)衰变分支比测量"
      ],
      "text/plain": [
       "<IPython.core.display.Latex object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "Measurement of the Cross Section for ${e}^{+}{e}^{\\ensuremath{-}}\\ensuremath{\\rightarrow}\\text{Hadrons}$ at Energies from 2.2324 to 3.6710 GeV"
      ],
      "text/plain": [
       "<IPython.core.display.Latex object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "博士论文—J/psi共振参数测量"
      ],
      "text/plain": [
       "<IPython.core.display.Latex object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "Shower fractal dimension analysis in a highly-granular calorimeter"
      ],
      "text/plain": [
       "<IPython.core.display.Latex object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "Graph Neural Networks in Particle Physics"
      ],
      "text/plain": [
       "<IPython.core.display.Latex object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "Particle Flow Performance at CLIC"
      ],
      "text/plain": [
       "<IPython.core.display.Latex object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "CLD -- A Detector Concept for the FCC-ee"
      ],
      "text/plain": [
       "<IPython.core.display.Latex object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "Performance of particle flow calorimetry at CLIC"
      ],
      "text/plain": [
       "<IPython.core.display.Latex object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "QCD formulation of the tau decay and determination of ΛMS¯"
      ],
      "text/plain": [
       "<IPython.core.display.Latex object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "Perturbative QCD corrections to the ratio R for \\ensuremath{\\tau} decay"
      ],
      "text/plain": [
       "<IPython.core.display.Latex object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "QCD predictions for the decay of the \\ensuremath{\\tau} lepton"
      ],
      "text/plain": [
       "<IPython.core.display.Latex object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "Standard Model Theory for the FCC-ee Tera-Z stage"
      ],
      "text/plain": [
       "<IPython.core.display.Latex object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "Theory for the FCC-ee : Report on the 11th FCC-ee Workshop"
      ],
      "text/plain": [
       "<IPython.core.display.Latex object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "High precision determination of the gluon fusion Higgs boson cross-section at the LHC"
      ],
      "text/plain": [
       "<IPython.core.display.Latex object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "Leading QCD-induced four-loop contributions to the β-function of the Higgs self-coupling in the SM and vacuum stability"
      ],
      "text/plain": [
       "<IPython.core.display.Latex object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "Particle Identification Using Boosted Decision Trees in the Semi-Digital Hadronic Calorimeter Prototype"
      ],
      "text/plain": [
       "<IPython.core.display.Latex object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "4D tracking with ultra-fast silicon detectors"
      ],
      "text/plain": [
       "<IPython.core.display.Latex object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "4-Dimensional Tracking with Ultra-Fast Silicon Detectors"
      ],
      "text/plain": [
       "<IPython.core.display.Latex object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "Test beam studies of silicon timing for use in calorimetry"
      ],
      "text/plain": [
       "<IPython.core.display.Latex object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "Investigation of fast timing capabilities of silicon sensors for the CMS high granularity calorimeter at HL-LHC"
      ],
      "text/plain": [
       "<IPython.core.display.Latex object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "Performance of the ALEPH detector at LEP"
      ],
      "text/plain": [
       "<IPython.core.display.Latex object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "The CLEO II detector"
      ],
      "text/plain": [
       "<IPython.core.display.Latex object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "Jet Charge Measurement Using the Leading Charged Particles at e+e− → Z → qq¯ Process at CEPC Z pole operation"
      ],
      "text/plain": [
       "<IPython.core.display.Latex object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "Weightfield2: A fast simulator for silicon and diamond solid state detector"
      ],
      "text/plain": [
       "<IPython.core.display.Latex object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "Design optimization of ultra-fast silicon detectors"
      ],
      "text/plain": [
       "<IPython.core.display.Latex object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "First beam tests of prototype silicon modules for the CMS High Granularity Endcap Calorimeter"
      ],
      "text/plain": [
       "<IPython.core.display.Latex object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "Precision timing calorimetry with the CMS HGCAL"
      ],
      "text/plain": [
       "<IPython.core.display.Latex object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "Software digitizer for high granular gaseous detector"
      ],
      "text/plain": [
       "<IPython.core.display.Latex object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "博士论文-北京谱仪含粲夸克强子产生与衰变的实验研究"
      ],
      "text/plain": [
       "<IPython.core.display.Latex object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "High performance timing detectors for high energy physics experiments and new developments for the high luminosity LHC"
      ],
      "text/plain": [
       "<IPython.core.display.Latex object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "CMS precision timing physics impact for the HL-LHC upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.Latex object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "Precision timing calorimeter for high energy physics"
      ],
      "text/plain": [
       "<IPython.core.display.Latex object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "博士论文-ψ'->τ+τ-分支比的测量与BESIII μ探测器的研制"
      ],
      "text/plain": [
       "<IPython.core.display.Latex object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "博士论文-ψ(2S)共振参数的测量"
      ],
      "text/plain": [
       "<IPython.core.display.Latex object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "The Phase-2 Upgrade of the CMS Endcap Calorimeter"
      ],
      "text/plain": [
       "<IPython.core.display.Latex object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "Geant4—a simulation toolkit"
      ],
      "text/plain": [
       "<IPython.core.display.Latex object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "THE GAUSSIAN TRANSFORM"
      ],
      "text/plain": [
       "<IPython.core.display.Latex object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "On the timing performance of thin planar silicon sensors"
      ],
      "text/plain": [
       "<IPython.core.display.Latex object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "Search for the Lepton Flavor Violation Process $J/\\psi \\to e\\mu$ at BESIII"
      ],
      "text/plain": [
       "<IPython.core.display.Latex object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "Detailed studies of hadronic showers and comparison to GEANT4 simulations with data from highly granular calorimeters"
      ],
      "text/plain": [
       "<IPython.core.display.Latex object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "The H → b¯b, cc¯, gg measurement at CEPC"
      ],
      "text/plain": [
       "<IPython.core.display.Latex object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "Determination of the $e^ + e^- \\to \\gamma \\gamma (\\gamma)$cross-section at LEP 2"
      ],
      "text/plain": [
       "<IPython.core.display.Latex object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "Measurement of the e+e− → γγ(γ) cross section at LEP energies"
      ],
      "text/plain": [
       "<IPython.core.display.Latex object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "Study of photon detection efficiency in e+e− → γμ+μ− process"
      ],
      "text/plain": [
       "<IPython.core.display.Latex object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "Photon Reconstruction Performance at the CEPC baseline detector"
      ],
      "text/plain": [
       "<IPython.core.display.Latex object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "Tau-lepton Physics at the FCC-ee circular e$^+$e$^-$ Collider"
      ],
      "text/plain": [
       "<IPython.core.display.Latex object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "Blossom V: a new implementation of a minimum cost perfect matching algorithm"
      ],
      "text/plain": [
       "<IPython.core.display.Latex object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "Improving the Prompt Electromagnetic Energy Component of Jet Energy Resolution with pi0 Fitting in High Granularity Electromagnetic Calorimeters"
      ],
      "text/plain": [
       "<IPython.core.display.Latex object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "Resolution of RD/RD⁎ puzzle"
      ],
      "text/plain": [
       "<IPython.core.display.Latex object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "Jet performance at the Circular electron-positron Collider"
      ],
      "text/plain": [
       "<IPython.core.display.Latex object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "传感器线性度计算方法的研究"
      ],
      "text/plain": [
       "<IPython.core.display.Latex object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "The BABAR detector"
      ],
      "text/plain": [
       "<IPython.core.display.Latex object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "The BaBar electromagnetic calorimeter"
      ],
      "text/plain": [
       "<IPython.core.display.Latex object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "Experimental Tests of Particle Flow Calorimetry"
      ],
      "text/plain": [
       "<IPython.core.display.Latex object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "Performance of production modules of the Belle II pixel detector in a high-energy particle beam"
      ],
      "text/plain": [
       "<IPython.core.display.Latex object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "arXiv : Separation of two electromagnetic or electromagnetic - hadronic showers in CALICE SiW ECAL and ILD"
      ],
      "text/plain": [
       "<IPython.core.display.Latex object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "Separation of two overlapped electromagnetic or electromagnetic-hadronic showers in CALICE highly granular physics calorimeter prototypes using Pandora, Garlic and Arbor Particle Flow Algorithms"
      ],
      "text/plain": [
       "<IPython.core.display.Latex object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "Arbor, a new approach of the Particle Flow Algorithm"
      ],
      "text/plain": [
       "<IPython.core.display.Latex object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "GARLIC: GAmma Reconstruction at a LInear Collider experiment"
      ],
      "text/plain": [
       "<IPython.core.display.Latex object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "Jet Lepton identiﬁcation performance at a future electron positron Higgs Z factory"
      ],
      "text/plain": [
       "<IPython.core.display.Latex object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "Particle Flow Calorimetry and the PandoraPFA Algorithm"
      ],
      "text/plain": [
       "<IPython.core.display.Latex object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "The Pandora Particle Flow Algorithm"
      ],
      "text/plain": [
       "<IPython.core.display.Latex object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "Probing the strange Higgs coupling at lepton colliders using light-jet flavor tagging"
      ],
      "text/plain": [
       "<IPython.core.display.Latex object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "Secondary Vertex Reconstruction Performance at CEPC"
      ],
      "text/plain": [
       "<IPython.core.display.Latex object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "Performance study of the full hadronic WW and ZZ events’ separation at the CEPC"
      ],
      "text/plain": [
       "<IPython.core.display.Latex object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "Precision Higgs physics at the CEPC"
      ],
      "text/plain": [
       "<IPython.core.display.Latex object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "Feasibility study of TPC at electron positron colliders at $Z$ pole operation"
      ],
      "text/plain": [
       "<IPython.core.display.Latex object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "Cross section and Higgs mass measurement with Higgsstrahlung at the CEPC"
      ],
      "text/plain": [
       "<IPython.core.display.Latex object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "The Higgs signatures at the CEPC CDR baseline"
      ],
      "text/plain": [
       "<IPython.core.display.Latex object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "Experimental Tests of Particle Flow Calorimetry"
      ],
      "text/plain": [
       "<IPython.core.display.Latex object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "Precision Measurement of sin^2 theta_W at a Reactor"
      ],
      "text/plain": [
       "<IPython.core.display.Latex object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "Monte Carlo study of particle identification at the CEPC using TPC dE / dx information"
      ],
      "text/plain": [
       "<IPython.core.display.Latex object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "Reconstruction of physics objects at the Circular Electron Positron Collider with Arbor"
      ],
      "text/plain": [
       "<IPython.core.display.Latex object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "Measurement of b quark EW couplings at ILC"
      ],
      "text/plain": [
       "<IPython.core.display.Latex object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "Study of vertex optimization at the CEPC"
      ],
      "text/plain": [
       "<IPython.core.display.Latex object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "LCFIPlus: A framework for jet analysis in linear collider studies"
      ],
      "text/plain": [
       "<IPython.core.display.Latex object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "Timing performance of the CMS ECAL and prospects for the future"
      ],
      "text/plain": [
       "<IPython.core.display.Latex object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "Fractal Dimension of Particle Showers Measured in a Highly Granular Calorimeter"
      ],
      "text/plain": [
       "<IPython.core.display.Latex object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "TMVA - Toolkit for Multivariate Data Analysis"
      ],
      "text/plain": [
       "<IPython.core.display.Latex object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "Predicting protein structures with a multiplayer online game"
      ],
      "text/plain": [
       "<IPython.core.display.Latex object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "Topological B hadron decay reconstruction and identification of b-jets with JetFitter in the ATLAS experiment at the LHC The ATLAS Collaboration"
      ],
      "text/plain": [
       "<IPython.core.display.Latex object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "A framework for vertex reconstruction in the ATLAS experiment at LHC"
      ],
      "text/plain": [
       "<IPython.core.display.Latex object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "The measurement of the $$H\\rightarrow \\tau \\tau $$H→ττ signal strength in the future $$e^{+}e^{-}$$e+e- Higgs factories"
      ],
      "text/plain": [
       "<IPython.core.display.Latex object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "Measurement of the b forward-backward asymmetry and mixing using high-p⊥ leptons"
      ],
      "text/plain": [
       "<IPython.core.display.Latex object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "CEPC detector performance study"
      ],
      "text/plain": [
       "<IPython.core.display.Latex object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "Lepton identification at particle flow oriented detector for the future $$e^{+}e^{-}$$ e + e - Higgs factories"
      ],
      "text/plain": [
       "<IPython.core.display.Latex object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "Triple Gauge Boson Couplings"
      ],
      "text/plain": [
       "<IPython.core.display.Latex object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       "Optimal observables for the measurement of three gauge boson couplings in e + e -> W + W ?"
      ],
      "text/plain": [
       "<IPython.core.display.Latex object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display, Markdown, Latex\n",
    "for i in range(len(corpus)):\n",
    "    display(Latex(corpus[i]['data']['title']) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "A sample of $1.69\\times 10^7$ fully reconstructed $\\pi^0\\to\\gamma e^+e^-$ decay candidates collected by the NA48/2 experiment at CERN in 2003--2004 is analysed to search for the dark photon ($A'$) production in the $\\pi^0\\to\\gamma A'$ decay followed by the prompt $A'\\to e^+e^-$ decay. No signal is observed, and an exclusion region in the plane of the dark photon mass $m_{A'}$ and mixing parameter $\\varepsilon^2$ is established. The obtained upper limits on $\\varepsilon^2$ are more stringent than the previous limits in the mass range $9~{\\rm MeV}/c^2<m_{A'}<70~{\\rm MeV}/c^2$. The NA48/2 sensitivity to the dark photon production in the $K^\\pm\\to\\pi^\\pm A'$ decay is also evaluated."
      ],
      "text/plain": [
       "<IPython.core.display.Latex object>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Latex(corpus[0]['data']['abstractNote'])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "arXivDaily",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
